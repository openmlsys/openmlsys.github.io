<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>15.1. 背景 &#8212; 机器学习系统：设计和实现 1.0.0 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="附录：机器学习介绍" href="../appendix_machine_learning_introduction/index.html" />
    <link rel="prev" title="15. 可解释性AI系统" href="index.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">15. </span>可解释性AI系统</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">15.1. </span>背景</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_explainable_AI/explainable_ai.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  机器学习系统：设计和实现
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">1.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">1.2. 机器学习系统的需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">1.3. 机器学习系统基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">1.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">2. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">2.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">2.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">2.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">2.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">3.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">3.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">3.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">3.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">3.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">4. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">5. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">5.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">5.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">5.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">5.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">5.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">5.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">6. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">6.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">6.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">6.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">6.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">6.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">7. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">7.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">7.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html">7.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">8. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">8.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">8.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">8.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">8.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">8.6. 章节总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">9. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">9.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">9.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">9.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">9.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">9.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">10. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">10.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">10.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">10.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">10.4. 集合通讯</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">10.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">10.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">11. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">12. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">12.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">12.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">12.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">12.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">12.5. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_federated_learning/index.html">13. 联邦学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/overview.html">13.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/system_architecture.html">13.2. 系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/fedavg.html">13.3. 联邦平均算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/privacy_encryption_algorithm.html">13.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/challenge.html">13.5. 实际部署时的挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/summary.html">13.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">14. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">14.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">14.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">14.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">14.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">14.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">15. 可解释性AI系统</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">15.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ai">15.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">15.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id8">15.4. 未来可解释AI</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/index.html">参考文献</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  机器学习系统：设计和实现
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">1.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">1.2. 机器学习系统的需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">1.3. 机器学习系统基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">1.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">2. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">2.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">2.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">2.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">2.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">3.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">3.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">3.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">3.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">3.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">4. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">5. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">5.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">5.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">5.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">5.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">5.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">5.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">6. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">6.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">6.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">6.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">6.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">6.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">7. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">7.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">7.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html">7.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">8. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">8.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">8.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">8.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">8.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">8.6. 章节总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">9. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">9.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">9.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">9.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">9.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">9.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">10. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">10.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">10.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">10.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">10.4. 集合通讯</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">10.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">10.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">11. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">12. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">12.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">12.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">12.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">12.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">12.5. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_federated_learning/index.html">13. 联邦学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/overview.html">13.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/system_architecture.html">13.2. 系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/fedavg.html">13.3. 联邦平均算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/privacy_encryption_algorithm.html">13.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/challenge.html">13.5. 实际部署时的挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/summary.html">13.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">14. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">14.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">14.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">14.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">14.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">14.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">15. 可解释性AI系统</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">15.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ai">15.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">15.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id8">15.4. 未来可解释AI</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/index.html">参考文献</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <section id="id1">
<h1><span class="section-number">15.1. </span>背景<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>在人类历史上，技术进步、生产关系逻辑和伦理法规的发展是动态演进的。当一种新的技术在实验室获得突破后，其引发的价值产生方式的变化会依次对商品形态、生产关系等带来冲击。而同时当新技术带来的价值提升得到认可后，商业逻辑的组织形态在自发的调整过程中，也会对技术发展的路径、内容甚至速度提出诉求，并当诉求得到满足时适配以新型的伦理法规。在这样的相互作用中，技术系统与社会体系会共振完成演进，是谓技术革命。</p>
<p>近10年来，籍由算力与数据规模的性价比突破临界点，以深度神经网络为代表的联结主义模型架构及统计学习范式（以后简称深度学习）在特征表征能力上取得了跨越级别的突破，大大推动了人工智能的发展，在很多场景中达到令人难以置信的效果。比如：人脸识别准确率达到97%以上；谷歌智能语音助手回答正确率，在2019年的测试中达到92.9%。在这些典型场景下，深度学习在智能表现上的性能已经超过了普通人类（甚至专家），从而到了撬动技术更替的临界点。在过去几年间，在某些商业逻辑对技术友好，或者伦理法规暂时稀缺的领域，如安防、实时调度、流程优化、竞技博弈、信息流分发等，人工智能和深度学习取得了技术和商业上快速突破。</p>
<p>食髓知味，技术发展的甜头自然每个领域都不愿放过。而当对深度学习商业化运用来到某些对技术敏感、与人的生存或安全关系紧密的领域，如自动驾驶、金融、医疗和司法等高风险应用场景时，原有的商业逻辑在进行技术更替的过程中就会遇到阻力，从而导致商业化变现速度的减缓甚至失败。究其原因，以上场景的商业逻辑及背后伦理法规的中枢之一是稳定的、可追踪的责任明晰与责任分发；而深度学习得到的模型是个黑盒，我们无法从模型的结构或权重中获取模型行为的任何信息，从而使这些场景下责任追踪和分发的中枢无法复用，导致人工智能在业务应用中遇到技术上和结构上的困难。</p>
<p>举2个具体的例子：例1，在金融风控场景，通过深度学习模型识别出来小部分用户有欺诈嫌疑，但是业务部门不敢直接使用这个结果进行处理。因为人们难以理解结果是如何得到的，从而无法判断结果是否准确。而且该结果缺乏明确的依据，如果处理了，也无法向监管机构交代；
例2，在医疗领域，深度学习模型根据患者的检测数据，判断患者有肺结核，但是医生不知道诊断结果是怎么来的，不敢直接采用，而是根据自己的经验，仔细查看相关检测数据，然后给出自己的判断。从这2个例子可以看出，黑盒模型严重影响模型在实际场景的应用和推广。</p>
<p>此外，模型的可解释性问题也引起了国家层面的关注，相关机构对此推出了相关的政策和法规。</p>
<ul class="simple">
<li><p>2017年7月，国务院印发《新一代人工智能发展规划》，首次涵盖可解释AI。</p></li>
<li><p>2021年3月，中国人民银行发布金融行业标准《人工智能算法金融应用评价规范》，对金融行业AI模型可解释性提出了明确要求。</p></li>
<li><p>2021年8月，网信办《互联网信息服务算法推荐管理规定》,
提出对互联网行业算法推荐可解释性的要求。</p></li>
<li><p>2021年9月，科技部发布《新一代人工智能伦理规范》。</p></li>
</ul>
<p>因此，从商业推广层面以及从法规层面，我们都需要打开黑盒模型，对模型进行解释，可解释AI正是解决该类问题的技术。</p>
</section>
<section id="ai">
<h1><span class="section-number">15.2. </span>可解释AI定义<a class="headerlink" href="#ai" title="Permalink to this headline">¶</a></h1>
<p>按DARPA（美国国防部先进研究项目局）的描述，如图
<a class="reference internal" href="#xai-concept"><span class="std std-numref">图15.2.1</span></a>所示，
可解释AI的概念在于：区别于现有的AI系统，可解释AI系统可以解决用户面对黑盒模型时遇到的问题，使得用户知其然并知其所以然。</p>
<figure class="align-default" id="id9">
<span id="xai-concept"></span><a class="reference internal image-reference" href="../_images/xai_concept.png"><img alt="../_images/xai_concept.png" src="../_images/xai_concept.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.2.1 </span><span class="caption-text">可解释AI概念（图片来源于Broad Agency Announcement Explainable
Artificial Intelligence (XAI) DARPA-BAA-16–53）</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>然而，不论是学术界还是工业界，对于可解释AI (eXplainable
AI(XAI))都没有一个统一的定义。这里列举3种典型定义，供大家参考讨论：</p>
<ul class="simple">
<li><p>可解释性就是希望寻求对模型工作机理的直接理解，打破人工智能的黑盒子。</p></li>
<li><p>可解释AI是为AI算法所做出的决策提供人类可读的以及可理解的解释。</p></li>
<li><p>可解释AI是确保人类可以轻松理解和信任人工智能代理做出的决策的一组方法。</p></li>
</ul>
<p>可见，关注点在于对模型的理解、黑盒模型白盒化以及模型的可信任。</p>
<p>我们根据自身的实践经验和理解，将可解释AI定义为：一套面向机器学习（主要是深度神经网络）的技术合集，包括可视化、数据挖掘、逻辑推理、知识图谱等，目的是通过此技术合集，使深度神经网络呈现一定的可理解性，以满足相关使用者对模型及应用服务产生的信息诉求（如因果或背景信息），从而为使用者对人工智能服务建立认知层面的信任。</p>
</section>
<section id="id2">
<h1><span class="section-number">15.3. </span>可解释AI算法现状介绍<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h1>
<p>随着可解释AI概念的提出，可解释AI越来越受到学术界及工业界的关注，下图展示了人工智能领域顶级学术会议中可解释AI关键字的趋势。为了让读者更好的对现有可解释AI算法有一个整体认知，我们这里参考
<a class="bibtex reference internal" href="../chapter_references/index.html#tkde-li" id="id3">[Li et al., 2020]</a>总结归纳了可解释AI的算法类型，如图
<a class="reference internal" href="#xai-methods"><span class="std std-numref">图15.3.1</span></a>所示。</p>
<figure class="align-default" id="id10">
<span id="xai-methods"></span><a class="reference internal image-reference" href="../_images/XAI_methods.PNG"><img alt="../_images/XAI_methods.PNG" src="../_images/XAI_methods.PNG" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.1 </span><span class="caption-text">可解释AI（XAI）算法分支</span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>对模型进行解释有多种多样的方法，这里依据解释过程是否引入数据集以外的外部知识，将其分为数据驱动的解释方法和知识感知的解释方法。</p>
<p><strong>数据驱动的解释</strong></p>
<p>数据驱动的解释是指纯粹从数据本身生成解释的方法，而不需要先验知识等外部信息。为了提供解释，数据驱动的方法通常从选择数据集（具有全局或局部分布）开始。然后，将选定的数据集或其变体输入到黑盒模型（在某些情况下，选取数据集不是所必需的。例如，
<a class="bibtex reference internal" href="../chapter_references/index.html#erhan2009visualizing" id="id4">[Erhan et al., 2009]</a>提出的最大激活值方法），通过对黑盒模型的相应预测进行一定的分析(例如，对预测w.r.t.输入特征进行求导）来生成解释。根据可解释性的范围，这些方法可以进一步分为全局方法或局部方法，即它们是解释所有数据点的全局模型行为还是预测子集行为。数据驱动方法的解释可以以各种形式进行，例如特征重要性和决策规则等。特别地，基于样本的方法提供了一种特殊类型的解释——它们直接返回数据实例作为解释。虽然从解释范围的分类来看，基于实例的方法也可以适合全局方法（代表性样本）或局部方法（反事实），但我们单独列出它们，以强调它们提供解释的特殊方式。
全局方法旨在提供对模型逻辑的理解以及所有预测的完整推理，基于对其特征、学习到的组件和结构的整体视图等等。有几个方向可以探索全局可解释性。为了便于理解，我们将它们分为以下三个子类：
(i)
模型提取——从原始黑盒模型中提取出一个可解释的模型，比如通过模型蒸馏的方式将原有黑盒模型蒸馏到可解释的决策树，从而使用决策树中的规则解释该原始模型；
(ii) 基于特征的方法——估计特征的重要性或相关性，如图
<a class="reference internal" href="#xai-global-feature-importance"><span class="std std-numref">图15.3.2</span></a>所示,
该类型解释可提供如“信用逾期记录是模型依赖的最重要特征”的解释，从而协助判定模型是否存在偏见
(iii) 透明模型设计——修改或重新设计黑盒模型以提高其可解释性。</p>
<figure class="align-default" id="id11">
<span id="xai-global-feature-importance"></span><a class="reference internal image-reference" href="../_images/xai_global_feature_importance.png"><img alt="../_images/xai_global_feature_importance.png" src="../_images/xai_global_feature_importance.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.2 </span><span class="caption-text">全局特征重要性解释</span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>全局解释提供了黑盒模型的透明视图，但构建大规模复杂模型的忠实近似和从整个输入分布中提取一般显着性模式在实践中仍然具有挑战性。在为单个样例生成解释时，全局解释也缺乏局部准确性，因为全局重要的特征可能无法准确解释单个样例的输出。局部方法不是给出黑盒模型内部不透明机制的完整描述，而是尝试为单个样例或一组样例证明模型行为的合理性。复杂模型的局部行为可能通过简单的线性关系与较少的特征相关联，从而减轻解释黑盒模型的挑战。简单的函数也有助于在局部区域内提供可信任的解释。基于获得解释的过程，局部方法可以分为两类：局部近似和基于梯度传播的方法。</p>
<p>局部近似是通过在样本近邻区域模拟黑盒模型的行为生成可理解的子模型。相比于全局方法中的模型提取，局部近似仅需关注样本临近区域，因此更容易获得精确描述局部行为的子模型。如图
<a class="reference internal" href="#xai-lime"><span class="std std-numref">图15.3.3</span></a>所示，通过在关注数据点</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-0">
<span class="eqno">(15.3.1)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-0" title="Permalink to this equation">¶</a></span>\[x\]</div>
<p>附近生成</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-1">
<span class="eqno">(15.3.2)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-1" title="Permalink to this equation">¶</a></span>\[m\]</div>
<p>个数据点</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-2">
<span class="eqno">(15.3.3)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-2" title="Permalink to this equation">¶</a></span>\[(x_i^\prime, f(x_i^\prime)), for\  i=1,2, ...m\]</div>
<p>（这里</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-3">
<span class="eqno">(15.3.4)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-3" title="Permalink to this equation">¶</a></span>\[f\]</div>
<p>为黑盒模型决策函数）,用线性拟合这些数据点，可以得到一个线性模型</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-4">
<span class="eqno">(15.3.5)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-4" title="Permalink to this equation">¶</a></span>\[g=\sum_i^k w_ix^i\]</div>
<p>，这里</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-5">
<span class="eqno">(15.3.6)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-5" title="Permalink to this equation">¶</a></span>\[k\]</div>
<p>表示数据的特征维度。那么线性模型中的权重</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-6">
<span class="eqno">(15.3.7)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-6" title="Permalink to this equation">¶</a></span>\[w_i\]</div>
<p>即可用于表示数据</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-7">
<span class="eqno">(15.3.8)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-7" title="Permalink to this equation">¶</a></span>\[x\]</div>
<p>中第</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-8">
<span class="eqno">(15.3.9)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-8" title="Permalink to this equation">¶</a></span>\[i\]</div>
<p>个特征对于模型</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-9">
<span class="eqno">(15.3.10)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-9" title="Permalink to this equation">¶</a></span>\[f\]</div>
<p>的重要性。</p>
<figure class="align-default" id="id12">
<span id="xai-lime"></span><a class="reference internal image-reference" href="../_images/xai_lime.png"><img alt="../_images/xai_lime.png" src="../_images/xai_lime.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.3 </span><span class="caption-text">局部近似方法示例</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>基于梯度传播的方法通常是用梯度传播直接定位相关特征，这些方法封装了基于反向传播的方法和基于前向传播的方法。基于反向传播的方法将输出的贡献归因于输入特征。如图
<a class="reference internal" href="#xai-gradient-based"><span class="std std-numref">图15.3.4</span></a>所示,通过梯度回传，计算模型输出对输入的梯度</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-10">
<span class="eqno">(15.3.11)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-10" title="Permalink to this equation">¶</a></span>\[\frac{d(f(x)}{dx}\]</div>
<p>作为模型解释。
而基于前向传播的方法通过扰动特征后的输出差异来量化输出与特征的相关性。</p>
<figure class="align-default" id="id13">
<span id="xai-gradient-based"></span><a class="reference internal image-reference" href="../_images/xai_gradient_based.PNG"><img alt="../_images/xai_gradient_based.PNG" src="../_images/xai_gradient_based.PNG" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.4 </span><span class="caption-text">局部近似方法示例</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p><strong>知识感知的解释</strong></p>
<p>数据驱动的解释方法能够从数据集或输入和输出之间的关系提供全面的解释。在此基础上，还可以利用外部知识来丰富解释并使其更加人性化。没有机器学习背景知识的门外汉可能很难直接理解特征的重要性，以及特征和目标之间的联系。借助外部领域知识，我们不仅可以生成表明特征重要性的解释，还可以描述某些特征比其他特征更重要的原因。因此，在过去几年中，基于知识感知的可解释AI方法引起了越来越多的关注。与从多种情景中收集的原始数据集相比，知识通常被视为人类根据生活经验或严格的理论推理得出的实体或关系。一般来说，知识可以有多种形式。它可以保留在人的头脑中，也可以用自然语言、音频或规则记录，具有严格的逻辑。为了对这些方法进行系统回顾，我们在此根据知识来源将它们分为两类：通用知识方法和知识库（KB）方法。前者以非结构化数据为知识源来构建解释，后者以结构化知识库为基础来构建解释。</p>
<p>提供知识的一个相对直接的方法是通过人类的参与。事实上，随着人工智能研究和应用的爆炸式增长，人类在人工智能系统中的关键作用已经慢慢显现。这样的前景被称为以人为中心的人工智能。
<a class="bibtex reference internal" href="../chapter_references/index.html#riedl2019human" id="id5">[Riedl, 2019]</a>认为，以人为中心的人工智能不仅能让人工智能系统从社会文化的角度更好地了解人类，还能让人工智能系统帮助人类了解自己。为了实现这些目标，人工智能需要满足可解释性和透明度等几个属性。</p>
<p>具体来说，人类能够通过提供相当多的人类定义的概念来在人工智能系统中发挥作用。
<a class="bibtex reference internal" href="../chapter_references/index.html#kim2018interpretability" id="id6">[Kim et al., 2018]</a>利用概念激活向量（CAV）来测试概念在分类任务中的重要性（TCAV）。CAV是垂直于感兴趣概念的正输入和负输入激活之间的决策边界的矢量，该过程通过输入概念的正负样本并通过线性回归获得。以“斑马”的“条纹”概念为例，用户首先收集包含有“条纹”的数据样本及不含“条纹”的数据样本，输入到网络中，获取中间层的激活值，基于正负样本的标签（</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-11">
<span class="eqno">(15.3.12)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-11" title="Permalink to this equation">¶</a></span>\[1\]</div>
<p>代表含有概念，</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-12">
<span class="eqno">(15.3.13)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-12" title="Permalink to this equation">¶</a></span>\[0\]</div>
<p>代表不含概念）对中间层激活值进行拟合，获取决策边界，CAV即为该决策边界的垂直向量。</p>
<p>如 <a class="reference internal" href="#xai-tcav"><span class="std std-numref">图15.3.5</span></a>所示，为了计算TCAV评分，代表第</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-13">
<span class="eqno">(15.3.14)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-13" title="Permalink to this equation">¶</a></span>\[l\]</div>
<p>层概念对类</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-14">
<span class="eqno">(15.3.15)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-14" title="Permalink to this equation">¶</a></span>\[k\]</div>
<p>预测的重要性的“概念敏感度”可以首先计算为方向导数</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-15">
<span class="eqno">(15.3.16)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-15" title="Permalink to this equation">¶</a></span>\[S_{C,k,l}(\mathbf{x})\]</div>
<p>：</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-16">
<span class="eqno">(15.3.17)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-16" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{split}
S_{C,k,l}(\mathbf{x}) =  &amp;\lim_{\epsilon\rightarrow 0}\frac{h_{l,k}(f_{l}(\mathbf{x})+\epsilon \mathbf{v}^{l}_{C})-h_{l,k}(f_{l}(\mathbf{x}))}{\epsilon} \\ = &amp;\nabla h_{l,k}(f_{l}(\mathbf{x})) \cdot \mathbf{v}^{l}_{C}
\end{split}
\label{eq:TCAV_score}\end{split}\]</div>
<p>其中</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-17">
<span class="eqno">(15.3.18)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-17" title="Permalink to this equation">¶</a></span>\[f_{l}(\mathbf{x})\]</div>
<p>是在第</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-18">
<span class="eqno">(15.3.19)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-18" title="Permalink to this equation">¶</a></span>\[l\]</div>
<p>、</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-19">
<span class="eqno">(15.3.20)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-19" title="Permalink to this equation">¶</a></span>\[h_{l,k}(\cdot)\]</div>
<p>是类</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-20">
<span class="eqno">(15.3.21)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-20" title="Permalink to this equation">¶</a></span>\[k\]</div>
<p>的logit,</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-21">
<span class="eqno">(15.3.22)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-21" title="Permalink to this equation">¶</a></span>\[\nabla h_{l,k}(\cdot)\]</div>
<p>是</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-22">
<span class="eqno">(15.3.23)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-22" title="Permalink to this equation">¶</a></span>\[h_{l，k}\]</div>
<p>w.r.t层</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-23">
<span class="eqno">(15.3.24)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-23" title="Permalink to this equation">¶</a></span>\[l\]</div>
<p>的激活的梯度。</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-24">
<span class="eqno">(15.3.25)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-24" title="Permalink to this equation">¶</a></span>\[\mathbf{v}^{l}_{C}\]</div>
<p>是用户旨在探索的概念</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-25">
<span class="eqno">(15.3.26)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-25" title="Permalink to this equation">¶</a></span>\[C\]</div>
<p>的CAV。正（或负）敏感性表明概念</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-26">
<span class="eqno">(15.3.27)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-26" title="Permalink to this equation">¶</a></span>\[C\]</div>
<p>对输入的激活有正（或负）影响。</p>
<p>使用</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-27">
<span class="eqno">(15.3.28)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-27" title="Permalink to this equation">¶</a></span>\[S_{C,k,l}\]</div>
<p>, TCAV可以作为来自类</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-28">
<span class="eqno">(15.3.29)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-28" title="Permalink to this equation">¶</a></span>\[k\]</div>
<p>的样本的比率获得，具有正</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-29">
<span class="eqno">(15.3.30)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-29" title="Permalink to this equation">¶</a></span>\[S_{C,k,l}\]</div>
<p>’s：</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-30">
<span class="eqno">(15.3.31)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-30" title="Permalink to this equation">¶</a></span>\[\textbf{TCAV}_{Q_{C,k,l}}=\frac{\vert \{\mathbf{x}\in X_{k}:S_{C,k,l}(\mathbf{x})&gt;0\}\vert}{\vert X_{k}\vert}
\label{eq:TCAV}\]</div>
<p>结合</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-31">
<span class="eqno">(15.3.32)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-31" title="Permalink to this equation">¶</a></span>\[t\]</div>
<p>-分布假设方法，如果</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-32">
<span class="eqno">(15.3.33)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-32" title="Permalink to this equation">¶</a></span>\[\textbf{TCAV}_{Q_{C,k,l}}\]</div>
<p>大于0.5，则表明概念</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-33">
<span class="eqno">(15.3.34)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-33" title="Permalink to this equation">¶</a></span>\[C\]</div>
<p>对类</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-34">
<span class="eqno">(15.3.35)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-34" title="Permalink to this equation">¶</a></span>\[k\]</div>
<p>有重大影响。</p>
<p>= [rectangle, minimum height=2.5cm, text width=2.4cm, text centered,
draw=black, font=] = [thick,-&gt;,&gt;=stealth]</p>
<p>(step1) [startstop] 收集一个概念的正负样本; (step2) [startstop, right
of=step1] 输入正负样模型获取中间层的激活; (step3) [startstop, right
of=step2] 通过线性回归获取 CAVs; (step4) [startstop, right of=step3]
计算TCAV分值;</p>
<p>(step1) – (step2); (step2) – (step3); (step3) – (step4);</p>
<figure class="align-default" id="id14">
<span id="xai-tcav"></span><a class="reference internal image-reference" href="../_images/xai_tcav.png"><img alt="../_images/xai_tcav.png" src="../_images/xai_tcav.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.5 </span><span class="caption-text">TCAV流程(图片来源于 <a class="bibtex reference internal" href="../chapter_references/index.html#tkde-li" id="id7">[Li et al., 2020]</a>)</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>人类的知识可以是主观的，而KB可以是客观的。在当前研究中，KB通常被建模为知识图谱(KG)。以下以MindSpore支持的可解释推荐模型TB-Net为例，讲解如何使用知识图谱构建可解释模型。知识图谱可以捕捉实体之间丰富的语义关系。TB-Net的目的之一就是确定哪一对实体（即，物品-物品）对用户产生最重大的影响，并通过什么关系和关键节点进行关联。不同于现有的基于KG嵌入的方法（RippleNet使用KG补全方法预测用户与物品之间的路径），TB-Net提取真实路径，以达到推荐结果的高准确性和和优越的可解释性。</p>
<figure class="align-default" id="id15">
<span id="tb-net"></span><a class="reference internal image-reference" href="../_images/tb_net.png"><img alt="../_images/tb_net.png" src="../_images/tb_net.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.6 </span><span class="caption-text">TB-Net网络训练框架</span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>TB-Net的框架如图
<a class="reference internal" href="#tb-net"><span class="std std-numref">图15.3.6</span></a>所示：其中，Step代表步骤，historical代表历史的记录在图谱中的节点。Path
extraction代表路径抽取，embedding
propagation代表图嵌入向量传导技术，R代表关系矩阵，e代表图谱中的实体节点，pair
block代表物品配对块，user
response代表用户兴趣反馈向量，update代表更新词向量，concat代表拼接计算。步骤1，TB-Net得到目标项</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-35">
<span class="eqno">(15.3.36)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-35" title="Permalink to this equation">¶</a></span>\[\tau\]</div>
<p>，用户</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-36">
<span class="eqno">(15.3.37)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-36" title="Permalink to this equation">¶</a></span>\[u\]</div>
<p>和该用户的子图。子图是通过历史点击项集合</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-37">
<span class="eqno">(15.3.38)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-37" title="Permalink to this equation">¶</a></span>\[I_u\]</div>
<p>（蓝色部分）来构建生成；步骤2，连接</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-38">
<span class="eqno">(15.3.39)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-38" title="Permalink to this equation">¶</a></span>\[\tau\]</div>
<p>和</p>
<div class="math notranslate nohighlight" id="equation-chapter-explainable-ai-explainable-ai-39">
<span class="eqno">(15.3.40)<a class="headerlink" href="#equation-chapter-explainable-ai-explainable-ai-39" title="Permalink to this equation">¶</a></span>\[I_u\]</div>
<p>之间的路径（第2小节），提取路径作为双向嵌入传播网络TB-Net的输入（第3小节）。词向量的计算从路径的左侧和右侧传播到中间节点（图中的绿色节点）；步骤3，计算左右两个流向的词向量汇集到同一中间实体的概率。概率用于表示用户对中间实体的喜好程度，并作为解释的依据；步骤4，TB-Net同时输出推荐结果和具有语义级别的解释。</p>
<p>以游戏推荐为场景，随机对一个用户推荐新的游戏，如图
<a class="reference internal" href="#xai-kg-recommendataion"><span class="std std-numref">图15.3.7</span></a>所示，其中Half-Life代表游戏半条命，DOTA
2 代表游戏刀塔2，Team Fortress 2代表游戏军团要塞2。关系属性中，game.year
代表游戏发行年份，game.genres代表游戏属性，game.developer代表游戏的开发商，game.categories代表游戏分类。属性节点中，MOBA代表多人在线战术竞技游戏，valve代表威尔乌游戏公司，action代表动作类，Multi-player代表多人游戏，Valve
Anti-Cheat
enabled代表威尔乌防作弊类，Free代表免费，Cross-Platform代表跨平台。左边的游戏是从训练数据中选取的评分项。而测试数据中正确推荐的游戏是“Team
Fortress 2”。</p>
<figure class="align-default" id="id16">
<span id="xai-kg-recommendataion"></span><a class="reference internal image-reference" href="../_images/xai_kg_recommendataion.png"><img alt="../_images/xai_kg_recommendataion.png" src="../_images/xai_kg_recommendataion.png" style="width: 800px;" /></a>
<figcaption>
<p><span class="caption-number">图15.3.7 </span><span class="caption-text">Steam游戏推荐可解释示例 （用户玩过的游戏: Half-Life, DOAT 2.
推荐命中的游戏: “Team Fortress 2”。具有属性信息的节点如，game.geners:
Action, free-to-play; game.developer: Valve; game.categories:
Multiplayer, MOBA.）</span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>在图
<a class="reference internal" href="#xai-kg-recommendataion"><span class="std std-numref">图15.3.7</span></a>中，有两个突出显示的相关概率（38.6%,
21.1%），它们是在推荐过程中模型计算的路径被激活的概率。实线箭头突出显示从“Team
Fortress
2”到历史项目“Half-Life”之间的路径。它表明TB-Net能够通过各种关系连接向用户推荐物品，并输出关键因素作为解释。因此，将“Team
Fortress 2”推荐给用户的解释可以翻译成固定话术：“Team Fortress
2”是游戏公司“Valve”开发的一款动作类、多人在线、射击类“action”电子游戏。这与用户历史玩过的游戏“Half-Life”有高度关联。</p>
</section>
<section id="id8">
<h1><span class="section-number">15.4. </span>未来可解释AI<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h1>
<p>为了进一步推动可解释AI的研究，我们在此总结了一些值得注意的研究方向。</p>
<p>首先，知识感知型XAI仍有很大的研究扩展空间。然而，要有效地利用外部知识，仍有许多悬而未决的问题。问题之一是，如何在如此广阔的知识空间中获取或检索有用的知识。一个人通常拥有来自各个领域的知识，因此XAI系统需要引导这个人提供所需的知识而不是无关的知识。</p>
<p>此外，XAI系统的部署也非常需要一个更加标准和更加统一的评估框架。为了构建标准统一的评估框架，我们可能需要同时利用不同的指标，相互补充。不同的指标可能适用于不同的任务和用户。统一的评价框架应具有相应的灵活性。</p>
<p>最后，我们相信跨学科合作将是有益的。XAI的发展不仅需要计算机科学家来开发先进的算法，还需要物理学家、生物学家和认知科学家来揭开人类认知的奥秘，以及特定领域的专家来贡献他们的领域知识。</p>
</section>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">15.1. 背景</a></li>
<li><a class="reference internal" href="#ai">15.2. 可解释AI定义</a></li>
<li><a class="reference internal" href="#id2">15.3. 可解释AI算法现状介绍</a></li>
<li><a class="reference internal" href="#id8">15.4. 未来可解释AI</a></li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>15. 可解释性AI系统</div>
         </div>
     </a>
     <a id="button-next" href="../appendix_machine_learning_introduction/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>附录：机器学习介绍</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>