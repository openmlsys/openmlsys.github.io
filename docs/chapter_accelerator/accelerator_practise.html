<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>8.4. 加速器实践 &#8212; 机器学习系统：设计和实现 1.0.0 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8.5. 总结" href="summary.html" />
    <link rel="prev" title="8.3. 加速器基本编程原理" href="accelerator_programming.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">8. </span>硬件加速器</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">8.4. </span>加速器实践</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_accelerator/accelerator_practise.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="机器学习系统：设计和实现"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">1. 序言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">2. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">2.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">2.2. 设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">2.3. 基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">2.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">3. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">3.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">3.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">3.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">3.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">3.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html#id2">3.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">4. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">4.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">4.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">4.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">4.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">4.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html#id2">4.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">5. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">6. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">6.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">6.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">6.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">6.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">6.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html#id2">6.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">7. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">7.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">7.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">7.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">7.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">7.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html#id2">7.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">8. 硬件加速器</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="accelerator_introduction.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="accelerator_architecture.html">8.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="accelerator_programming.html">8.3. 加速器基本编程原理</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">8.4. 加速器实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html">8.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html#id2">8.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html#id3">8.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">9. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">9.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">9.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">9.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">9.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">9.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html#id2">9.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">10. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">10.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">10.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">10.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">10.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">10.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">10.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html#id2">10.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">11. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">11.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">11.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">11.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">11.4. 集合通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">11.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">11.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id2">11.7. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id3">11.8. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">12. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">13. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">13.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">13.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">13.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">13.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">13.5. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id2">13.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id3">13.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_federated_learning/index.html">14. 联邦学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/overview.html">14.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/horizontal_fl.html">14.2. 横向联邦学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/vertical_fl.html">14.3. 纵向联邦学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/privacy_encryption_algorithm.html">14.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/outlook.html">14.5. 展望</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">15. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">15.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">15.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">15.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">15.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">15.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">15.6. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html#id2">15.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_explainable_AI/index.html">16. 可解释性AI系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html">16.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#ai">16.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id2">16.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id17">16.4. 可解释AI系统及实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id21">16.5. 未来可解释AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id22">16.6. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rl_sys/index.html">17. 机器人系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/rl_sys_intro.html">17.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros.html">17.2. 通用机器人操作系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros_code_ex.html">17.3. 机器人操作系统（ROS）的入门案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception.html">17.4. 感知系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception_code_ex.html">17.5. 感知系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning.html">17.6. 规划系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning_code_ex.html">17.7. 规划系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control.html">17.8. 控制系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control_code_ex.html">17.9. 控制系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/robot_safety.html">17.10. 在机器人项目中安全的应用机器学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html">17.11. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html#id2">17.12. 参考文献</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html#id4">4. 参考文献</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="机器学习系统：设计和实现"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">1. 序言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">2. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">2.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">2.2. 设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">2.3. 基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">2.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">3. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">3.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">3.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">3.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">3.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">3.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html#id2">3.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">4. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">4.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">4.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">4.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">4.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">4.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html#id2">4.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">5. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">6. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">6.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">6.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">6.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">6.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">6.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html#id2">6.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">7. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">7.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">7.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">7.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">7.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">7.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html#id2">7.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">8. 硬件加速器</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="accelerator_introduction.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="accelerator_architecture.html">8.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="accelerator_programming.html">8.3. 加速器基本编程原理</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">8.4. 加速器实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html">8.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html#id2">8.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html#id3">8.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">9. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">9.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">9.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">9.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">9.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">9.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html#id2">9.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">10. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">10.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">10.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">10.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">10.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">10.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">10.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html#id2">10.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">11. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">11.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">11.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">11.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">11.4. 集合通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">11.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">11.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id2">11.7. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id3">11.8. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">12. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">13. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">13.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">13.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">13.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">13.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">13.5. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id2">13.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id3">13.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_federated_learning/index.html">14. 联邦学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/overview.html">14.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/horizontal_fl.html">14.2. 横向联邦学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/vertical_fl.html">14.3. 纵向联邦学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/privacy_encryption_algorithm.html">14.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/outlook.html">14.5. 展望</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">15. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">15.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">15.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">15.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">15.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">15.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">15.6. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html#id2">15.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_explainable_AI/index.html">16. 可解释性AI系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html">16.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#ai">16.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id2">16.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id17">16.4. 可解释AI系统及实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id21">16.5. 未来可解释AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id22">16.6. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rl_sys/index.html">17. 机器人系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/rl_sys_intro.html">17.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros.html">17.2. 通用机器人操作系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros_code_ex.html">17.3. 机器人操作系统（ROS）的入门案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception.html">17.4. 感知系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception_code_ex.html">17.5. 感知系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning.html">17.6. 规划系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning_code_ex.html">17.7. 规划系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control.html">17.8. 控制系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control_code_ex.html">17.9. 控制系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/robot_safety.html">17.10. 在机器人项目中安全的应用机器学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html">17.11. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html#id2">17.12. 参考文献</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html#id4">4. 参考文献</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="id1">
<h1><span class="section-number">8.4. </span>加速器实践<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>上一节中介绍了调用第三方库或算子优化器的外部接口从而利用硬件加速器加速计算，这种方法要求我们算法的算子全部被第三方库或是算法优化器所支持，对于一些特殊的自定义算子很有可能不被支持，因此能自行实现高性能算子是实现定制化分布式系统的一个极为重要的能力。本节将会以广义矩阵乘法为例，通过提高计算强度、使用共享内存、优化内存读取流水线等方法最终取得接近硬件加速器性能峰值的实现，同时介绍若干性能优化的关键技术。选择广义矩阵乘法的原因是在深度学习中全连接网络的重要组件就是广义矩阵乘法，事实上，卷积操作也往往是通过im2col等方法将其转化为广义矩阵乘法；此外实现一个高性能的广义矩阵乘法算子相比其他算子（如矩阵转置）对开发者的编程能力和底层硬件架构要求更高。</p>
<div class="section" id="id2">
<h2><span class="section-number">8.4.1. </span>环境<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>本节的实践有以下的软件环境依赖：</p>
<ul class="simple">
<li><p>Eigen：Eigen是一个线性代数C++模板库，用户可以只使用几条语句完成多线程线性代数运算。</p></li>
<li><p>OpenMP（可选）：OpenMP是用于共享内存并行系统的多处理器程序设计的一套指导性编译处理方案，我们可以使用OpenMP对Eigen的计算进行加速。</p></li>
<li><p>CUDA Toolkit：CUDA
Toolkit是英伟达发布的CUDA工具包，其包含了CUDA编译器（NVCC），CUDA线性代数库（cuBLAS）等组件。
本节的实践都是在CPU Intex Xeon E5-2650 v3，GPU Nvidia Geforce RTX
3080；系统Ubuntu 18.04版本，CUDA Toolkit 11.1进行的。</p></li>
</ul>
<div class="section" id="id3">
<h3><span class="section-number">8.4.1.1. </span>安装<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Eigen：Eigen的安装可以通过使用包管理器安装（如使用指令<code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">libeigen3-dev</span></code>），也可以从<a class="reference external" href="https://eigen.tuxfamily.org/index.php?title=Main_Page">官网</a>下载。</p></li>
<li><p>OpenMP（可选）：通常会被大多数编译器默认支持，如果没有被支持的话可以使用包管理器安装（如使用指令<code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">libomp-dev</span></code>）。</p></li>
<li><p>CUDA Toolkit：CUDA
Toolkit的安装建议按照<a class="reference external" href="https://developer.nvidia.com/cuda-downloads">官方的提示</a>安装，也可以通过使用包管理器安装（如使用指令<code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">cuda</span></code>）。</p></li>
</ul>
</div>
</div>
<div class="section" id="sec-accelerator-naive">
<span id="id4"></span><h2><span class="section-number">8.4.2. </span>广义矩阵乘法的朴素实现<a class="headerlink" href="#sec-accelerator-naive" title="Permalink to this headline">¶</a></h2>
<p>广义矩阵乘法指GEMM（General Matrix
Multiplication），即<span class="math notranslate nohighlight">\(C = \alpha A\times B + \beta C\)</span>，其中<span class="math notranslate nohighlight">\(A\in\mathbb{R}^{M\times K}, B\in\mathbb{R}^{K\times N}, C\in\mathbb{R}^{M\times N}\)</span>。</p>
<p>矩阵<span class="math notranslate nohighlight">\(C\)</span>
的第<span class="math notranslate nohighlight">\(m\)</span>行第<span class="math notranslate nohighlight">\(n\)</span>列元素<span class="math notranslate nohighlight">\(C_{m, n}\)</span>
是由矩阵<span class="math notranslate nohighlight">\(A\)</span>中第<span class="math notranslate nohighlight">\(m\)</span>行<span class="math notranslate nohighlight">\(K\)</span>维向量和矩阵<span class="math notranslate nohighlight">\(B\)</span>中第<span class="math notranslate nohighlight">\(n\)</span>列<span class="math notranslate nohighlight">\(K\)</span>维向量的内积与<span class="math notranslate nohighlight">\(C_{m, n}\)</span>原始值加权求和得到的，因此在这种视角下的CPU代码为：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">float</span> <span class="n">A</span><span class="p">[</span><span class="n">M</span><span class="p">][</span><span class="n">K</span><span class="p">];</span>
<span class="kt">float</span> <span class="n">B</span><span class="p">[</span><span class="n">K</span><span class="p">][</span><span class="n">N</span><span class="p">];</span>
<span class="kt">float</span> <span class="n">C</span><span class="p">[</span><span class="n">M</span><span class="p">][</span><span class="n">N</span><span class="p">];</span>
<span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">;</span>

<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="n">M</span><span class="p">;</span> <span class="o">++</span><span class="n">m</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">float</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">K</span><span class="p">;</span> <span class="o">++</span><span class="n">k</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">c</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">n</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">c</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">C</span><span class="p">[</span><span class="n">m</span><span class="p">][</span><span class="n">n</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>因此可以看到，矩阵<span class="math notranslate nohighlight">\(C\)</span>
中各个元素的计算是独立的。我们可以利用GPU的大量线程去分别计算矩阵<span class="math notranslate nohighlight">\(C\)</span>
中相应的元素，以达到并行计算的目的，GPU核函数将如下所示：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gemmKernel</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">A</span><span class="p">,</span>
                           <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">C</span><span class="p">,</span>
                           <span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">float</span> <span class="n">beta</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">M</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">N</span><span class="p">,</span>
                           <span class="kt">unsigned</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">m</span> <span class="o">&gt;=</span> <span class="n">M</span> <span class="o">||</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="n">N</span><span class="p">)</span>
      <span class="k">return</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">K</span><span class="p">;</span> <span class="o">++</span><span class="n">k</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">c</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">m</span> <span class="o">*</span> <span class="n">K</span> <span class="o">+</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">n</span><span class="p">];</span>
  <span class="p">}</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">result</span> <span class="o">=</span> <span class="n">c</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span> <span class="n">C</span><span class="p">[</span><span class="n">m</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">beta</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">C</span><span class="p">[</span><span class="n">m</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>其可视化结构如
<a class="reference internal" href="#cuda-naive-gemm"><span class="std std-numref">图8.4.1</span></a>所示，矩阵<span class="math notranslate nohighlight">\(C\)</span>中每一个元素由一个线程计算，在GPU
Kernel的第5和6行计算该线程对应矩阵<span class="math notranslate nohighlight">\(C\)</span>中的元素行号<span class="math notranslate nohighlight">\(m\)</span>及列号<span class="math notranslate nohighlight">\(n\)</span>，然后在第9到11行该线程利用行号与列号读取矩阵<span class="math notranslate nohighlight">\(A\)</span>和矩阵<span class="math notranslate nohighlight">\(B\)</span>中相应的行列向量元素并计算向量内积，最后在第17行将结果写回<span class="math notranslate nohighlight">\(C\)</span>矩阵。</p>
<div class="figure align-default" id="id26">
<span id="cuda-naive-gemm"></span><a class="reference internal image-reference" href="../_images/naive.svg"><img alt="../_images/naive.svg" src="../_images/naive.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.1 </span><span class="caption-text">矩阵乘法的朴素实现</span><a class="headerlink" href="#id26" title="Permalink to this image">¶</a></p>
</div>
<p>使用以下代码启动核函数：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span> <span class="nf">gemmNaive</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span>
               <span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">float</span> <span class="n">beta</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">M</span><span class="p">,</span>
               <span class="kt">unsigned</span> <span class="n">N</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">dim3</span> <span class="n">block</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">);</span>
  <span class="n">dim3</span> <span class="n">grid</span><span class="p">((</span><span class="n">M</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">block</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>

  <span class="n">gemmKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>在这里我们令每个线程块处理矩阵<span class="math notranslate nohighlight">\(C\)</span>中<span class="math notranslate nohighlight">\(16\times16\)</span>个元素，因此我们开启<span class="math notranslate nohighlight">\((M - 1) / 16 + 1 \times (N - 1) / 16 + 1\)</span>个线程块用于计算整个矩阵<span class="math notranslate nohighlight">\(C\)</span>。</p>
<p>接下来我们生成数据并执行：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;Eigen/Core&gt;</span><span class="cp"></span>

<span class="k">using</span> <span class="k">namespace</span> <span class="n">Eigen</span><span class="p">;</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kt">unsigned</span> <span class="n">M</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">;</span>
  <span class="kt">float</span> <span class="o">*</span><span class="n">deviceAPrt</span><span class="p">,</span> <span class="o">*</span><span class="n">deviceBPtr</span><span class="p">,</span> <span class="o">*</span><span class="n">deviceCPtr</span><span class="p">;</span>
  <span class="n">Matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="n">Dynamic</span><span class="p">,</span> <span class="n">Dynamic</span><span class="p">,</span> <span class="n">RowMajor</span><span class="o">&gt;</span> <span class="n">A</span><span class="p">{</span><span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">},</span> <span class="n">B</span><span class="p">{</span><span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">},</span> <span class="n">C</span><span class="p">{</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">};</span>
  <span class="n">A</span><span class="p">.</span><span class="n">setRandom</span><span class="p">();</span>
  <span class="n">B</span><span class="p">.</span><span class="n">setRandom</span><span class="p">();</span>
  <span class="n">C</span><span class="p">.</span><span class="n">setRandom</span><span class="p">();</span>
  <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceAPrt</span><span class="p">,</span> <span class="n">M</span> <span class="o">*</span> <span class="n">K</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">deviceAPrt</span><span class="p">,</span> <span class="n">A</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">M</span> <span class="o">*</span> <span class="n">K</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
             <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
  <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceBPtr</span><span class="p">,</span> <span class="n">K</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">deviceBPtr</span><span class="p">,</span> <span class="n">B</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">K</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
             <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
  <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceCPtr</span><span class="p">,</span> <span class="n">M</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">deviceCPtr</span><span class="p">,</span> <span class="n">C</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">M</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
             <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
  <span class="n">gemmNaive</span><span class="p">(</span><span class="n">deviceAPrt</span><span class="p">,</span> <span class="n">deviceBPtr</span><span class="p">,</span> <span class="n">deviceCPtr</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
<p>我们在代码的第8到11行利用Eigen构建并初始化矩阵<span class="math notranslate nohighlight">\(A, B, C\)</span>。在代码的第12到20行分配GPU内存并将CPU数据拷贝到GPU端。最后我们在第21行执行函数并在22行等待该函数结束。</p>
<p>接下来我们需要对我们实现的GPU代码测速并验证其数值正确性。对GPU代码的测速我们使用<code class="docutils literal notranslate"><span class="pre">cudaEvent</span></code>，<code class="docutils literal notranslate"><span class="pre">cudaEvent</span></code>可以记录GPU端程序事务并用来计算两个事务之间的耗时，使用方法如下段代码：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">cudaEvent_t</span> <span class="n">startEvent</span><span class="p">,</span> <span class="n">stopEvent</span><span class="p">;</span>
<span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">startEvent</span><span class="p">);</span>
<span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stopEvent</span><span class="p">);</span>

<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">startEvent</span><span class="p">);</span>
<span class="n">gemmNaive</span><span class="p">(</span><span class="n">deviceAPrt</span><span class="p">,</span> <span class="n">deviceBPtr</span><span class="p">,</span> <span class="n">deviceCPtr</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">);</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">stopEvent</span><span class="p">);</span>

<span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">stopEvent</span><span class="p">);</span>
<span class="kt">float</span> <span class="n">milliseconds</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">cudaEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">milliseconds</span><span class="p">,</span> <span class="n">startEvent</span><span class="p">,</span> <span class="n">stopEvent</span><span class="p">);</span>
<span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average Time: %.3f ms</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">milliseconds</span><span class="p">);</span>

<span class="n">cudaEventDestroy</span><span class="p">(</span><span class="n">stopEvent</span><span class="p">);</span>
<span class="n">cudaEventDestroy</span><span class="p">(</span><span class="n">startEvent</span><span class="p">);</span>
</pre></div>
</div>
<p>具体地，我们首先声明类型为<code class="docutils literal notranslate"><span class="pre">cudaEvent_t</span></code>的变量，然后使用第2及第3行所示代码创建GPU事务，在待测的GPU代码起始时使用第5行的代码记录起始事务并在GPU代码结束后使用第7行的代码记录结束事务。通过使用第9到第12行代码计算两次事务间的时间差并打印，最后使用第12及第13行代码销毁GPU事务。</p>
<p>执行这段代码，得到输出结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">46.354</span> <span class="n">ms</span>
</pre></div>
</div>
<p>接下来我们实现数值验证的相关代码并计算CPU耗时：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;omp.h&gt;</span><span class="cp"></span>

<span class="c1">// ...</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// ...</span>
  <span class="n">Matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="n">Dynamic</span><span class="p">,</span> <span class="n">Dynamic</span><span class="p">,</span> <span class="n">RowMajor</span><span class="o">&gt;</span> <span class="n">hostResult</span><span class="p">{</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">},</span>
      <span class="n">deviceResult</span><span class="p">{</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">};</span>
  <span class="n">omp_set_num_threads</span><span class="p">(</span><span class="n">omp_get_num_procs</span><span class="p">());</span>
  <span class="kt">clock_t</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">;</span>
  <span class="n">begin</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
  <span class="n">hostResult</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">A</span> <span class="o">*</span> <span class="n">B</span><span class="p">)</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">C</span><span class="p">;</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">clock</span><span class="p">();</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average Time: %.3f ms</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="kt">double</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">begin</span><span class="p">)</span> <span class="o">/</span> <span class="n">CLOCKS_PER_SEC</span> <span class="o">*</span> <span class="mf">1e3</span><span class="p">);</span>
  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">deviceResult</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">deviceCPtr</span><span class="p">,</span> <span class="n">M</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
             <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

  <span class="n">Eigen</span><span class="o">::</span><span class="n">Array</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="n">Eigen</span><span class="o">::</span><span class="n">Dynamic</span><span class="p">,</span> <span class="n">Eigen</span><span class="o">::</span><span class="n">Dynamic</span><span class="o">&gt;</span> <span class="n">diffArray</span> <span class="o">=</span>
      <span class="p">(</span><span class="n">hostResult</span> <span class="o">-</span> <span class="n">deviceResult</span><span class="p">).</span><span class="n">array</span><span class="p">().</span><span class="n">abs</span><span class="p">();</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Max Error: %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">diffArray</span><span class="p">.</span><span class="n">maxCoeff</span><span class="p">());</span>
<span class="p">}</span>
</pre></div>
</div>
<p>我们在第9到14行使用CPU计算结果并计时，在第15行将GPU计算的结果拷贝到CPU内存中，在第19到21行计算误差并打印。值得注意的是我们在第9行使用了OpenMP以启用CPU多线程计算一般矩阵乘法。</p>
<p>完整代码在<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/first_attempt.cu">first_attempt.cu</a>中，编译及执行指令如下：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir build <span class="o">&amp;&amp;</span> <span class="nb">cd</span> build
cmake ..
make first_attempt
./first_attempt
</pre></div>
</div>
<p>输出结果为：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">48.961</span> <span class="n">ms</span>
<span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
</pre></div>
</div>
<p>我们可以使用以下公式粗略的计算GPU的峰值吞吐量：2<span class="math notranslate nohighlight">\(\times\)</span>频率<span class="math notranslate nohighlight">\(\times\)</span>单精度计算单元数量
，其中单精度计算单元数量等于GPU中流多处理器（SM）数量乘每个流多处理器中单精度计算单元数量；并用以下公式粗略的计算我们代码的吞吐量：2<span class="math notranslate nohighlight">\(\times\)</span>数据量<span class="math notranslate nohighlight">\(\div\)</span>时间：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">// ...</span>
  <span class="kt">int</span> <span class="n">gpu_rank</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="n">cudaDeviceProp</span> <span class="n">deviceProp</span><span class="p">{};</span>
  <span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">deviceProp</span><span class="p">,</span> <span class="n">gpu_rank</span><span class="p">);</span>
  <span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">gpu_rank</span><span class="p">);</span>
  <span class="kt">double</span> <span class="n">boostFrequency</span> <span class="o">=</span> <span class="n">deviceProp</span><span class="p">.</span><span class="n">clockRate</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">;</span>
  <span class="n">int1</span> <span class="n">fp32CoresNum</span> <span class="o">=</span> <span class="mi">128</span><span class="p">;</span>
  <span class="kt">double</span> <span class="n">peakPerformance</span> <span class="o">=</span> <span class="n">boostFrequency</span> <span class="o">*</span> <span class="n">fp32CoresNum</span> <span class="o">*</span> <span class="mi">2</span><span class="p">;</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">&quot;FP32 peak throughput %.3f GFLOPS</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">peakPerformance</span><span class="p">);</span>
  <span class="kt">double</span> <span class="n">GFLOPS</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="mf">1e-9</span> <span class="o">*</span> <span class="n">M</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="n">K</span> <span class="o">/</span> <span class="p">(</span><span class="n">milliseconds</span> <span class="o">*</span> <span class="mf">1e-3</span><span class="p">);</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Average Throughput: %.3f GFLOPS</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">GFLOPS</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>执行可以输出：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FP32</span> <span class="n">peak</span> <span class="n">throughput</span> <span class="mf">29767.680</span> <span class="n">GFLOPS</span>
<span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">185.313</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>可以发现目前的代码距离设备峰值性能仍有较大的差距。在整个计算过程中计算密集最大的过程为矩阵乘法<span class="math notranslate nohighlight">\(A\times B\)</span>，其时间复杂度为<span class="math notranslate nohighlight">\(O(M*N*K)\)</span>，而整个计算过程时间复杂度为<span class="math notranslate nohighlight">\(O(M*N*K+2*M*N)\)</span>，因此对矩阵乘法的优化是提升性能的关键。</p>
<div class="section" id="id5">
<h3><span class="section-number">8.4.2.1. </span>使用封装结构代替指针<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>在上面的实现中，由于二维矩阵的数据是使用一维数组进行存储，所以在访问数据时需要使用行坐标与二维矩阵宽度的乘积和列坐标的和来索引到具体位置的元素，这样的访问方式并不直观且在后续逐渐复杂的实现中容易出错。因此，我们可以自定义一个结构体，通过重载
<code class="docutils literal notranslate"><span class="pre">()</span></code> 运算符，实现对矩阵元素的二维索引，同时我们提供 <code class="docutils literal notranslate"><span class="pre">addOffset</span></code>
方法用于加入一个固定的偏移，具体实现如下：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
<span class="k">struct</span> <span class="n">__device_builtin__</span> <span class="n">Tensor2D</span> <span class="p">{</span>
  <span class="n">T</span> <span class="o">*</span><span class="k">const</span> <span class="n">__restrict__</span> <span class="n">ptr</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">unsigned</span> <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">_rowOffset</span><span class="p">{</span><span class="mi">0</span><span class="p">},</span> <span class="n">_colOffset</span><span class="p">{</span><span class="mi">0</span><span class="p">};</span>

  <span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">t</span><span class="o">&gt;</span>
  <span class="n">__host__</span> <span class="n">__device__</span> <span class="n">Tensor2D</span><span class="p">(</span><span class="n">t</span> <span class="o">&amp;&amp;</span><span class="n">ptr</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">rows</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">cols</span><span class="p">)</span>
      <span class="o">:</span> <span class="n">ptr</span><span class="p">{</span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="n">T</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">ptr</span><span class="p">)},</span> <span class="n">rows</span><span class="p">{</span><span class="n">rows</span><span class="p">},</span> <span class="n">cols</span><span class="p">{</span><span class="n">cols</span><span class="p">}</span> <span class="p">{};</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="n">T</span> <span class="o">&amp;</span><span class="k">operator</span><span class="p">()(</span><span class="kt">unsigned</span> <span class="n">row</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">col</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">ptr</span><span class="p">[</span><span class="n">_colOffset</span> <span class="o">+</span> <span class="n">col</span> <span class="o">+</span> <span class="p">(</span><span class="n">row</span> <span class="o">+</span> <span class="n">_rowOffset</span><span class="p">)</span> <span class="o">*</span> <span class="n">cols</span><span class="p">];</span>
  <span class="p">}</span>

  <span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="o">&gt;</span>
  <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">void</span> <span class="n">addOffset</span><span class="p">(</span><span class="kt">int</span> <span class="n">rowOffset</span><span class="p">,</span> <span class="kt">int</span> <span class="n">colOffset</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">_rowOffset</span> <span class="o">+=</span> <span class="n">rowOffset</span><span class="p">;</span>
    <span class="n">_colOffset</span> <span class="o">+=</span> <span class="n">colOffset</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>另外，我们在读取数据数据之前需要对偏移判断是否越界，因此我们增加以下方法：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
<span class="k">struct</span> <span class="n">__device_builtin__</span> <span class="n">Tensor2D</span> <span class="p">{</span>
  <span class="c1">// ...</span>
  <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">bool</span> <span class="n">validRowOffset</span><span class="p">(</span><span class="kt">int</span> <span class="n">rowOffset</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">_rowOffset</span> <span class="o">+</span> <span class="n">rowOffset</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">rows</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">bool</span> <span class="n">validColOffset</span><span class="p">(</span><span class="kt">int</span> <span class="n">colOffset</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">_colOffset</span> <span class="o">+</span> <span class="n">colOffset</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">bool</span> <span class="n">validOffset</span><span class="p">(</span><span class="kt">int</span> <span class="n">rowOffset</span><span class="p">,</span>
                                       <span class="kt">int</span> <span class="n">colOffset</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">validRowOffset</span><span class="p">(</span><span class="n">rowOffset</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">validColOffset</span><span class="p">(</span><span class="n">colOffset</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>完整代码在<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/util.cuh">util.cuh</a>。
最终，我们可以将GPU核函数改写为以下形式：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gemmKernel</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">A</span><span class="p">,</span>
                           <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span> <span class="n">C</span><span class="p">,</span>
                           <span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">float</span> <span class="n">beta</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">M</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">N</span><span class="p">,</span>
                           <span class="kt">unsigned</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="n">Tensor2D</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">float</span><span class="o">&gt;</span> <span class="n">tensorA</span><span class="p">{</span><span class="n">A</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">};</span>
  <span class="n">Tensor2D</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">float</span><span class="o">&gt;</span> <span class="n">tensorB</span><span class="p">{</span><span class="n">B</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">};</span>
  <span class="n">Tensor2D</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span> <span class="n">tensorC</span><span class="p">{</span><span class="n">C</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">};</span>
  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">tensorC</span><span class="p">.</span><span class="n">validOffset</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span> <span class="k">return</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">K</span><span class="p">;</span> <span class="o">++</span><span class="n">k</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">c</span> <span class="o">+=</span> <span class="n">tensorA</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">*</span> <span class="n">tensorB</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="n">c</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">result</span> <span class="o">=</span> <span class="n">c</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span> <span class="n">tensorC</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">beta</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">tensorC</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id6">
<h2><span class="section-number">8.4.3. </span>提高计算强度<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>计算强度（Compute
Intensity）指计算指令数量与访存指令数量的比值，在现代GPU中往往有大量计算单元但只有有限的访存带宽，程序很容易出现计算单元等待数据读取的问题，因此提高计算强度是提升程序性能的一条切实有限的指导思路。对于之前实现的GPU核函数，我们可以粗略计算其计算强度：在<span class="math notranslate nohighlight">\(K\)</span>次循环的内积计算中，对矩阵<span class="math notranslate nohighlight">\(A\)</span>与矩阵<span class="math notranslate nohighlight">\(B\)</span>的每次读取会计算一次浮点乘法与浮点加法，因此计算强度为1——两次浮点运算除以两次数据读取。之前的版本是每个线程负责处理矩阵<span class="math notranslate nohighlight">\(C\)</span>的一个元素——计算矩阵﻿﻿<span class="math notranslate nohighlight">\(A\)</span>的一行与矩阵<span class="math notranslate nohighlight">\(B\)</span>的一列的内积，我们可以通过使每个线程计算<span class="math notranslate nohighlight">\(C\)</span>更多的元素——计算矩阵<span class="math notranslate nohighlight">\(A\)</span>的多行与矩阵<span class="math notranslate nohighlight">\(B\)</span>的多列的内积——从而提升计算强度。具体地，如果在<span class="math notranslate nohighlight">\(K\)</span>次循环的内积计算中一次读取矩阵<span class="math notranslate nohighlight">\(A\)</span>中的<span class="math notranslate nohighlight">\(m\)</span>个元素和矩阵<span class="math notranslate nohighlight">\(B\)</span>中的<span class="math notranslate nohighlight">\(n\)</span>个元素，那么访存指令为<span class="math notranslate nohighlight">\(m+n\)</span>条，而计算指令为<span class="math notranslate nohighlight">\(2mn\)</span>条，所以计算强度为<span class="math notranslate nohighlight">\(\frac{2mn}{m+n}\)</span>，因此可以很容易发现提高<span class="math notranslate nohighlight">\(m\)</span>和<span class="math notranslate nohighlight">\(n\)</span>会带来计算强度的提升。</p>
<p>我们在上一个代码例子中对全局内存的访问与存储都是借助 <code class="docutils literal notranslate"><span class="pre">float</span></code>
指针完成的，具体到硬件指令集上实际是使用指令 <code class="docutils literal notranslate"><span class="pre">LDG.E</span></code> 与 <code class="docutils literal notranslate"><span class="pre">STG.E</span></code>
完成的。我们可以使用128位宽指令<code class="docutils literal notranslate"><span class="pre">LDG.E.128</span></code> 与 <code class="docutils literal notranslate"><span class="pre">STG.E.128</span></code>
一次读取多个 <code class="docutils literal notranslate"><span class="pre">float</span></code>
数。使用宽指令的好处是一方面简化了指令序列，使用一个宽指令代替四个标准指令可以节省十几个指令的发射周期，这可以为计算指令的发射争取到额外的时间；另一方面128比特正好等于一个cache
line的长度，使用宽指令也有助于提高cache
line的命中率。但我们并不提倡在一切代码中过度追求宽指令的使用，开发者应当将更多的时间关注并行性设计和局部数据复用等更直接的优化手段。</p>
<p>具体的实现如下，由于每个 <code class="docutils literal notranslate"><span class="pre">float</span></code> 类型大小为32个比特，我们可以将4个
<code class="docutils literal notranslate"><span class="pre">float</span></code> 堆叠在一起构成一个128比特的 <code class="docutils literal notranslate"><span class="pre">float4</span></code> 类，对 <code class="docutils literal notranslate"><span class="pre">float4</span></code>
的访存将会是使用宽指令完成。虽然CUDA Toolkit已经有实现的 <code class="docutils literal notranslate"><span class="pre">float4</span></code>
类，但是为了代码抽象我们将自行实现我们自己的 <code class="docutils literal notranslate"><span class="pre">float4</span></code> 类。</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span> <span class="n">__device_builtin__</span> <span class="nf">__builtin_align__</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span> <span class="n">float4</span> <span class="p">{</span>
  <span class="kt">float</span> <span class="n">data</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">float</span> <span class="k">operator</span><span class="p">[](</span><span class="kt">unsigned</span> <span class="n">idx</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span> <span class="p">}</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="kt">float</span> <span class="o">&amp;</span><span class="k">operator</span><span class="p">[](</span><span class="kt">unsigned</span> <span class="n">idx</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span> <span class="p">}</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="n">float4</span> <span class="k">operator</span><span class="o">*</span><span class="p">(</span><span class="kt">float</span> <span class="n">other</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">float4</span><span class="p">{</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">other</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">other</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">other</span><span class="p">,</span>
                  <span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">other</span><span class="p">};</span>
  <span class="p">}</span>

  <span class="n">__host__</span> <span class="n">__device__</span> <span class="n">float4</span> <span class="k">operator</span><span class="o">+</span><span class="p">(</span><span class="k">const</span> <span class="n">float4</span> <span class="o">&amp;</span><span class="n">other</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">float4</span><span class="p">{</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">other</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">other</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">other</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="n">other</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">3</span><span class="p">]};</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>我们重载了<code class="docutils literal notranslate"><span class="pre">[]</span></code>运算符，从而可以通过索引访问<code class="docutils literal notranslate"><span class="pre">float4</span></code>
内部元素。此外我们定义了 <code class="docutils literal notranslate"><span class="pre">float4</span></code> 与 <code class="docutils literal notranslate"><span class="pre">float</span></code> 乘法及 <code class="docutils literal notranslate"><span class="pre">float4</span></code> 与
<code class="docutils literal notranslate"><span class="pre">float4</span></code>
加法的实现，方便对后续代码抽象。完整代码在<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/util.cuh">util.cuh</a>中。</p>
<p>在实现GPU核函数过程中要注意，每个线程需要从原本各读取矩阵<span class="math notranslate nohighlight">\(A\)</span>和矩阵<span class="math notranslate nohighlight">\(B\)</span>中一个
<code class="docutils literal notranslate"><span class="pre">float</span></code> 数据变为各读取4个 <code class="docutils literal notranslate"><span class="pre">float</span></code>
数据，这就要求现在每个线程负责处理矩阵<span class="math notranslate nohighlight">\(C\)</span>中<span class="math notranslate nohighlight">\(4\times 4\)</span>的矩阵块，我们称之为
<code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code> 。相应的GPU核函数应为以下形式：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gemmKernel</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">A</span><span class="p">,</span>
                           <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">C</span><span class="p">,</span>
                           <span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">float</span> <span class="n">beta</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">M</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">N</span><span class="p">,</span>
                           <span class="kt">unsigned</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">ratio</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">float4</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">;</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">;</span>
  <span class="n">Tensor2D</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">float</span><span class="o">&gt;</span> <span class="n">tensorA</span><span class="p">{</span><span class="n">A</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">};</span>
  <span class="n">tensorA</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
  <span class="n">Tensor2D</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">float4</span><span class="o">&gt;</span> <span class="n">tensorB</span><span class="p">{</span><span class="n">B</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">};</span>
  <span class="n">tensorB</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">);</span>
  <span class="n">Tensor2D</span><span class="o">&lt;</span><span class="n">float4</span><span class="o">&gt;</span> <span class="n">tensorC</span><span class="p">{</span><span class="n">C</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">N</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">};</span>
  <span class="n">tensorC</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">);</span>
  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">tensorC</span><span class="p">.</span><span class="n">validOffset</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="k">return</span><span class="p">;</span>

  <span class="n">float4</span> <span class="n">c</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
  <span class="n">memset</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">c</span><span class="p">));</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">K</span><span class="p">;</span> <span class="o">++</span><span class="n">k</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">float4</span> <span class="n">fragmentA</span><span class="p">{};</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ratio</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">fragmentA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensorA</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">float4</span> <span class="n">fragmentB</span> <span class="o">=</span> <span class="n">tensorB</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ratio</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">fragmentB</span> <span class="o">*</span> <span class="n">fragmentA</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="nl">term</span> <span class="p">:</span> <span class="n">c</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">term</span> <span class="o">=</span> <span class="n">term</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ratio</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">float4</span> <span class="n">result</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">tensorC</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">beta</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">tensorC</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>我们首先在第6到14行计算每个线程需要处理的数据块在矩阵中的起始行列坐标<code class="docutils literal notranslate"><span class="pre">m,n</span></code>，即
<a class="reference internal" href="#use-float4"><span class="std std-numref">图8.4.2</span></a>
中矩阵<span class="math notranslate nohighlight">\(C\)</span>中浅绿色数据块的左上角坐标，然后使用<code class="docutils literal notranslate"><span class="pre">Tensor2D</span></code>中的<code class="docutils literal notranslate"><span class="pre">addOffset</span></code>方法，为每个线程定位到它要处理的数据块的起始位置上，并且利用<code class="docutils literal notranslate"><span class="pre">validOffset</span></code>方法判断线程是否越界。然后就可以沿着K方向循环，在第18到23行每个线程分别读取矩阵<span class="math notranslate nohighlight">\(A\)</span>中连续的4行和矩阵<span class="math notranslate nohighlight">\(B\)</span>中连续的四列组成两个
<code class="docutils literal notranslate"><span class="pre">float4</span></code> ，即 <a class="reference internal" href="#use-float4"><span class="std std-numref">图8.4.2</span></a>
中粉色与黄色的四个元素。之后在第25到27行计算线程负责处理矩阵<span class="math notranslate nohighlight">\(C\)</span>中的<span class="math notranslate nohighlight">\(4 \times 4\)</span>个元素。最后在第30到40行对结果使用参数
<code class="docutils literal notranslate"><span class="pre">alpha</span></code> 和 <code class="docutils literal notranslate"><span class="pre">beta</span></code> 进行放缩并写回矩阵<span class="math notranslate nohighlight">\(C\)</span>的内存。</p>
<div class="figure align-default" id="id27">
<span id="use-float4"></span><a class="reference internal image-reference" href="../_images/use_float4.svg"><img alt="../_images/use_float4.svg" src="../_images/use_float4.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.2 </span><span class="caption-text">提高计算强度</span><a class="headerlink" href="#id27" title="Permalink to this image">¶</a></p>
</div>
<p>为了将尺寸数据在编译期确定，减少执行期的额外数据读取开销，我们引入一个新的模板类
<code class="docutils literal notranslate"><span class="pre">Layout</span></code> ，这个类保存各种尺寸数据。其实现代码如下：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="kt">int</span> <span class="n">_m</span><span class="p">,</span> <span class="kt">int</span> <span class="n">_n</span><span class="p">,</span> <span class="kt">int</span> <span class="n">_k</span> <span class="o">=</span> <span class="mi">1</span><span class="o">&gt;</span>
<span class="k">struct</span> <span class="n">Layout</span> <span class="p">{</span>
 <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="n">_m</span><span class="p">;</span>
 <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">_n</span><span class="p">;</span>
 <span class="k">static</span> <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="n">_k</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p>对上述代码稍加修改便可使用这个新的特性：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">LayoutTile</span><span class="o">&gt;</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="n">gemmKernel</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">A</span><span class="p">,</span>
                           <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">C</span><span class="p">,</span>
                           <span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">float</span> <span class="n">beta</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">M</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">N</span><span class="p">,</span>
                           <span class="kt">unsigned</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">ratio</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">float4</span><span class="p">)</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">;</span>
  <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">n</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">;</span>
  <span class="c1">// ...</span>
<span class="p">}</span>
</pre></div>
</div>
<p>同时在启动时使用新修改的模板函数来启动GPU核函数：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">LayoutTile</span> <span class="o">=</span> <span class="n">Layout</span><span class="o">&lt;</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">4</span><span class="o">&gt;</span><span class="p">;</span>

<span class="n">gemmKernel</span><span class="o">&lt;</span><span class="n">LayoutTile</span><span class="o">&gt;&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">deviceAPtr</span><span class="p">,</span> <span class="n">deviceBPtr</span><span class="p">,</span> <span class="n">deviceCPtr</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span>
                             <span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">);</span>
</pre></div>
</div>
<p>完整代码见<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/gemm_use_128.cu">gemm_use_128.cu</a>。</p>
<div class="section" id="id7">
<h3><span class="section-number">8.4.3.1. </span>测试及分析<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">6.232</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">1378.317</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>接下来我们使用分析工具Nsight Compute分析取得性能提升的具体原因。Nsight
Compute是英伟达发布的主要针对GPU核函数的性能分析工具，它通过劫持驱动的方式对GPU底层数据采样和输出。可以使用以下指令进行性能分析：</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ncu --set full -o &lt;profile_output_file&gt; &lt;profile_process&gt;
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">--set</span> <span class="pre">full</span></code> 代表采样所有数据， <code class="docutils literal notranslate"><span class="pre">-o</span></code> 代表以文件的形式输出结果；
<code class="docutils literal notranslate"><span class="pre">&lt;profile_output_file&gt;</span></code> 填输出文件名但注意不要加后缀名，
<code class="docutils literal notranslate"><span class="pre">&lt;profile_process&gt;</span></code> 填待分析的可执行文件及其参数。 比如我们需要分析
<code class="docutils literal notranslate"><span class="pre">first_attempt</span></code> ，将输出结果命名为 <code class="docutils literal notranslate"><span class="pre">first_attepmt_prof_result</span></code>
我们可以使用以下指令：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">ncu</span> <span class="o">--</span><span class="n">set</span> <span class="n">full</span> <span class="o">-</span><span class="n">o</span> <span class="n">first_attepmt_prof_result</span> <span class="p">.</span><span class="o">/</span><span class="n">first_attempt</span>
</pre></div>
</div>
<p>如果提示权限不足可以使在指令前加<code class="docutils literal notranslate"><span class="pre">sudo</span></code> 。
在得到输出文件之后，我们可以使用 <code class="docutils literal notranslate"><span class="pre">nv-nsight-cu</span></code>
查看文件。我们对我们改动的GPU核函数与上一版本的GPU核函数进行对比分析，发现：</p>
<p>首先 <code class="docutils literal notranslate"><span class="pre">LDG</span></code> 指令数量下降了84%，且指标 <code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">LG</span> <span class="pre">Throttle</span></code>
下降33%，说明使用宽指令增加计算密度确实可以通过减少全局内存访问的指令数目而减少发射等待时间。最后指标
<code class="docutils literal notranslate"><span class="pre">Arithmetic</span> <span class="pre">Intensity</span></code> 的提升也和我们之前的关于计算强度的分析相吻合。</p>
</div>
</div>
<div class="section" id="id8">
<h2><span class="section-number">8.4.4. </span>进一步提升计算强度<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>我们可以通过使每个线程负责处理更多的矩阵<span class="math notranslate nohighlight">\(C\)</span>中的数据块从而实现更高的计算强度，即如
<a class="reference internal" href="#use-tile"><span class="std std-numref">图8.4.3</span></a> 右侧所示，使 <code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code>
扩大为4个<span class="math notranslate nohighlight">\(4 \times 4\)</span>矩阵的规模。我们对核函数进行以下修改，首先我们用<code class="docutils literal notranslate"><span class="pre">LayoutTile</span></code>
来描述每个线程块处理数据 <code class="docutils literal notranslate"><span class="pre">tile</span></code>的布局 ，其中 <code class="docutils literal notranslate"><span class="pre">LayoutTile::m</span></code> 和
<code class="docutils literal notranslate"><span class="pre">LayoutTile::n</span></code> 等于 <a class="reference internal" href="#use-tile"><span class="std std-numref">图8.4.3</span></a>
左图中浅绿色矩阵块的高度和宽度， <code class="docutils literal notranslate"><span class="pre">LayoutTile::k</span></code>
等于1；其次我们用<code class="docutils literal notranslate"><span class="pre">LayoutBlock</span></code>
来描述一个线程块中线程的布局；同时我们用<code class="docutils literal notranslate"><span class="pre">LayoutThread</span></code> 来描述
<code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code> 中子矩阵的布局 ，其中<code class="docutils literal notranslate"><span class="pre">LayoutThread::m</span></code> 和
<code class="docutils literal notranslate"><span class="pre">LayoutThread::n</span></code> 等于 <a class="reference internal" href="#use-tile"><span class="std std-numref">图8.4.3</span></a>
右图中深绿色矩阵块的高度和宽度 。</p>
<div class="figure align-default" id="id28">
<span id="id9"></span><span id="use-tile"></span><a class="reference internal image-reference" href="../_images/use_tile.svg"><img alt="../_images/use_tile.svg" src="../_images/use_tile.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.3 </span><span class="caption-text">通过提高线程所处理矩阵块的数量来进一步提高计算强度</span><a class="headerlink" href="#id28" title="Permalink to this image">¶</a></p>
</div>
<p>首先修改核函数签名：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">LayoutTile</span><span class="p">,</span> <span class="k">typename</span> <span class="n">LayoutBlock</span><span class="p">,</span> <span class="k">typename</span> <span class="n">LayoutThread</span><span class="o">&gt;</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="n">gemmKernel</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">A</span><span class="p">,</span>
                          <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">__restrict__</span> <span class="n">C</span><span class="p">,</span>
                          <span class="kt">float</span> <span class="n">alpha</span><span class="p">,</span> <span class="kt">float</span> <span class="n">beta</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">M</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="n">N</span><span class="p">,</span>
                          <span class="kt">unsigned</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// ...</span>
<span class="p">}</span>
</pre></div>
</div>
<p>然后改写线程负责处理数据的偏移量，即图3左图中的行列偏移值 <code class="docutils literal notranslate"><span class="pre">m</span></code> 和 <code class="docutils literal notranslate"><span class="pre">n</span></code>
，其代码实现如下 ：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">unsigned</span> <span class="n">m</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span> <span class="o">+</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="kt">unsigned</span> <span class="n">n</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">n</span> <span class="o">+</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">n</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</pre></div>
</div>
<p>由于每个线程从原来的处理一个数据块变为多个数据块，我们需要以下几个变量：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">const</span> <span class="kt">unsigned</span> <span class="n">iterationA</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">iterationB</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">n</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">intervalA</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">iterationA</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">intervalB</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">iterationB</span><span class="p">;</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">iterationA</span></code> 是每个线程处理 <code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code>
在行方向上迭代的次数。<code class="docutils literal notranslate"><span class="pre">intervalA</span></code> 是 <code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code>
子矩阵在行方向的间隔。同理 <code class="docutils literal notranslate"><span class="pre">iterationB</span></code> 与 <code class="docutils literal notranslate"><span class="pre">intervalB</span></code>
是在列方向上数据块的数量与数据块的间隔。 因为 <code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code>
扩大为若干个矩阵块，我们使用以下代码用来记录每个矩阵块是否越界：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">bool</span> <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">iterationA</span><span class="p">];</span>
<span class="kt">bool</span> <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">iterationB</span><span class="p">];</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">iterationA</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pA</span><span class="p">.</span><span class="n">validRowOffset</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">intervalA</span><span class="p">);</span>
<span class="p">}</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">iterationB</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pB</span><span class="p">.</span><span class="n">validColOffset</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">intervalB</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>对于数据的读取和累加计算相应的需要增加循环：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">constexpr</span> <span class="n">float4</span> <span class="n">float4Zero</span><span class="p">{</span><span class="mf">0.f</span><span class="p">,</span> <span class="mf">0.f</span><span class="p">,</span> <span class="mf">0.f</span><span class="p">,</span> <span class="mf">0.f</span><span class="p">};</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="n">K</span><span class="p">;</span> <span class="o">++</span><span class="n">k</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">iterA</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iterA</span> <span class="o">&lt;</span> <span class="n">iterationA</span><span class="p">;</span> <span class="o">++</span><span class="n">iterA</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">float4</span> <span class="n">fragmentA</span><span class="p">{};</span>
    <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">iterA</span><span class="p">]</span> <span class="o">&amp;=</span> <span class="n">pA</span><span class="p">.</span><span class="n">validColOffset</span><span class="p">(</span><span class="n">k</span><span class="p">);</span>
<span class="cp">#pragma unroll</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ratio</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">fragmentA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">?</span> <span class="n">pA</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">iterA</span> <span class="o">*</span> <span class="n">intervalA</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">:</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>
<span class="cp">#pragma unroll</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">iterB</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iterB</span> <span class="o">&lt;</span> <span class="n">iterationB</span><span class="p">;</span> <span class="o">++</span><span class="n">iterB</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">iterB</span><span class="p">]</span> <span class="o">&amp;=</span> <span class="n">pB</span><span class="p">.</span><span class="n">validRowOffset</span><span class="p">(</span><span class="n">k</span><span class="p">);</span>
      <span class="n">float4</span> <span class="n">fragmentB</span> <span class="o">=</span> <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">iterB</span><span class="p">]</span>
                             <span class="o">?</span> <span class="n">pB</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">iterB</span> <span class="o">*</span> <span class="n">intervalB</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">)</span>
                             <span class="o">:</span> <span class="n">float4Zero</span><span class="p">;</span>
<span class="cp">#pragma unroll</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ratio</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">c</span><span class="p">[</span><span class="n">iterA</span><span class="p">][</span><span class="n">iterB</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">iterA</span><span class="p">][</span><span class="n">iterB</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">fragmentB</span> <span class="o">*</span> <span class="n">fragmentA</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>注意到我们此时使用了编译器指令 <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">unroll</span></code>
用于将循环展开，即如果循环次数是可以在编译时确定的话，编译器将会把带有判断和跳转的循环代码展开成串行代码。这样做的好处主要是减少了判断语句，此外还有利于编译器发现数据依赖从而更好地分配寄存器。缺点是可能会增加寄存器的使用，有潜在的降低GPU占用率的风险。
最后对于结果使用 <code class="docutils literal notranslate"><span class="pre">alpha</span></code> 和 <code class="docutils literal notranslate"><span class="pre">beta</span></code>
的放缩以及写回也相应的加上数据块的循环：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="nl">termA</span> <span class="p">:</span> <span class="n">c</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="nl">termB</span> <span class="p">:</span> <span class="n">termA</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
   <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="nl">term</span> <span class="p">:</span> <span class="n">termB</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">term</span> <span class="o">=</span> <span class="n">term</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span>
   <span class="p">}</span>
 <span class="p">}</span>
<span class="p">}</span>

<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">iterA</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iterA</span> <span class="o">&lt;</span> <span class="n">iterationA</span><span class="p">;</span> <span class="o">++</span><span class="n">iterA</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">iterB</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iterB</span> <span class="o">&lt;</span> <span class="n">iterationB</span><span class="p">;</span> <span class="o">++</span><span class="n">iterB</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ratio</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">float4</span> <span class="n">result</span><span class="p">{</span><span class="n">c</span><span class="p">[</span><span class="n">iterA</span><span class="p">][</span><span class="n">iterB</span><span class="p">][</span><span class="n">i</span><span class="p">]};</span>
     <span class="k">if</span> <span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
       <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span>
                <span class="n">pC</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">iterA</span> <span class="o">*</span> <span class="n">intervalA</span><span class="p">,</span> <span class="n">iterB</span> <span class="o">*</span> <span class="n">intervalB</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">)</span> <span class="o">*</span> <span class="n">beta</span><span class="p">;</span>
     <span class="p">}</span>
     <span class="n">pC</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">iterA</span> <span class="o">*</span> <span class="n">intervalA</span><span class="p">,</span> <span class="n">iterB</span> <span class="o">*</span> <span class="n">intervalB</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">)</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
   <span class="p">}</span>
 <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>完整代码见<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/gemm_use_tile.cu">gemm_use_tile.cu</a>。</p>
<div class="section" id="id10">
<h3><span class="section-number">8.4.4.1. </span>测试及分析<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">3.188</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">2694.440</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>使用Nsight Compute分析发现：类似地，本次优化在<code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">LG</span> <span class="pre">Throttle</span></code>
等指标上取得了进一步的提升。</p>
</div>
</div>
<div class="section" id="sec-accelerator-use-smem">
<span id="id11"></span><h2><span class="section-number">8.4.5. </span>使用共享内存缓存复用数据<a class="headerlink" href="#sec-accelerator-use-smem" title="Permalink to this headline">¶</a></h2>
<p>虽然令一个线程一次读取更多的数据能取得计算强度的提升进而带来性能的提升，但是这种令单个线程处理数据增多的设计会导致开启总的线程数量减少，进而导致并行度下降，因此我们需要使用其他硬件特性在尽可能不影响并行度的前提下取得性能提升。在之前的代码中，我们开启若干个线程块，每个线程块处理矩阵<span class="math notranslate nohighlight">\(C\)</span>中的一个或多个矩阵块。在
<a class="reference internal" href="#duplicated-data"><span class="std std-numref">图8.4.4</span></a>
中，我们可以观察到，处理矩阵<span class="math notranslate nohighlight">\(C\)</span>同一行的线程<span class="math notranslate nohighlight">\(x, y\)</span>会读取矩阵<span class="math notranslate nohighlight">\(A\)</span>中相同的数据，我们可以借助共享内存让同一个线程块中不同的线程读取不重复的数据而提升程序吞吐量。</p>
<div class="figure align-default" id="id29">
<span id="duplicated-data"></span><a class="reference internal image-reference" href="../_images/duplicated_data.svg"><img alt="../_images/duplicated_data.svg" src="../_images/duplicated_data.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.4 </span><span class="caption-text">线程间重复读取数据</span><a class="headerlink" href="#id29" title="Permalink to this image">¶</a></p>
</div>
<p>具体地，我们需要对代码进行如下改造：首先此前代码在计算内积过程是进行<span class="math notranslate nohighlight">\(K\)</span>次循环读取数据并累加计算，在此设定下每次循环中处理矩阵<span class="math notranslate nohighlight">\(C\)</span>中相同行的线程会读取相同的矩阵<span class="math notranslate nohighlight">\(A\)</span>的数据，处理矩阵<span class="math notranslate nohighlight">\(C\)</span>中相同列的线程会读取相同的矩阵<span class="math notranslate nohighlight">\(B\)</span>的数据。我们可以通过将此<span class="math notranslate nohighlight">\(K\)</span>次循环拆解成两层循环，外层循环<span class="math notranslate nohighlight">\(\frac{K}{tileK}\)</span>次，每次外循环的迭代读取一整块数据，内层循环<span class="math notranslate nohighlight">\(tileK\)</span>次进行累加数据。直观来看，外层循环如
<a class="reference internal" href="#use-smem-store"><span class="std std-numref">图8.4.5</span></a>
所示，每次循环将矩阵<span class="math notranslate nohighlight">\(A\)</span>和矩阵<span class="math notranslate nohighlight">\(B\)</span>中一整个 <code class="docutils literal notranslate"><span class="pre">tile</span></code>
读取到共享内存中；内层循环如 <a class="reference internal" href="#use-smem-load"><span class="std std-numref">图8.4.6</span></a>
所示，每次循环从共享内存读取数据并计算。这种设计带来的好处是，我们可以让每个线程不必独自从全局内存读取所有需要的数据，整个线程块将共同需要的数据从全局内存中读取并写入到共享内存中，此后每个线程在计算过程中只需要从共享内存中读取所需要的数据即可。</p>
<div class="figure align-default" id="id30">
<span id="use-smem-store"></span><a class="reference internal image-reference" href="../_images/use_smem_store.svg"><img alt="../_images/use_smem_store.svg" src="../_images/use_smem_store.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.5 </span><span class="caption-text">向共享内存中写入数据</span><a class="headerlink" href="#id30" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id31">
<span id="id12"></span><span id="use-smem-load"></span><a class="reference internal image-reference" href="../_images/use_smem_load.svg"><img alt="../_images/use_smem_load.svg" src="../_images/use_smem_load.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.6 </span><span class="caption-text">从共享内存中读取数据</span><a class="headerlink" href="#id31" title="Permalink to this image">¶</a></p>
</div>
<p>下面我们将实现使用共享内存的GPU核函数。首先，我们定义每个线程块在外层循环的每次迭代中从矩阵<span class="math notranslate nohighlight">\(A\)</span>中读取大小为<span class="math notranslate nohighlight">\(tileM \times tileK\)</span>的数据块，在矩阵<span class="math notranslate nohighlight">\(B\)</span>中读取大小为<span class="math notranslate nohighlight">\(tileK \times tileN\)</span>的数据块。假设每个线程块中一共含有<span class="math notranslate nohighlight">\(blockSize\)</span>个线程，那么就可以使用这<span class="math notranslate nohighlight">\(blockSize\)</span>个线程，每个线程循环<span class="math notranslate nohighlight">\(\frac{tileM * tileK}{blockSize * 4}\)</span>次将矩阵<span class="math notranslate nohighlight">\(A\)</span>中的矩阵块
<code class="docutils literal notranslate"><span class="pre">tileA</span></code>
读取进共享内存中，同理每个线程循环<span class="math notranslate nohighlight">\(\frac{tileM * tileK}{blockSize * 4}\)</span>次将矩阵<span class="math notranslate nohighlight">\(B\)</span>中的矩阵块
<code class="docutils literal notranslate"><span class="pre">tileB</span></code> 读取进共享内存中。</p>
<p>首先需要定义若干变量：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">LayoutTileT</span> <span class="o">=</span>
     <span class="n">Layout</span><span class="o">&lt;</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">,</span>
                               <span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span> <span class="o">/</span> <span class="n">ratio</span><span class="o">&gt;</span><span class="p">;</span>
 <span class="k">using</span> <span class="n">LayoutThreadT</span> <span class="o">=</span>
     <span class="n">Layout</span><span class="o">&lt;</span><span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">ratio</span><span class="o">&gt;</span><span class="p">;</span>

<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">blockSize</span> <span class="o">=</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">m</span> <span class="o">*</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">n</span><span class="p">;</span>

<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">nInTileC</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">%</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">m</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">mInTileC</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">m</span><span class="p">;</span>

<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileSizeA</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">*</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileIterationsA</span> <span class="o">=</span> <span class="n">tileSizeA</span> <span class="o">/</span> <span class="n">blockSize</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileGlobalIntervalA</span> <span class="o">=</span> <span class="n">blockSize</span> <span class="o">/</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">k</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileComputeIterationsA</span> <span class="o">=</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">m</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileSharedIntervalA</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span> <span class="o">/</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">kInTileA</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">%</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">k</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">mInTileA</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">k</span><span class="p">;</span>

<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileSizeB</span> <span class="o">=</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">n</span> <span class="o">*</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileIterationsB</span> <span class="o">=</span> <span class="n">tileSizeB</span> <span class="o">/</span> <span class="n">blockSize</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileGlobalIntervalB</span> <span class="o">=</span> <span class="n">blockSize</span> <span class="o">/</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileComputeIterationsB</span> <span class="o">=</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">LayoutBlock</span><span class="o">::</span><span class="n">n</span><span class="p">;</span>
<span class="k">constexpr</span> <span class="kt">unsigned</span> <span class="n">tileSharedIntervalBT</span> <span class="o">=</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span> <span class="o">/</span> <span class="n">tileComputeIterationsB</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">nInTileB</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">%</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span><span class="p">;</span>
<span class="k">const</span> <span class="kt">unsigned</span> <span class="n">kinTileB</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span><span class="p">;</span>
</pre></div>
</div>
<p>因为 <code class="docutils literal notranslate"><span class="pre">LayoutTile</span></code> 与 <code class="docutils literal notranslate"><span class="pre">LayoutThread</span></code> 是表示的 <code class="docutils literal notranslate"><span class="pre">float</span></code>
数据的布局，我们有时将其看为 <code class="docutils literal notranslate"><span class="pre">float4</span></code> 的数据储存，因此我们需要加入变量
<code class="docutils literal notranslate"><span class="pre">LayoutTileT</span></code> 与 <code class="docutils literal notranslate"><span class="pre">LayoutThreadT</span></code> 。 <code class="docutils literal notranslate"><span class="pre">blockSize</span></code>
指一个线程块内的线程数量。
我们在此版本使用一维线程块的布局模拟二维布局，所以我们需要计算在二维布局下的坐标：用
<code class="docutils literal notranslate"><span class="pre">mInTileC</span></code> 与 <code class="docutils literal notranslate"><span class="pre">nInTileC</span></code> 表示在给定 <code class="docutils literal notranslate"><span class="pre">LayoutBlock</span></code>
布局下的二维线程坐标。由于 <code class="docutils literal notranslate"><span class="pre">tileA</span></code>
是<span class="math notranslate nohighlight">\(tileM \times timeK\)</span>的尺寸，因此我们可以确定其中数据数量<code class="docutils literal notranslate"><span class="pre">tileSizeA</span></code>
，由于一个线程块内有 <code class="docutils literal notranslate"><span class="pre">blockSize</span></code> 个线程且每个线程一次读取 <code class="docutils literal notranslate"><span class="pre">ratio</span></code> 个
<code class="docutils literal notranslate"><span class="pre">float</span></code> 数，因此整个 <code class="docutils literal notranslate"><span class="pre">tileA</span></code> 需要用
<code class="docutils literal notranslate"><span class="pre">tileIterationsA</span> <span class="pre">=</span> <span class="pre">tileSizeA</span> <span class="pre">/</span> <span class="pre">blockSize</span> <span class="pre">/</span> <span class="pre">ratio</span></code>
次读取。每个线程在最开始时负责读取的 <code class="docutils literal notranslate"><span class="pre">tileA</span></code> 的位置使用变量
<code class="docutils literal notranslate"><span class="pre">kInTileA</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mInTileA</span></code> 表示。因为需要用<code class="docutils literal notranslate"><span class="pre">tileIterationsA</span></code>
次读取 <code class="docutils literal notranslate"><span class="pre">tileA</span></code>
，每次向下滑动的距离我们使用变量<code class="docutils literal notranslate"><span class="pre">tileGlobalIntervalA</span></code>表示。同时因为需要用每个线程需要处理
<code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code> 中多个子矩阵块，其中每个线程处理 <code class="docutils literal notranslate"><span class="pre">thread</span> <span class="pre">tile</span></code>
时在行方向上迭代的次数 定义为<code class="docutils literal notranslate"><span class="pre">tileComputeIterationsA</span></code>
。这些子矩阵块在 <code class="docutils literal notranslate"><span class="pre">m</span></code> 方向的间隔我们用<code class="docutils literal notranslate"><span class="pre">tileSharedIntervalA</span></code>
表示。类似地，我们定义与 <code class="docutils literal notranslate"><span class="pre">tileB</span></code> 的若干变量。</p>
<p>此外我们需要声明共享内存 <code class="docutils literal notranslate"><span class="pre">tile</span></code> 和从全局内存读取的数据 <code class="docutils literal notranslate"><span class="pre">buffer</span></code> ：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__shared__</span> <span class="n">float4</span> <span class="n">tileA</span><span class="p">[</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">m</span><span class="p">][</span><span class="n">LayoutTileT</span><span class="o">::</span><span class="n">k</span><span class="p">];</span>
<span class="n">__shared__</span> <span class="n">float4</span> <span class="n">tileB</span><span class="p">[</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">][</span><span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span><span class="p">];</span>
<span class="n">float4</span> <span class="n">bufferA</span><span class="p">[</span><span class="n">tileIterationsA</span><span class="p">];</span>
<span class="n">float4</span> <span class="n">bufferB</span><span class="p">[</span><span class="n">tileIterationsB</span><span class="p">];</span>
</pre></div>
</div>
<p>我们使用以下代码将数据从全局内存中读出：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">tileIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
 <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">pA</span><span class="p">.</span><span class="n">validColOffset</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
 <span class="n">bufferA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span>
     <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">?</span> <span class="n">pA</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">:</span> <span class="n">float4Zero</span><span class="p">;</span>
<span class="p">}</span>

<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">tileIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
 <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span>
     <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">pB</span><span class="p">.</span><span class="n">validRowOffset</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">);</span>
 <span class="n">bufferB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span>
     <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">?</span> <span class="n">pB</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">:</span> <span class="n">float4Zero</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>从全局内存将数据读入 <code class="docutils literal notranslate"><span class="pre">buffer</span></code> 之后我们使用以下代码将数据写入共享内存：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
 <span class="n">tileA</span><span class="p">[</span><span class="n">mInTileA</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span><span class="p">][</span><span class="n">kInTileA</span><span class="p">]</span> <span class="o">=</span> <span class="n">bufferA</span><span class="p">[</span><span class="n">a</span><span class="p">];</span>
<span class="p">}</span>

<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
 <span class="n">tileB</span><span class="p">[</span><span class="n">kinTileB</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">][</span><span class="n">nInTileB</span><span class="p">]</span> <span class="o">=</span> <span class="n">bufferB</span><span class="p">[</span><span class="n">a</span><span class="p">];</span>
<span class="p">}</span>
<span class="n">__syncthreads</span><span class="p">();</span>
</pre></div>
</div>
<p>不要忘记写入前和写入后进行一次同步避免数据竞争。
此后我们使用以下代码执行内层循环：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">b</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">fragmentA</span><span class="p">[</span><span class="n">a</span><span class="p">][</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span>
         <span class="n">tileA</span><span class="p">[</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalA</span> <span class="o">+</span> <span class="n">mInTileC</span> <span class="o">*</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span> <span class="o">+</span> <span class="n">b</span><span class="p">]</span>
              <span class="p">[</span><span class="n">j</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">][</span><span class="n">j</span> <span class="o">%</span> <span class="n">ratio</span><span class="p">];</span>
   <span class="p">}</span>
 <span class="p">}</span>
<span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
   <span class="n">fragmentB</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">tileB</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span> <span class="o">+</span> <span class="n">nInTileC</span><span class="p">];</span>
 <span class="p">}</span>
<span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">d</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span> <span class="o">*</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">d</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">e</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">e</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsB</span> <span class="o">*</span> <span class="n">LayoutThreadT</span><span class="o">::</span><span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">c</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">e</span><span class="p">]</span> <span class="o">=</span>
         <span class="n">c</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">e</span><span class="p">]</span> <span class="o">+</span> <span class="n">fragmentB</span><span class="p">[</span><span class="n">e</span><span class="p">]</span> <span class="o">*</span>
                       <span class="n">fragmentA</span><span class="p">[</span><span class="n">d</span> <span class="o">/</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">][</span><span class="n">d</span> <span class="o">%</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">];</span>
   <span class="p">}</span>
 <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>内层循环的流程包括从共享内存中读取数据到 <code class="docutils literal notranslate"><span class="pre">fragment</span></code> ，使用
<code class="docutils literal notranslate"><span class="pre">fragment</span></code> 的数据进行计算。
在内层循环结束后对全局内存增加偏移量后执行下一次外层循环：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">pA</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">k</span><span class="p">);</span>
<span class="n">pB</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</pre></div>
</div>
<p>其他计算放缩等代码与上一个版本基本一致，写回代码如下：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="n">a</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
   <span class="k">const</span> <span class="kt">bool</span> <span class="n">mValid</span> <span class="o">=</span> <span class="n">pC</span><span class="p">.</span><span class="n">validRowOffset</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
<span class="cp">#pragma unroll</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">b</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsB</span><span class="p">;</span> <span class="n">b</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
     <span class="k">const</span> <span class="kt">bool</span> <span class="n">nValid</span> <span class="o">=</span> <span class="n">pC</span><span class="p">.</span><span class="n">validColOffset</span><span class="p">(</span><span class="n">b</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span><span class="p">);</span>
     <span class="k">if</span> <span class="p">(</span><span class="n">mValid</span> <span class="o">&amp;&amp;</span> <span class="n">nValid</span><span class="p">)</span> <span class="p">{</span>
       <span class="n">openmlsys</span><span class="o">::</span><span class="n">float4</span> <span class="n">result</span><span class="p">{</span><span class="n">c</span><span class="p">[</span><span class="n">a</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">][</span><span class="n">b</span><span class="p">]};</span>
       <span class="k">if</span> <span class="p">(</span><span class="n">beta</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
         <span class="n">result</span> <span class="o">=</span> <span class="n">result</span> <span class="o">+</span> <span class="n">pC</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span><span class="p">)</span> <span class="o">*</span> <span class="n">beta</span><span class="p">;</span>
       <span class="p">}</span>
       <span class="n">pC</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span><span class="p">)</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
     <span class="p">}</span>
   <span class="p">}</span>
 <span class="p">}</span>
 <span class="n">pC</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="n">tileSharedIntervalA</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>完整代码见<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/gemm_use_smem.cu">gemm_use_smem.cu</a>。</p>
<div class="section" id="id13">
<h3><span class="section-number">8.4.5.1. </span>测试及分析<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">0.617</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">13925.168</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>我们使用Nsight
Compute对核函数分析并与上一个核函数进行对比，我们观察到主要的变化有：首先
<code class="docutils literal notranslate"><span class="pre">LDG</span></code> 指令数量下降了97%，与我们的此前设计相吻合。同时观察到
<code class="docutils literal notranslate"><span class="pre">SM</span> <span class="pre">Utilization</span></code>
提升了218%也可以侧面证实我们使用共享内存减少了内存访问延迟从而提升了利用率，此外我们观察到各项指标如
<code class="docutils literal notranslate"><span class="pre">Pipe</span> <span class="pre">Fma</span> <span class="pre">Cycles</span> <span class="pre">Active</span></code>
等都有显著提升，这都能充分解释了我们使用共享内存的改进是合理且有效的。</p>
</div>
</div>
<div class="section" id="id14">
<span id="id15"></span><h2><span class="section-number">8.4.6. </span>减少寄存器使用<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>我们注意到在我们向共享内存中存储矩阵<span class="math notranslate nohighlight">\(A\)</span>的数据块是按照行优先的数据排布进行的，而我们对此共享内存的读取是按列逐行读取的。我们可以将矩阵<span class="math notranslate nohighlight">\(A\)</span>的数据块在共享内存中数据按照列优先的形式排布，这样我们可以减少循环及循环变量从而带来寄存器使用数量减少进而带来性能提升。</p>
<p>需要对代码做如下修改，首先将 <code class="docutils literal notranslate"><span class="pre">tileA</span></code> 修改为列优先矩阵：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__shared__</span> <span class="n">float4</span> <span class="n">tileA</span><span class="p">[</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">][</span><span class="n">LayoutTileT</span><span class="o">::</span><span class="n">m</span><span class="p">];</span>
</pre></div>
</div>
<p>其次需要将写入 <code class="docutils literal notranslate"><span class="pre">tileA</span></code> 的过程按照列优先调整：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
   <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">tileA</span><span class="p">[</span><span class="n">kInTileA</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span>
          <span class="p">[(</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span> <span class="o">+</span> <span class="n">mInTileA</span><span class="p">)</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">]</span>
          <span class="p">[(</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span> <span class="o">+</span> <span class="n">mInTileA</span><span class="p">)</span> <span class="o">%</span> <span class="n">ratio</span><span class="p">]</span> <span class="o">=</span> <span class="n">bufferA</span><span class="p">[</span><span class="n">a</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
   <span class="p">}</span>
 <span class="p">}</span>
</pre></div>
</div>
<p>最后修改从 <code class="docutils literal notranslate"><span class="pre">tileA</span></code> 读取的过程：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
 <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
   <span class="n">fragmentA</span><span class="p">[</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">tileA</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalAT</span> <span class="o">+</span> <span class="n">mInTileC</span><span class="p">];</span>
 <span class="p">}</span>
</pre></div>
</div>
<p>完整代码见<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/gemm_transpose_smem.cu">gemm_transpose_smem.cu</a>。</p>
<div class="section" id="id16">
<h3><span class="section-number">8.4.6.1. </span>测试及分析<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">0.610</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">14083.116</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>使用Nsight Compute分析有以下观察发现主要的变化： <code class="docutils literal notranslate"><span class="pre">Occupancy</span></code>
提升1.3%，而带来此提升的原因是寄存器使用111个，相比上一个GPU核函数使用128个寄存器减少了17个，从而带来了性能提升。但这个变化会因为GPU架构不同导致有不同的变化，同时我们观察到
<code class="docutils literal notranslate"><span class="pre">STS</span></code> 指令数量提升且带来一些 <code class="docutils literal notranslate"><span class="pre">bank</span> <span class="pre">confilct</span></code>
，因此在其他GPU架构上此改动可能不会带来正面影响。</p>
</div>
</div>
<div class="section" id="id17">
<h2><span class="section-number">8.4.7. </span>隐藏共享内存读取延迟<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<p>在GPU中使用指令 <code class="docutils literal notranslate"><span class="pre">LDS</span></code>
读取共享内存中的数据，在这条指令发出后并不会等待数据读取到寄存器后再执行下一条语句，只有执行到依赖
<code class="docutils literal notranslate"><span class="pre">LDS</span></code>
指令读取的数据的指令时才会等待读取的完成。而在上一小节中，我们在内层<span class="math notranslate nohighlight">\(tileK\)</span>次循环中，每次发射完读取共享内存的指令之后就会立即执行依赖于读取数据的数学运算，这样就会导致计算单元等待数据从共享内存的读取，如
<a class="reference internal" href="#use-smem-pipeline"><span class="std std-numref">图8.4.7</span></a>
所示。事实上，对共享内存的访问周期能多达几十个时钟周期，而计算指令的执行往往只有几个时钟周期，因此通过一定方式隐藏对共享内存的访问会取得不小的收益。我们可以重新优化流水线隐藏一定的数据读取延迟。具体地，我们可以在内层的<span class="math notranslate nohighlight">\(tileK\)</span>次循环中每次循环开始时读取发射下一次内层循环数据的读取指令。由于在执行本次运算时计算指令并不依赖于下一次循环的数据，因此计算过程不会等待之前发出的读取下一次内层循环数据的指令，具体见
<a class="reference internal" href="#hide-smem-latency"><span class="std std-numref">图8.4.8</span></a> 。</p>
<div class="figure align-default" id="id32">
<span id="use-smem-pipeline"></span><a class="reference internal image-reference" href="../_images/use_smem_pipeline.svg"><img alt="../_images/use_smem_pipeline.svg" src="../_images/use_smem_pipeline.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.7 </span><span class="caption-text">上一个GPU核函数的流水线</span><a class="headerlink" href="#id32" title="Permalink to this image">¶</a></p>
</div>
<div class="figure align-default" id="id33">
<span id="id18"></span><span id="hide-smem-latency"></span><a class="reference internal image-reference" href="../_images/hide_smem_latency.svg"><img alt="../_images/hide_smem_latency.svg" src="../_images/hide_smem_latency.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.8 </span><span class="caption-text">隐藏共享内存读取延迟的流水线</span><a class="headerlink" href="#id33" title="Permalink to this image">¶</a></p>
</div>
<p>我们对代码需要做如下修改，首先需要将<code class="docutils literal notranslate"><span class="pre">fragment</span></code>
的数量加倍用于存储下一次内循环读取的数据：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">float4</span> <span class="n">fragmentA</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">tileComputeIterationsA</span> <span class="o">*</span> <span class="n">LayoutThreadT</span><span class="o">::</span><span class="n">m</span><span class="p">];</span>
<span class="n">float4</span> <span class="n">fragmentB</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">tileComputeIterationsB</span> <span class="o">*</span> <span class="n">LayoutThreadT</span><span class="o">::</span><span class="n">n</span><span class="p">];</span>
</pre></div>
</div>
<p>其后要在内层循环开始前从 <code class="docutils literal notranslate"><span class="pre">tile</span></code> 中向 <code class="docutils literal notranslate"><span class="pre">fragment</span></code> 传输数据：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fragmentA</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">tileA</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalAT</span> <span class="o">+</span> <span class="n">mInTileC</span><span class="p">];</span>
<span class="p">}</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fragmentB</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">tileB</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span> <span class="o">+</span> <span class="n">nInTileC</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
<p>同时在内层循环每次迭代的开始时读取下一次内层循环需要的 <code class="docutils literal notranslate"><span class="pre">tile</span></code>
中的数据：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fragmentA</span><span class="p">[(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">][</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">tileA</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalAT</span> <span class="o">+</span> <span class="n">mInTileC</span><span class="p">];</span>
<span class="p">}</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fragmentB</span><span class="p">[(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span><span class="p">][</span><span class="n">a</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">tileB</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">a</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span> <span class="o">+</span> <span class="n">nInTileC</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
<p>其中 <code class="docutils literal notranslate"><span class="pre">j</span></code> 为内存循环的次数。 最后我们修改计算过程的代码 ：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">d</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span> <span class="o">*</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">d</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">e</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">e</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span> <span class="o">*</span> <span class="n">LayoutThreadT</span><span class="o">::</span><span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">c</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">e</span><span class="p">]</span> <span class="o">=</span>
        <span class="n">c</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">e</span><span class="p">]</span> <span class="o">+</span>
        <span class="n">fragmentB</span><span class="p">[</span><span class="n">j</span> <span class="o">%</span> <span class="mi">2</span><span class="p">][</span><span class="n">e</span><span class="p">]</span> <span class="o">*</span>
            <span class="n">fragmentA</span><span class="p">[</span><span class="n">j</span> <span class="o">%</span> <span class="mi">2</span><span class="p">][</span><span class="n">d</span> <span class="o">/</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">][</span><span class="n">d</span> <span class="o">%</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>其中 <code class="docutils literal notranslate"><span class="pre">j</span></code> 为内层循环的次数。
完整代码见<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/gemm_hide_smem_latency.cu">gemm_hide_smem_latency.cu</a>。</p>
<div class="section" id="id19">
<h3><span class="section-number">8.4.7.1. </span>测试及分析<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">0.585</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">14686.179</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>使用Nsight Compute观察发现：相比上一个GPU核函数，指标
<code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Short</span> <span class="pre">Scoreboard</span></code>
减少了67%。而此前提过GPU内存读写指令发出后并不会等待数据读取到寄存器后再执行下一条语句，但是会在Scoreboard设置符号并在完成读取后置回符号，等到之后有数据依赖的指令执行前会等待Scoreboard中符号的置回。所以这里<code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Short</span> <span class="pre">Scoreboard</span></code>
的减少充分说明了内存延迟是有效的。</p>
</div>
</div>
<div class="section" id="id20">
<h2><span class="section-number">8.4.8. </span>隐藏全局内存读取延迟<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h2>
<p>上一小节中我们介绍了对共享内存读取流水线优化的方法，事实上，GPU再读取全局内存中使用的指令
<code class="docutils literal notranslate"><span class="pre">LDG</span></code> 也有与共享内存读取指令 <code class="docutils literal notranslate"><span class="pre">LDS</span></code>
类似的行为特性。因此我们类似的在<span class="math notranslate nohighlight">\(\frac{K}{tileK}\)</span>次外层循环中每次循环开始时发出下一次外层循环需要的矩阵<span class="math notranslate nohighlight">\(A\)</span>中的数据块的读取指令，而本次外循环的整个内层循环过程中不依赖下一次外循环的数据，因此本次外循环的内循环过程中不会等待对下一次外层循环需要的矩阵<span class="math notranslate nohighlight">\(A\)</span>中的数据块的读取指令完成，从而实现隐藏全局内存读取延迟的目的。具体流水线可视化见
<a class="reference internal" href="#hide-global-latency"><span class="std std-numref">图8.4.9</span></a> 。</p>
<div class="figure align-default" id="id34">
<span id="id21"></span><span id="hide-global-latency"></span><a class="reference internal image-reference" href="../_images/hide_global_latency.svg"><img alt="../_images/hide_global_latency.svg" src="../_images/hide_global_latency.svg" width="800px" /></a>
<p class="caption"><span class="caption-number">图8.4.9 </span><span class="caption-text">隐藏全局内存读取延迟的流水线</span><a class="headerlink" href="#id34" title="Permalink to this image">¶</a></p>
</div>
<p>我们将对代码进行以下修改，首先需要将 <code class="docutils literal notranslate"><span class="pre">tile</span></code> 加倍并加入一个决定向哪个
<code class="docutils literal notranslate"><span class="pre">tile</span></code> 写入的符号 <code class="docutils literal notranslate"><span class="pre">writeStageIdx</span></code> ：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__shared__</span> <span class="n">float4</span> <span class="n">tileA</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">][</span><span class="n">LayoutTileT</span><span class="o">::</span><span class="n">m</span><span class="p">];</span>
<span class="n">__shared__</span> <span class="n">float4</span> <span class="n">tileB</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">][</span><span class="n">LayoutTileT</span><span class="o">::</span><span class="n">n</span><span class="p">];</span>
<span class="kt">bool</span> <span class="n">writeStageIdx</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</pre></div>
</div>
<p>紧接着我们将从 <code class="docutils literal notranslate"><span class="pre">buffer</span></code> 向 <code class="docutils literal notranslate"><span class="pre">tile</span></code> 写入的过程相应的依照加倍后的
<code class="docutils literal notranslate"><span class="pre">tile</span></code> 修改 ：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tileIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">tileA</span><span class="p">[</span><span class="n">writeStageIdx</span><span class="p">][</span><span class="n">kInTileA</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span>
         <span class="p">[(</span><span class="n">i</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span> <span class="o">+</span> <span class="n">mInTileA</span><span class="p">)</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">]</span>
         <span class="p">[(</span><span class="n">i</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span> <span class="o">+</span> <span class="n">mInTileA</span><span class="p">)</span> <span class="o">%</span> <span class="n">ratio</span><span class="p">]</span> <span class="o">=</span> <span class="n">bufferA</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tileIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">tileB</span><span class="p">[</span><span class="n">writeStageIdx</span><span class="p">][</span><span class="n">kinTileB</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">][</span><span class="n">nInTileB</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">bufferB</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</pre></div>
</div>
<p>其后相应修改从 <code class="docutils literal notranslate"><span class="pre">tile</span></code> 向 <code class="docutils literal notranslate"><span class="pre">fragment</span></code> 读取数据的相关代码，并将符号
<code class="docutils literal notranslate"><span class="pre">writeStageIdx</span></code> 翻转：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fragmentA</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">tileA</span><span class="p">[</span><span class="n">writeStageIdx</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span> <span class="o">*</span> <span class="n">tileSharedIntervalAT</span> <span class="o">+</span> <span class="n">mInTileC</span><span class="p">];</span>
<span class="p">}</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tileComputeIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">fragmentB</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">tileB</span><span class="p">[</span><span class="n">writeStageIdx</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span> <span class="o">*</span> <span class="n">tileSharedIntervalBT</span> <span class="o">+</span> <span class="n">nInTileC</span><span class="p">];</span>
<span class="p">}</span>
<span class="n">writeStageIdx</span> <span class="o">=</span> <span class="o">!</span><span class="n">writeStageIdx</span><span class="p">;</span>
</pre></div>
</div>
<p>接下来我们在每次外层循环开始时从全局内存读取下一次计算需要的 <code class="docutils literal notranslate"><span class="pre">buffer</span></code>
：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">tensorA</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">LayoutTileT</span><span class="o">::</span><span class="n">k</span><span class="p">);</span>
<span class="n">tensorB</span><span class="p">.</span><span class="n">addOffset</span><span class="p">(</span><span class="n">LayoutTile</span><span class="o">::</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">tileIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">tensorA</span><span class="p">.</span><span class="n">validColOffset</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
  <span class="n">bufferA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">validLoadTileA</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">?</span> <span class="n">tensorA</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">:</span> <span class="n">float4Zero</span><span class="p">;</span>
<span class="p">}</span>

<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">tileIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="n">tensorB</span><span class="p">.</span><span class="n">validRowOffset</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">);</span>
  <span class="n">bufferB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">validLoadTileB</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">?</span> <span class="n">tensorB</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">:</span> <span class="n">float4Zero</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>最后我们在内层循环结束后将预先读取的 <code class="docutils literal notranslate"><span class="pre">buffer</span></code> 写入到 <code class="docutils literal notranslate"><span class="pre">tile</span></code>
中并翻转符号位 <code class="docutils literal notranslate"><span class="pre">writeStageIdx</span></code> ：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">d</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="n">tileIterationsA</span><span class="p">;</span> <span class="o">++</span><span class="n">d</span><span class="p">)</span> <span class="p">{</span>
<span class="cp">#pragma unroll</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">e</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">e</span> <span class="o">&lt;</span> <span class="n">LayoutThread</span><span class="o">::</span><span class="n">m</span><span class="p">;</span> <span class="o">++</span><span class="n">e</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">tileA</span><span class="p">[</span><span class="n">writeStageIdx</span><span class="p">][</span><span class="n">kInTileA</span> <span class="o">*</span> <span class="n">ratio</span> <span class="o">+</span> <span class="n">e</span><span class="p">]</span>
         <span class="p">[(</span><span class="n">d</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span> <span class="o">+</span> <span class="n">mInTileA</span><span class="p">)</span> <span class="o">/</span> <span class="n">ratio</span><span class="p">]</span>
         <span class="p">[(</span><span class="n">d</span> <span class="o">*</span> <span class="n">tileGlobalIntervalA</span> <span class="o">+</span> <span class="n">mInTileA</span><span class="p">)</span> <span class="o">%</span> <span class="n">ratio</span><span class="p">]</span> <span class="o">=</span> <span class="n">bufferA</span><span class="p">[</span><span class="n">d</span><span class="p">][</span><span class="n">e</span><span class="p">];</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="cp">#pragma unroll</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">unsigned</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="n">tileIterationsB</span><span class="p">;</span> <span class="o">++</span><span class="n">a</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">tileB</span><span class="p">[</span><span class="n">writeStageIdx</span><span class="p">][</span><span class="n">kinTileB</span> <span class="o">+</span> <span class="n">a</span> <span class="o">*</span> <span class="n">tileGlobalIntervalB</span><span class="p">][</span><span class="n">nInTileB</span><span class="p">]</span> <span class="o">=</span>
      <span class="n">bufferB</span><span class="p">[</span><span class="n">a</span><span class="p">];</span>
<span class="p">}</span>
<span class="n">writeStageIdx</span> <span class="o">=</span> <span class="o">!</span><span class="n">writeStageIdx</span><span class="p">;</span>
</pre></div>
</div>
<p>事实上，我们可以让内层循环先执行<span class="math notranslate nohighlight">\(tileK - 1\)</span>次，在最后一次执行前将
<code class="docutils literal notranslate"><span class="pre">buffer</span></code> 中的数据写入 <code class="docutils literal notranslate"><span class="pre">tile</span></code>
，其后再执行内层循环的最后一次迭代，这样能更进一步隐藏向 <code class="docutils literal notranslate"><span class="pre">tile</span></code>
写入的内存延迟。</p>
<p>完整代码见<a class="reference external" href="https://github.com/openmlsys/openmlsys-cuda/blob/main/gemm_final.cu">gemm_final.cu</a>。</p>
<div class="section" id="id22">
<h3><span class="section-number">8.4.8.1. </span>测试及分析<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">0.542</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Average</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">15838.302</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>使用Nsight Compute分析我们观察到指标 <code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Long</span> <span class="pre">Scoreboard</span></code>
减少了67%，与上一小结的 <code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Short</span> <span class="pre">Scoreboard</span></code>
概念相对应，<code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Long</span> <span class="pre">Scoreboard</span></code>
主要是针对全局内存的指标。该指标的显著减少充分说明我们可以在一定程度上隐藏全局内存的读取。</p>
</div>
</div>
<div class="section" id="cublas">
<span id="id23"></span><h2><span class="section-number">8.4.9. </span>与cuBLAS对比<a class="headerlink" href="#cublas" title="Permalink to this headline">¶</a></h2>
<p>前一节中介绍了cuBLAS的接口，我们可以很容易地写出以下代码使用cuBLAS完成矩阵乘法：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span> <span class="nf">cublasGemm</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span> <span class="kt">float</span> <span class="n">alf</span><span class="p">,</span> <span class="kt">float</span> <span class="n">bet</span><span class="p">,</span> <span class="kt">int</span> <span class="n">M</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">K</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">lda</span> <span class="o">=</span> <span class="n">N</span><span class="p">,</span> <span class="n">ldb</span> <span class="o">=</span> <span class="n">K</span><span class="p">,</span> <span class="n">ldc</span> <span class="o">=</span> <span class="n">N</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">alpha</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">alf</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="n">beta</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">bet</span><span class="p">;</span>
  <span class="n">cublasHandle_t</span> <span class="n">handle</span><span class="p">;</span>
  <span class="n">cublasCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">handle</span><span class="p">);</span>
  <span class="n">cublasSgemm</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">CUBLAS_OP_N</span><span class="p">,</span> <span class="n">CUBLAS_OP_N</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">lda</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">ldb</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">ldc</span><span class="p">);</span>
  <span class="n">cublasDestroy</span><span class="p">(</span><span class="n">handle</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>需要注意的是cuBLAS默认矩阵在GPU中是按列优先存储的，而我们的矩阵是按行优先存储的，而两者可以通过转置相互转换，所以<span class="math notranslate nohighlight">\(A\times B = (B^T\times A^T)^T\)</span>，因此在输入时需要调整矩阵的顺序，即可保证输出结果仍是行优先矩阵。</p>
<div class="section" id="id24">
<h3><span class="section-number">8.4.9.1. </span>测试及分析<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h3>
<p>测试得到以下结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Max</span> <span class="n">Error</span><span class="p">:</span> <span class="mf">0.000092</span>
<span class="n">Average</span> <span class="n">Time</span><span class="p">:</span> <span class="mf">0.613</span> <span class="n">ms</span><span class="p">,</span> <span class="n">Throughput</span><span class="p">:</span> <span class="mf">14002.600</span> <span class="n">GFLOPS</span>
</pre></div>
</div>
<p>使用Nsight Compute分析发现 <code class="docutils literal notranslate"><span class="pre">LDG</span></code> 和 <code class="docutils literal notranslate"><span class="pre">STS</span></code>
等指令使用较多，导致指令发射压力较大，具体体现在 <code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Wait</span></code> 与
<code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Dispatch</span> <span class="pre">Stall</span></code> 指标相比我们较差。但其他指标诸如
<code class="docutils literal notranslate"><span class="pre">Stall</span> <span class="pre">Long</span> <span class="pre">Scoreboard</span></code> 等优于我们，但总体上我们略胜一筹。
尽管我们的代码相比cuBLAS已经取得了一定的性能提升，但是需要强调的是cuBLAS内部为各种不同的矩阵尺寸以及不同的设备实现了若干不同的GPU核函数，我们实现的核函数在其他尺寸或其他设备设备上性能可能无法取得此加速比。</p>
<ol class="arabic simple">
<li><p><strong>并行资源映射——提高并行性</strong>：将多层级的并行资源（<code class="docutils literal notranslate"><span class="pre">block</span></code>
、<code class="docutils literal notranslate"><span class="pre">warp</span></code> 、<code class="docutils literal notranslate"><span class="pre">thread</span></code>
）与对应需要计算/搬移的数据建立映射关系，提高程序并行性。将可并行的计算/数据搬移操作映射到并行资源上，对于一般矩阵乘法实例，在朴素实现的例子中
<a class="reference internal" href="#sec-accelerator-naive"><span class="std std-numref">8.4.2节</span></a> ，我们令每个<code class="docutils literal notranslate"><span class="pre">block</span></code>
与矩阵<span class="math notranslate nohighlight">\(C\)</span>中的一个矩阵块建立映射关系，每个<code class="docutils literal notranslate"><span class="pre">thread</span></code>
与矩阵块中的一个元素建立映射关系。</p></li>
<li><p><strong>优化内存结构——减小访存延迟</strong>：观察计算过程中同一个<code class="docutils literal notranslate"><span class="pre">block</span></code>
中数据复用的情况，将复用的数据被如共享内存、寄存器等高性能体系结构存储下来，以此提高吞吐量。如在
<a class="reference internal" href="#sec-accelerator-use-smem"><span class="std std-numref">8.4.5节</span></a>
中我们将矩阵<span class="math notranslate nohighlight">\(A\)</span>与矩阵<span class="math notranslate nohighlight">\(B\)</span>中会被同一个<code class="docutils literal notranslate"><span class="pre">block</span></code>
内不同<code class="docutils literal notranslate"><span class="pre">thread</span></code> 共同访问的数据缓存到共享内存中。</p></li>
<li><p><strong>优化指令执行——减小指令发射开销</strong>：使用#unroll功能进行循环展开来提升指令级并行，减少逻辑判断；使用向量化加载指令以提高带宽等，对于Ampere架构，最大向量化加载指令为<code class="docutils literal notranslate"><span class="pre">LDG.E.128</span></code>，可以采用<code class="docutils literal notranslate"><span class="pre">float4</span></code>
类型的数据进行读取。</p></li>
<li><p><strong>优化访存流水线——隐藏访存延迟</strong>：在进行内存结构变化（矩阵数据搬移）时，可以优化访存流水线，在数据搬移的间隔执行计算操作以隐藏数据搬移的延迟。</p></li>
</ol>
</div>
</div>
<div class="section" id="id25">
<h2><span class="section-number">8.4.10. </span>扩展<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h2>
<p>张量核是在从Volta架构加入的新硬件电路，此电路能对半精度（FP16）、双精度（FP64）、低比特整型（INT8等）和特殊格式（TF16等）数据格式加速。其提供了新的数据读取与计算指令集并使用CUDA代码对部分指令封装以允许用户使用此结构。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">mma.h</span></code> 中定义了若干C++接口，主要有的几个结构在命名空间
<code class="docutils literal notranslate"><span class="pre">nvcuda::wmma</span></code> 下，他们分有 <code class="docutils literal notranslate"><span class="pre">row_major</span></code> 与 <code class="docutils literal notranslate"><span class="pre">col_major</span></code>
用于表示数据布局； <code class="docutils literal notranslate"><span class="pre">matrix_a</span></code> 、 <code class="docutils literal notranslate"><span class="pre">matrix_b</span></code> 和<code class="docutils literal notranslate"><span class="pre">accumulator</span></code>
用于区别矩阵类型； <code class="docutils literal notranslate"><span class="pre">fragment</span></code> 用于表示数据存储的类； <code class="docutils literal notranslate"><span class="pre">fill_fragment</span></code>
、 <code class="docutils literal notranslate"><span class="pre">load_matrix_sync</span></code> 和 <code class="docutils literal notranslate"><span class="pre">store_matrix_sync</span></code> 用于对 <code class="docutils literal notranslate"><span class="pre">fragment</span></code>
进行设置、加载以及向全局内存操作； <code class="docutils literal notranslate"><span class="pre">mma_sync</span></code>
用于计算。但是由于其灵活性较差，且实际只是底层指令的封装，实际实践中主要是使用英伟达提供的PTX指令集内嵌到C++代码中进行编程。</p>
<p>PTX指令集是英伟达推出的一种CUDA指令集中间表示，其并不是直接由二进制反汇编得来的汇编语言，事实上它更像是Java语言中的ByteCode概念。PTX给用户更细粒度的编程的可能，但是要注意的是由于它并不是直接的汇编语言，所以最后被CUDA汇编器汇编得到的二进制文件可能会用其他等价语句实现。例如，在安培设备中不支持
<code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code>
相关功能，但用户仍然可以在代码中直接使用此PTX指令，但在汇编过程会被实现为等价的非
<code class="docutils literal notranslate"><span class="pre">mma</span></code> 指令，进而导致性能不如预期。</p>
<p>与一般矩阵乘法相关的PTX指令主要有 <code class="docutils literal notranslate"><span class="pre">wmma</span></code> 和 <code class="docutils literal notranslate"><span class="pre">mma</span></code> 。 <code class="docutils literal notranslate"><span class="pre">wmma</span></code> 是相对
<code class="docutils literal notranslate"><span class="pre">mma</span></code> 高一层的指令，它可以提供若干修饰符如 <code class="docutils literal notranslate"><span class="pre">load</span></code> 用于读取数据，
<code class="docutils literal notranslate"><span class="pre">store</span></code> 用于储存数据， <code class="docutils literal notranslate"><span class="pre">mma</span></code> 用于计算等操作。</p>
<p>修饰符的使用可以类似于以下形式
<code class="docutils literal notranslate"><span class="pre">wmma.load.a.sync.aligned.m16n16k16.global.row.f16</span></code> 。 <code class="docutils literal notranslate"><span class="pre">a</span></code>
代表目标为矩阵<span class="math notranslate nohighlight">\(A\)</span>中的数据；<code class="docutils literal notranslate"><span class="pre">sync</span></code>
代表线程束内线程在执行这条指令之前会进行同步； <code class="docutils literal notranslate"><span class="pre">aligned</span></code>
代表要求线程束内所有线程都执行相同的指令； <code class="docutils literal notranslate"><span class="pre">m16n16k16</span></code>
代表一个线程束的线程共同完成数据处理的规模； <code class="docutils literal notranslate"><span class="pre">global</span></code>
代表是从全局内存读取； <code class="docutils literal notranslate"><span class="pre">row</span></code> 代表数据是行优先的布局储存的； <code class="docutils literal notranslate"><span class="pre">f16</span></code>
代表数据类型为半精度。其他可能的修饰符可以在官方文档中查阅。 <code class="docutils literal notranslate"><span class="pre">mma</span></code>
指令相比 <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> 功能更加丰富，使用也更加灵活，其使用可类似以下形式
<code class="docutils literal notranslate"><span class="pre">mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16</span></code> 。 <code class="docutils literal notranslate"><span class="pre">sync</span></code>
代表线程束内线程在执行这条指令之前会进行同步； <code class="docutils literal notranslate"><span class="pre">aligned</span></code>
代表要求线程束内所有线程都执行相同的指令； <code class="docutils literal notranslate"><span class="pre">m16n8k16</span></code>
代表一个线程束的线程共同完成数据处理的规模； <code class="docutils literal notranslate"><span class="pre">row.col</span></code>
代表从矩阵<span class="math notranslate nohighlight">\(A\)</span>读入的矩阵块布局是行优先，从矩阵<span class="math notranslate nohighlight">\(B\)</span>读入的数据块布局是列优先；<code class="docutils literal notranslate"><span class="pre">f16.f16.f16.f16</span></code>
分别代表累加结果的矩阵块、从矩阵<span class="math notranslate nohighlight">\(A\)</span>读入的矩阵块、从矩阵<span class="math notranslate nohighlight">\(B\)</span>读入的矩阵块、累加输入的矩阵块的数据类型都是半精度浮点数。</p>
<p>通常我们并不会直接写PTX代码而是将一段或多段PTX指令内联嵌入到CUDA代码中，下面提供了一个例子。假设我们对一个向量的数值乘2，我们可以实现以下代码：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">times2</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">arr</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">unsigned</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">data</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
  <span class="n">data</span> <span class="o">*=</span> <span class="mi">2</span><span class="p">;</span>
  <span class="n">arr</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>如果我们希望第三行读取数据使用PTX指令 <code class="docutils literal notranslate"><span class="pre">ld.global.u32</span></code>
，我们可以实现以下的代码：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">times2UsePTX</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">arr</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">unsigned</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">data</span><span class="p">;</span>
  <span class="k">asm</span> <span class="k">volatile</span><span class="p">(</span>
      <span class="s">&quot;{</span><span class="se">\n</span><span class="s">&quot;</span>
      <span class="s">&quot;  ld.global.u32 %0, [%1];</span><span class="se">\n</span><span class="s">&quot;</span>
      <span class="s">&quot;}</span><span class="se">\n</span><span class="s">&quot;</span>
      <span class="o">:</span> <span class="s">&quot;=r&quot;</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      <span class="o">:</span> <span class="s">&quot;l&quot;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">arr</span><span class="p">[</span><span class="n">tid</span><span class="p">]));</span>
  <span class="n">data</span> <span class="o">*=</span> <span class="mi">2</span><span class="p">;</span>
  <span class="n">arr</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>第一个冒号后面应当是会被赋值的变量，第二个冒号后面是会被读取的变量；
<code class="docutils literal notranslate"><span class="pre">r</span></code> 代表32位无符号整型寄存器， <code class="docutils literal notranslate"><span class="pre">l</span></code>
代表64位无符号整型寄存器，除此之外还可能是 <code class="docutils literal notranslate"><span class="pre">h</span></code>
代表16位无符号整型寄存器， <code class="docutils literal notranslate"><span class="pre">f</span></code> 代表32位浮点寄存器， <code class="docutils literal notranslate"><span class="pre">d</span></code>
代表64位浮点寄存器。类似的，我们也可以用类似的方式将 <code class="docutils literal notranslate"><span class="pre">mma</span></code>
PTX指令嵌入到我们的CUDA代码中，下面给出了一个例子：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// ...</span>
<span class="n">half_t</span> <span class="n">a</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span>
<span class="n">half_t</span> <span class="n">b</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="n">half_t</span> <span class="n">c</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="n">half_t</span> <span class="n">d</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>

<span class="kt">uint32_t</span> <span class="k">const</span> <span class="o">*</span><span class="n">A</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span> <span class="k">const</span> <span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">a</span><span class="p">);</span>
<span class="kt">uint32_t</span> <span class="k">const</span> <span class="o">*</span><span class="n">B</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span> <span class="k">const</span> <span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">b</span><span class="p">);</span>
<span class="kt">uint32_t</span> <span class="k">const</span> <span class="o">*</span><span class="n">C</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span> <span class="k">const</span> <span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">);</span>
<span class="kt">uint32_t</span> <span class="o">*</span><span class="n">D</span> <span class="o">=</span> <span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uint32_t</span> <span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d</span><span class="p">);</span>

<span class="k">asm</span> <span class="k">volatile</span><span class="p">(</span><span class="s">&quot;mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 {%0,%1}, {%2,%3,%4,%5}, {%6,%7}, {%8,%9};</span><span class="se">\n</span><span class="s">&quot;</span>
   <span class="o">:</span> <span class="s">&quot;=r&quot;</span><span class="p">(</span><span class="n">D</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s">&quot;=r&quot;</span><span class="p">(</span><span class="n">D</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
   <span class="o">:</span> <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span>
     <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">B</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
     <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s">&quot;r&quot;</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="p">);</span>
<span class="c1">//...</span>
</pre></div>
</div>
<p>由于篇幅限制，我们在本节中不会过多的介绍张量核的实践，感兴趣的读者可以自行尝试实现。</p>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">8.4. 加速器实践</a><ul>
<li><a class="reference internal" href="#id2">8.4.1. 环境</a><ul>
<li><a class="reference internal" href="#id3">8.4.1.1. 安装</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sec-accelerator-naive">8.4.2. 广义矩阵乘法的朴素实现</a><ul>
<li><a class="reference internal" href="#id5">8.4.2.1. 使用封装结构代替指针</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">8.4.3. 提高计算强度</a><ul>
<li><a class="reference internal" href="#id7">8.4.3.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id8">8.4.4. 进一步提升计算强度</a><ul>
<li><a class="reference internal" href="#id10">8.4.4.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sec-accelerator-use-smem">8.4.5. 使用共享内存缓存复用数据</a><ul>
<li><a class="reference internal" href="#id13">8.4.5.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id14">8.4.6. 减少寄存器使用</a><ul>
<li><a class="reference internal" href="#id16">8.4.6.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id17">8.4.7. 隐藏共享内存读取延迟</a><ul>
<li><a class="reference internal" href="#id19">8.4.7.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id20">8.4.8. 隐藏全局内存读取延迟</a><ul>
<li><a class="reference internal" href="#id22">8.4.8.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cublas">8.4.9. 与cuBLAS对比</a><ul>
<li><a class="reference internal" href="#id24">8.4.9.1. 测试及分析</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id25">8.4.10. 扩展</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="accelerator_programming.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>8.3. 加速器基本编程原理</div>
         </div>
     </a>
     <a id="button-next" href="summary.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>8.5. 总结</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>