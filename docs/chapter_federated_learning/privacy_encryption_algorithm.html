<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>14.4. 隐私加密算法 &#8212; 机器学习系统：设计和实现 1.0.0 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="14.5. 展望" href="outlook.html" />
    <link rel="prev" title="14.3. 纵向联邦学习" href="vertical_fl.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">14. </span>联邦学习系统</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">14.4. </span>隐私加密算法</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_federated_learning/privacy_encryption_algorithm.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="机器学习系统：设计和实现"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">1. 序言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">2. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">2.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">2.2. 设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">2.3. 基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">2.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">3. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">3.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">3.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">3.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">3.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">3.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html#id2">3.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">4. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">4.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">4.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">4.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">4.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">4.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html#id2">4.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">5. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">6. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">6.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">6.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">6.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">6.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">6.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html#id2">6.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">7. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">7.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">7.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">7.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">7.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">7.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html#id2">7.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">8. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">8.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">8.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_practise.html">8.4. 加速器实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html">8.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html#id2">8.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html#id3">8.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">9. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">9.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">9.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">9.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">9.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">9.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html#id2">9.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">10. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">10.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">10.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">10.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">10.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">10.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">10.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html#id2">10.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">11. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">11.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">11.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">11.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">11.4. 集合通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">11.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">11.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id2">11.7. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id3">11.8. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">12. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">13. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">13.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">13.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">13.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">13.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">13.5. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id2">13.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id3">13.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">14. 联邦学习系统</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">14.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="horizontal_fl.html">14.2. 横向联邦学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="vertical_fl.html">14.3. 纵向联邦学习</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">14.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlook.html">14.5. 展望</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">15. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">15.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">15.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">15.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">15.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">15.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">15.6. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html#id2">15.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_explainable_AI/index.html">16. 可解释性AI系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html">16.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#ai">16.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id2">16.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id17">16.4. 可解释AI系统及实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id21">16.5. 未来可解释AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id22">16.6. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rl_sys/index.html">17. 机器人系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/rl_sys_intro.html">17.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros.html">17.2. 通用机器人操作系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros_code_ex.html">17.3. 机器人操作系统（ROS）的入门案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception.html">17.4. 感知系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception_code_ex.html">17.5. 感知系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning.html">17.6. 规划系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning_code_ex.html">17.7. 规划系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control.html">17.8. 控制系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control_code_ex.html">17.9. 控制系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/robot_safety.html">17.10. 在机器人项目中安全的应用机器学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html">17.11. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html#id2">17.12. 参考文献</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html#id4">4. 参考文献</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="机器学习系统：设计和实现"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">1. 序言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">2. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">2.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">2.2. 设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">2.3. 基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">2.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">3. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">3.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">3.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">3.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">3.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">3.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html#id2">3.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">4. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">4.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">4.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">4.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">4.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">4.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html#id2">4.6. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">5. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">6. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">6.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">6.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">6.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">6.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">6.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html#id2">6.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">7. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">7.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">7.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">7.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">7.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">7.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html#id2">7.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">8. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">8.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">8.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_practise.html">8.4. 加速器实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html">8.5. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html#id2">8.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html#id3">8.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">9. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">9.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">9.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">9.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">9.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">9.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html#id2">9.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">10. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">10.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">10.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">10.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">10.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">10.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">10.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html#id2">10.7. 扩展阅读</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">11. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">11.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">11.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">11.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">11.4. 集合通信</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">11.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">11.6. 总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id2">11.7. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html#id3">11.8. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">12. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">13. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">13.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">13.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">13.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">13.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">13.5. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id2">13.6. 扩展阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html#id3">13.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">14. 联邦学习系统</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">14.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="horizontal_fl.html">14.2. 横向联邦学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="vertical_fl.html">14.3. 纵向联邦学习</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">14.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="outlook.html">14.5. 展望</a></li>
<li class="toctree-l2"><a class="reference internal" href="summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">15. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">15.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">15.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">15.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">15.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">15.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">15.6. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html#id2">15.7. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_explainable_AI/index.html">16. 可解释性AI系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html">16.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#ai">16.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id2">16.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id17">16.4. 可解释AI系统及实践</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id21">16.5. 未来可解释AI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id22">16.6. 参考文献</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_rl_sys/index.html">17. 机器人系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/rl_sys_intro.html">17.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros.html">17.2. 通用机器人操作系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/ros_code_ex.html">17.3. 机器人操作系统（ROS）的入门案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception.html">17.4. 感知系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/perception_code_ex.html">17.5. 感知系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning.html">17.6. 规划系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/planning_code_ex.html">17.7. 规划系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control.html">17.8. 控制系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/control_code_ex.html">17.9. 控制系统案例</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/robot_safety.html">17.10. 在机器人项目中安全的应用机器学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html">17.11. 小结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_rl_sys/summary.html#id2">17.12. 参考文献</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html#id4">4. 参考文献</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="id1">
<h1><span class="section-number">14.4. </span>隐私加密算法<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>联邦学习过程中，用户数据仅用于本地设备训练，不需要上传至中央FL-Server。这样可以避免用户个人数据的直接泄露。然而联邦学习框架中，模型的权重以明文形式上云仍然存在间接泄露用户隐私的风险。敌手获取到用户上传的明文权重后，可以通过重构、模型逆向等攻击恢复用户的个人训练数据，导致用户隐私泄露。</p>
<p>MindSpore
Federated框架，提供了基于本地差分隐私（LDP）和基于多方安全计算（MPC）的安全聚合算法，在本地模型的权重上云前对其进行加噪或加扰。在保证模型可用性的前提下，解决联邦学习中的隐私泄露问题。</p>
<div class="section" id="ldp">
<h2><span class="section-number">14.4.1. </span>基于LDP的安全聚合<a class="headerlink" href="#ldp" title="Permalink to this headline">¶</a></h2>
<p>差分隐私（differential
privacy）是一种保护用户数据隐私的机制。差分隐私定义为：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-0">
<span class="eqno">(14.4.1)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-0" title="Permalink to this equation">¶</a></span>\[Pr[\mathcal{K}(D)\in S] \le e^{\epsilon} Pr[\mathcal{K}(D’) \in S]+\delta\]</div>
<p>对于两个差别只有一条记录的数据集<span class="math notranslate nohighlight">\(D, D’\)</span>，通过随机算法<span class="math notranslate nohighlight">\(\mathcal{K}\)</span>，输出结果为集合<span class="math notranslate nohighlight">\(S\)</span>子集的概率满足上面公式。<span class="math notranslate nohighlight">\(\epsilon\)</span>为差分隐私预算，<span class="math notranslate nohighlight">\(\delta\)</span>扰动，<span class="math notranslate nohighlight">\(\epsilon\)</span>和<span class="math notranslate nohighlight">\(\delta\)</span>越小，说明<span class="math notranslate nohighlight">\(\mathcal{K}\)</span>在<span class="math notranslate nohighlight">\(D\)</span>和<span class="math notranslate nohighlight">\(D’\)</span>上输出的数据分布越接近。</p>
<p>在联邦学习中，假设FL-Client本地训练之后的模型权重矩阵是<span class="math notranslate nohighlight">\(W\)</span>，由于模型在训练过程中会“记住”训练集的特征，所以敌手可以借助<span class="math notranslate nohighlight">\(W\)</span>还原出用户的训练数据集。</p>
<p>MindSpore
Federated提供基于本地差分隐私的安全聚合算法，防止本地模型的权重上云时泄露隐私数据。</p>
<p>FL-Client会生成一个与本地模型权重<span class="math notranslate nohighlight">\(W\)</span>相同维度的差分噪声矩阵<span class="math notranslate nohighlight">\(G\)</span>，然后将二者相加，得到一个满足差分隐私定义的权重<span class="math notranslate nohighlight">\(W_p\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-1">
<span class="eqno">(14.4.2)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-1" title="Permalink to this equation">¶</a></span>\[W_p=W+G\]</div>
<p>FL-Client将加噪后的模型权重<span class="math notranslate nohighlight">\(W_p\)</span>上传至云侧FL-Server进行联邦聚合。噪声矩阵<span class="math notranslate nohighlight">\(G\)</span>相当于给原模型加上了一层掩码，在降低模型泄露敏感数据风险的同时，也会影响模型训练的收敛性。如何在模型隐私性和可用性之间取得更好的平衡，仍然是一个值得研究的问题。实验表明，当参与方的数量<span class="math notranslate nohighlight">\(n\)</span>足够大时（一般指1000以上），大部分噪声能够相互抵消，本地差分机制对聚合模型的精度和收敛性没有明显影响。</p>
</div>
<div class="section" id="mpc">
<h2><span class="section-number">14.4.2. </span>基于MPC的安全聚合<a class="headerlink" href="#mpc" title="Permalink to this headline">¶</a></h2>
<p>尽管差分隐私技术可以适当保护用户数据隐私，但是当参与FL-Client数量比较少或者高斯噪声幅值较大时，模型精度会受较大影响。为了同时满足模型保护和模型收敛这两个要求，MindSpore
Federated提供了基于MPC的安全聚合方案。</p>
<p>在这种训练模式下，假设参与的FL-Client集合为<span class="math notranslate nohighlight">\(U\)</span>，对于任意FL-Client
<span class="math notranslate nohighlight">\(u\)</span>和<span class="math notranslate nohighlight">\(v\)</span>，
它们会两两协商出一对随机扰动<span class="math notranslate nohighlight">\(p_{uv}\)</span>、<span class="math notranslate nohighlight">\(p_{vu}\)</span>，满足</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-2">
<span class="eqno">(14.4.3)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-2" title="Permalink to this equation">¶</a></span>\[\begin{split}\label{puv}
    p_{uv}=
    \begin{cases}
    -p_{vu}, &amp;u{\neq}v\\
    0, &amp;u=v
    \end{cases}\end{split}\]</div>
<p>于是每个FL-Client <span class="math notranslate nohighlight">\(u\)</span>
在上传模型权重至FL-Server前，会在原模型权重<span class="math notranslate nohighlight">\(x_u\)</span>加上它与其它用户协商的扰动：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-3">
<span class="eqno">(14.4.4)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-3" title="Permalink to this equation">¶</a></span>\[x_{encrypt}=x_u+\sum\limits_{v{\in}U}p_{uv}\]</div>
<p>从而FL-Server聚合结果<span class="math notranslate nohighlight">\(\overline{x}\)</span>为：</p>
<p>上面的过程只是介绍了聚合算法的主要思想，基于MPC的聚合方案是精度无损的，代价是通讯轮次的增加。</p>
</div>
<div class="section" id="ldp-signds">
<h2><span class="section-number">14.4.3. </span>基于LDP-SignDS算法的安全聚合<a class="headerlink" href="#ldp-signds" title="Permalink to this headline">¶</a></h2>
<p>对于先前的基于维度加噪的LDP算法，在隐私预算一定时，添加到每个维度的噪声规模基本上与模型参数的数量成正比。因此，对于高维模型，可能需要非常多的参与方来减轻噪音对模型收敛的影响。为了解决上述“维度依赖”问题，MindSpore
Federated 进一步提供了基于维度选择的<strong>Sign-based Dimension Selection
(SignDS)</strong>
<span class="bibtex" id="id2">[jiang2022signds]</span>算法。SignDS算法的主要思想是，对于每一条真实的本地更新<span class="math notranslate nohighlight">\(\Delta\in\mathbb{R}^{d}\)</span>，用户端首先选择一小部分更新最明显的维度构建topk集合<span class="math notranslate nohighlight">\(S_k\)</span>，并以此选择一个维度集合<span class="math notranslate nohighlight">\(J\)</span>返回给FL-Server。FL-Server根据维度集合<span class="math notranslate nohighlight">\(J\)</span>构建一条对应的稀疏更新<span class="math notranslate nohighlight">\(\Delta^\prime\)</span>，并聚合所有稀疏更新进用于更新全局模型。由于本地模型更新与本地数据信息相关联，直接选取真实的最大更新维度可能导致隐私泄露。对此，SignDS算法在两方面实现了隐私保证。一方面，算法使用了一种基于指数机制（Exponential
Mechanism， EM
<span class="bibtex" id="id3">[mcsherry2007mechanism]</span>）的维度选择算法<strong>EM-MDS</strong>，使得所选维度集满足严格的<span class="math notranslate nohighlight">\(\epsilon\)</span>-LDP保证；另一方面，在构建稀疏更新时，对所选维度分配一个常量值而不直接使用实际更新值，以保证稀疏更新和本地数据不再直接关联。由于维度选择满足<span class="math notranslate nohighlight">\(\epsilon\)</span>-LDP，且分配给所选维度的更新值与本地数据无关，根据差分隐私的传递性
<span class="bibtex" id="id4">[dwork2014algorithmic]</span>，所构建的稀疏更新同样满足<span class="math notranslate nohighlight">\(\epsilon\)</span>-LDP保证。<strong>相较于之前基于维度加噪的LDP算法，SignDS算法可以显著提升高维模型的训练精度。同时，由于FL-Client只需上传一小部分的维度值而不是所有的模型权重，因此联邦学习的上行通信量也被大大降低。</strong></p>
<p>下面，我们分别对topk集合<span class="math notranslate nohighlight">\(S_k\)</span>的构建和EM-MDS维度选择算法进行详细介绍。</p>
<p>首先，由于实际更新值有正负，直接给所有选定的维度分配相同的常量值可能会明显改变模型更新方向，影响模型收敛。为了解决这个问题，SignDS提出了一种基于符号的topk集合构建策略。具体来讲，算法引入了一个额外的符号变量<span class="math notranslate nohighlight">\(s\in\\{-1,1\\}\)</span>。该变量由FL-Client以等概率随机采样，用于确定本地更新<span class="math notranslate nohighlight">\(\Delta\)</span>的topk集合<span class="math notranslate nohighlight">\(S_k\)</span>。如果<span class="math notranslate nohighlight">\(s=1\)</span>，我们将<span class="math notranslate nohighlight">\(\Delta\)</span>按<strong>真实更新值</strong>排序，并将<strong>最大</strong>的<span class="math notranslate nohighlight">\(k\)</span>个更新维度记为<span class="math notranslate nohighlight">\(S_k\)</span>。我们进一步从<span class="math notranslate nohighlight">\(S_k\)</span>中随机选择一部分维度，并将<span class="math notranslate nohighlight">\(s=1\)</span>作为这些维度的更新值用以构建稀疏更新。直觉上，<span class="math notranslate nohighlight">\(S_k\)</span>中维度的更新值很可能大于零。因此，将<span class="math notranslate nohighlight">\(s=1\)</span>分配给选定的维度不会导致模型更新方向的太大差异，从而减轻了对模型精度的影响。类似的，当<span class="math notranslate nohighlight">\(s=-1\)</span>时，我们选取<strong>最小</strong>的<span class="math notranslate nohighlight">\(k\)</span>个更新维度记为<span class="math notranslate nohighlight">\(S_k\)</span>，并将<span class="math notranslate nohighlight">\(s=-1\)</span>分配给所选维度。</p>
<p>下面，我们进一步介绍用于维度选择的EM-MDS算法。简单来说，EM-MDS算法的目的是从输出维度域<span class="math notranslate nohighlight">\(\mathcal{J}\)</span>中以一定概率<span class="math notranslate nohighlight">\(\mathcal{P}\)</span>随机选择一个维度集合<span class="math notranslate nohighlight">\(J\in\mathcal{J}\)</span>，不同维度集合对应的概率不同。我们假设<span class="math notranslate nohighlight">\(J\)</span>总共包含<span class="math notranslate nohighlight">\(h\)</span>个维度，其中有<span class="math notranslate nohighlight">\(\nu\)</span>个维度属于topk集合（即<span class="math notranslate nohighlight">\(|S_k \cap J|=\nu\)</span>，且<span class="math notranslate nohighlight">\(\nu\in[0,h]\)</span>），另外<span class="math notranslate nohighlight">\(h-\nu\)</span>个维度属于非topk集合。直观上，<span class="math notranslate nohighlight">\(\nu\)</span>越大，<span class="math notranslate nohighlight">\(J\)</span>中包含的topk维度越多，模型收敛越好。因此，我们希望给<span class="math notranslate nohighlight">\(\nu\)</span>较大的维度集合分配更高的概率。基于这个想法，我们将评分函数定义为：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-4">
<span class="eqno">(14.4.5)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-4" title="Permalink to this equation">¶</a></span>\[u(S_{k}, J) = 𝟙(|S_k\cap J| \geq \nu_{th}) =  𝟙(\nu \geq \nu_{th})
:label: score_function\]</div>
<p><span class="math notranslate nohighlight">\(u(S_{k}, J)\)</span>用来衡量输出维度集合<span class="math notranslate nohighlight">\(J\)</span>中包含的topk维度的数量是否超过某一阈值<span class="math notranslate nohighlight">\(\nu_{th}\)</span>（<span class="math notranslate nohighlight">\(\nu_{th}\in[1,h]\)</span>），超过则为1，否则为0。进一步，<span class="math notranslate nohighlight">\(u(S_{k}, J)\)</span>的敏感度可计算为：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-5">
<span class="eqno">(14.4.6)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-5" title="Permalink to this equation">¶</a></span>\[\phi = \max_{J\in\mathcal{J}} ||u(S_{k}, J) - u(S^\prime_{k}, J)||= 1 - 0 = 1
:label: sensitivity\]</div>
<p>注意
<code class="xref eq docutils literal notranslate"><span class="pre">sensitivity</span></code>对于任意一对不同的topk集合<span class="math notranslate nohighlight">\(S_k\)</span>和<span class="math notranslate nohighlight">\(S_k^\prime\)</span>均成立。</p>
<p>根据以上定义，EM-MDS算法描述如下：</p>
<p><em>给定真实本地更新:math:`Deltainmathbb{R}^{d}`的topk集合:math:`S_k`和隐私预算:math:`epsilon`，输出维度集合:math:`Jinmathcal{J}`的采样概率为：</em></p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-6">
<span class="eqno">(14.4.7)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-6" title="Permalink to this equation">¶</a></span>\[    \mathcal{P}=\frac{\mathrm{exp}(\frac{\epsilon}{\phi}\cdot u(S_{k}, J))}{\sum_{J^\prime\in\mathcal{J}}\mathrm{exp}(\frac{\epsilon}{\phi}\cdot u(S_{k}, J^\prime))}
    =
    \frac{\mathrm{exp}(\epsilon\cdot 𝟙(\nu \geq \nu_{th}))}{\sum_{\tau=0}^{\tau=h}\omega_{\tau}\cdot \mathrm{exp}(\epsilon\cdot 𝟙(\tau\geq\nu_{th}))}
    =
    \frac{\mathrm{exp}(\epsilon\cdot 𝟙(\nu \geq \nu_{th}))}{\sum_{\tau=0}^{\tau=\nu_{th}-1}\omega_{\tau} + \sum_{\tau=\nu_{th}}^{\tau=h}\omega_{\tau}\cdot \mathrm{exp}(\epsilon)}
:label: emmds\]</div>
<p><em>其中，:math:`nu`是:math:`J`中包含的topk维度数量，:math:`nu_{th}`是评分函数的阈值，:math:`J^prime`是任意一输出维度集合，:math:`omega_{tau}=binom{k}{tau}binom{d-k}{h-tau}`是所有包含:math:`tau`个topk维度的集合数。</em></p>
<p>我们进一步提供了EM-MDS算法的隐私证明:</p>
<p>对于每个FL-Client，给定随机采样的符号值<span class="math notranslate nohighlight">\(x\)</span>，任意两个本地更新<span class="math notranslate nohighlight">\(\Delta\)</span>，<span class="math notranslate nohighlight">\(\Delta^\prime\)</span>的topk集合记为<span class="math notranslate nohighlight">\(S_k\)</span>和<span class="math notranslate nohighlight">\(S_k^\prime\)</span>，对于任意输出维度集合<span class="math notranslate nohighlight">\(J\in\mathcal{J}\)</span>，令<span class="math notranslate nohighlight">\(\nu=|S_k \cap J|\)</span>,
<span class="math notranslate nohighlight">\(\nu^\prime=|S_k^\prime \cap J|\)</span>为<span class="math notranslate nohighlight">\(J\)</span>与两组topk维度集的交集数量。根据
<code class="xref eq docutils literal notranslate"><span class="pre">emmds</span></code>，以下不等式成立：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-7">
<span class="eqno">(14.4.8)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-7" title="Permalink to this equation">¶</a></span>\[\begin{split}\frac{\mathrm{Pr}\[J|\Delta\]}{\mathrm{Pr}\[J|\Delta^\prime\]} = \frac{\mathrm{Pr}\[J|S_{k}\]}{\mathrm{Pr}\[J|S^\prime_{k}\]} = \frac{\frac{\mathrm{exp}(\frac{\epsilon}{\phi}\cdot u(S_{k}, J))}{\sum_{J^\prime\in\mathcal{J}}\mathrm{exp}(\frac{\epsilon}{\phi}\cdot u(S_{k}, J^\prime))}}{\frac{\mathrm{exp}(\frac{\epsilon}{\phi}\cdot u(S^\prime_{k}, J))}{\sum_{J^\prime\in\mathcal{J}}\mathrm{exp}(\frac{\epsilon}{\phi}\cdot u(S^\prime_{k}, J^\prime))}}
    = \frac{\frac{\mathrm{exp}(\epsilon\cdot 𝟙(\nu \geq \nu_{th}))}{\sum_{\tau=0}^{\tau=h}\omega_{\tau}\cdot \mathrm{exp}(\epsilon\cdot 𝟙(\tau\geq\nu_{th}))}}{\frac{
    \mathrm{exp}(\epsilon\cdot 𝟙(\nu^\prime \geq \nu_{th}))}{\sum_{\tau=0}^{\tau=h}\omega_{\tau}\cdot \mathrm{exp}(\epsilon\cdot 𝟙(\tau\geq\nu_{th}))}} \\
    = \frac{\mathrm{exp}(\epsilon\cdot 𝟙(\nu \geq \nu_{th}))}{
    \mathrm{exp}(\epsilon\cdot 𝟙(\nu^\prime \geq \nu_{th}))}
    \leq \frac{\mathrm{exp}(\epsilon\cdot 1)}{\mathrm{exp}(\epsilon\cdot 0)} = \mathrm{exp}(\epsilon)\end{split}\]</div>
<p><em>证明EM-MDS算法满足:math:`epsilon`-LDP保证。</em></p>
<p>值得注意的是，计算
<code class="xref eq docutils literal notranslate"><span class="pre">emmds</span></code>需要先确定topk维度数的阈值<span class="math notranslate nohighlight">\(\nu_{th}\)</span>。为此，我们首先推导在给定阈值<span class="math notranslate nohighlight">\(\nu_{th}\)</span>时，任意一组输出维度集合<span class="math notranslate nohighlight">\(J\)</span>包含的topk维度的概率分布和期望：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-8">
<span class="eqno">(14.4.9)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-8" title="Permalink to this equation">¶</a></span>\[\begin{split}\mathrm{Pr}(\nu=\tau|\nu_{th})=
    \begin{cases}
        \omega_{\tau} / \Omega \quad \quad \quad \quad \quad \mathrm{ } &amp;if \quad \tau\in\[0,\nu_{th}\) \\
        \omega_{\tau}\cdot\mathrm{exp}(\epsilon) / \Omega \quad \quad &amp;if \quad \tau\in\[\nu_{th},h\]
    \end{cases}
:label: discrete-prob\end{split}\]</div>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-9">
<span class="eqno">(14.4.10)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-9" title="Permalink to this equation">¶</a></span>\[    \mathbb{E}\[\nu|\nu_{th}\] = \sum_{\tau=0}^{\tau=h}\tau\cdot \mathrm{Pr}(\nu=\tau|\nu_{th})
:label: expectation\]</div>
<p>这里，<span class="math notranslate nohighlight">\(\Omega\)</span>为
<code class="xref eq docutils literal notranslate"><span class="pre">emmds</span></code>中<span class="math notranslate nohighlight">\(\mathcal{P}\)</span>的分母部分。直觉上，<span class="math notranslate nohighlight">\(\mathbb{E}\[\nu|\nu_{th}\]\)</span>越高，随机采样的<span class="math notranslate nohighlight">\(J\)</span>集合中包含的topk维度的概率就越大，从而模型效用就越好。因此，我们将<span class="math notranslate nohighlight">\(\mathbb{E}\[\nu|\nu_{th}\]\)</span>最高时的阈值确定为目标阈值<span class="math notranslate nohighlight">\(\nu_{th}^{\*}\)</span>，即：</p>
<div class="math notranslate nohighlight" id="equation-chapter-federated-learning-privacy-encryption-algorithm-10">
<span class="eqno">(14.4.11)<a class="headerlink" href="#equation-chapter-federated-learning-privacy-encryption-algorithm-10" title="Permalink to this equation">¶</a></span>\[\nu_{th}^{\*} = \underset{\nu_{th}\in\[1, h\]}{\operatorname{argmax}} \mathbb{E}\[\nu|\nu_{th}\]
:label: threshold\]</div>
<p>最后，我们在
<a class="reference internal" href="#signds-workflow"><span class="std std-numref">图14.4.1</span></a>中描述了SignDS算法的详细流程。给定本地模型更新<span class="math notranslate nohighlight">\(\Delta\)</span>，我们首先随机采样一个符号值<span class="math notranslate nohighlight">\(s\)</span>并构建topk集合<span class="math notranslate nohighlight">\(S_k\)</span>。接下来，我们根据
<code class="xref eq docutils literal notranslate"><span class="pre">threshold</span></code>确定阈值<span class="math notranslate nohighlight">\(\nu_{th}^{\*}\)</span>并遵循
<code class="xref eq docutils literal notranslate"><span class="pre">emmds</span></code>定义的概率选择输出集合<span class="math notranslate nohighlight">\(J\)</span>。考虑到输出域<span class="math notranslate nohighlight">\(\mathcal{J}\)</span>包含<span class="math notranslate nohighlight">\(\binom{d}{k}\)</span>个可能的维度集合，以一定概率直接从<span class="math notranslate nohighlight">\(\mathcal{J}\)</span>中随机采样一个组合需要很大的计算成本和空间成本。因此，我们采用了逆采样算法以提升计算效率。具体来说，我们首先从标准均匀分布中采样一个随机值<span class="math notranslate nohighlight">\(\beta\sim U(0,1)\)</span>，并根据
<code class="xref eq docutils literal notranslate"><span class="pre">discrete-prob</span></code>中<span class="math notranslate nohighlight">\(p(\nu=\tau|\nu_{th})\)</span>的累计概率分布<span class="math notranslate nohighlight">\(CDF_{\tau}\)</span>确定输出维度集合中包含的topk维度数<span class="math notranslate nohighlight">\(\nu\)</span>。最后，我们从topk集合<span class="math notranslate nohighlight">\(S_k\)</span>中随机选取<span class="math notranslate nohighlight">\(\nu\)</span>个维度，从非topk集合中随机采样<span class="math notranslate nohighlight">\(h-\nu\)</span>个维度，以构建最终的输出维度集合<span class="math notranslate nohighlight">\(J\)</span>。</p>
<div class="figure align-default" id="id5">
<span id="signds-workflow"></span><a class="reference internal image-reference" href="../_images/ch10-federated-learning-signds.PNG"><img alt="../_images/ch10-federated-learning-signds.PNG" src="../_images/ch10-federated-learning-signds.PNG" style="width: 800px;" /></a>
<p class="caption"><span class="caption-number">图14.4.1 </span><span class="caption-text">SignDS工作流程</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">14.4. 隐私加密算法</a><ul>
<li><a class="reference internal" href="#ldp">14.4.1. 基于LDP的安全聚合</a></li>
<li><a class="reference internal" href="#mpc">14.4.2. 基于MPC的安全聚合</a></li>
<li><a class="reference internal" href="#ldp-signds">14.4.3. 基于LDP-SignDS算法的安全聚合</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="vertical_fl.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>14.3. 纵向联邦学习</div>
         </div>
     </a>
     <a id="button-next" href="outlook.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>14.5. 展望</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>