<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>参考文献 &#8212; 机器学习系统：设计和实现 1.0.0 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/d2l.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="3. 经典机器学习方法" href="../appendix_machine_learning_introduction/classic_machine_learning.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active">参考文献</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_references/index.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  机器学习系统：设计和实现
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">1.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">1.2. 机器学习系统的需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">1.3. 机器学习系统基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">1.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">2. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">2.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">2.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">2.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">2.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">3.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">3.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">3.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">3.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">3.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">4. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">5. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">5.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">5.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">5.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">5.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">5.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">5.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">6. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">6.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">6.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">6.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">6.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">6.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">7. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">7.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">7.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html">7.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">8. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">8.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">8.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">8.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">8.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">8.6. 章节总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">9. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">9.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">9.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">9.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">9.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">9.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">10. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">10.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">10.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">10.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">10.4. 集合通讯</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">10.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">10.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">11. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">12. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">12.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">12.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">12.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">12.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">12.5. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_federated_learning/index.html">13. 联邦学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/overview.html">13.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/system_architecture.html">13.2. 系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/fedavg.html">13.3. 联邦平均算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/privacy_encryption_algorithm.html">13.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/challenge.html">13.5. 实际部署时的挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/summary.html">13.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">14. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">14.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">14.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">14.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">14.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">14.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_explainable_AI/index.html">15. 可解释性AI系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html">15.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#ai">15.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id2">15.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id8">15.4. 未来可解释AI</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">参考文献</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  机器学习系统：设计和实现
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">1.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">1.2. 机器学习系统的需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">1.3. 机器学习系统基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">1.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">2. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">2.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">2.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">2.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">2.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">3.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">3.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">3.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">3.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">3.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_advanced/index.html">4. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_frontend_and_ir/index.html">5. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">5.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">5.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/ad.html">5.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">5.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">5.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_frontend_and_ir/summary.html">5.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_backend_and_runtime/index.html">6. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/overview.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/graph_optimizer.html">6.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/kernel_selecter.html">6.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/memory_allocator.html">6.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/compute_schedule_and_execute.html">6.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_backend_and_runtime/summary.html">6.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_accelerator/index.html">7. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">7.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">7.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_accelerator/summary.html">7.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing/index.html">8. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/requirements.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/program_model.html">8.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/performance.html">8.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/data_order.html">8.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/extension.html">8.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing/summary.html">8.6. 章节总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">9. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">9.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">9.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">9.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">9.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">9.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">9.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training/index.html">10. 分布式训练</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/overview.html">10.1. 系统概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/methods.html">10.2. 分布式方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/pipeline.html">10.3. 流水线并行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/collective.html">10.4. 集合通讯</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">10.5. 参数服务器</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_distributed_training/summary.html">10.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface_extension/index.html">11. 第三部分：拓展篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_recommender_system/index.html">12. 深度学习推荐系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/overview.html">12.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_architecture.html">12.2. 主流系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/system_problem.html">12.3. 现有解决方案及其存在的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/future.html">12.4. 未来可以探索的方向</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_recommender_system/summary.html">12.5. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_federated_learning/index.html">13. 联邦学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/overview.html">13.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/system_architecture.html">13.2. 系统架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/fedavg.html">13.3. 联邦平均算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/privacy_encryption_algorithm.html">13.4. 隐私加密算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/challenge.html">13.5. 实际部署时的挑战</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_federated_learning/summary.html">13.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_reinforcement_learning/index.html">14. 强化学习系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/rl_introduction.html">14.1. 强化学习介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/single_node_rl.html">14.2. 单节点强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/distributed_node_rl.html">14.3. 分布式强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl.html">14.4. 多智能体强化学习</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/marl_sys.html">14.5. 多智能体强化学习系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_reinforcement_learning/summary.html">14.6. 小结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_explainable_AI/index.html">15. 可解释性AI系统</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html">15.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#ai">15.2. 可解释AI定义</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id2">15.3. 可解释AI算法现状介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_explainable_AI/explainable_ai.html#id8">15.4. 未来可解释AI</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../appendix_machine_learning_introduction/index.html">附录：机器学习介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">3. 经典机器学习方法</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">参考文献</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <section id="id1">
<h1>参考文献<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
</section>
<p id="bibtex-bibliography-chapter_references/index-0"><dl class="bibtex citation">
<dt class="bibtex label" id="compilers"><span class="brackets">Aho et al., 2007</span></dt>
<dd><p>Aho, A. V., Lam, M. S., Ullman, J. D., &amp; Sethi, R. (2007). <em>Compilers: Principles, Techniques, and Tools (Rental), 2nd Edition</em>.</p>
</dd>
<dt class="bibtex label" id="bastoul2004code"><span class="brackets">Bastoul, 2004</span></dt>
<dd><p>Bastoul, C. (2004). Code generation in the polyhedral model is easier than you think. <em>Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004.</em> (pp. 7–16).</p>
</dd>
<dt class="bibtex label" id="numerical"><span class="brackets">Burden &amp; Faires, 2015</span></dt>
<dd><p>Burden, R. L., &amp; Faires, J. (2015). Numerical analysis. <em>Journal of the Royal Statistical Society</em>, <em>71</em>(1), 48-50.</p>
</dd>
<dt class="bibtex label" id="chen2018tvm"><span class="brackets">Chen et al., 2018</span></dt>
<dd><p>Chen, T., Moreau, T., Jiang, Z., Shen, H., Yan, E. Q., Wang, L., … Krishnamurthy, A. (2018). Tvm: end-to-end optimization stack for deep learning. <em>arXiv preprint arXiv:1802.04799</em>, <em>11</em>, 20.</p>
</dd>
<dt class="bibtex label" id="id2"><span class="brackets">Cheng et al., 2016</span></dt>
<dd><p>Cheng, H.-T., Koc, L., Harmsen, J., Shaked, T., Chandra, T., Aradhye, H., … Shah, H. (2016). Wide &amp;amp; deep learning for recommender systems. <em>Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</em> (pp. 7–10). New York, NY, USA: Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/2988450.2988454">https://doi.org/10.1145/2988450.2988454</a>, <a class="reference external" href="https://doi.org/10.1145/2988450.2988454">doi:10.1145/2988450.2988454</a></p>
</dd>
<dt class="bibtex label" id="id3"><span class="brackets">Chu et al., 2011</span></dt>
<dd><p>Chu, W., Zinkevich, M., Li, L., Thomas, A., &amp; Tseng, B. (2011). Unbiased online active learning in data streams. <em>Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> (pp. 195–203). New York, NY, USA: Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/2020408.2020444">https://doi.org/10.1145/2020408.2020444</a>, <a class="reference external" href="https://doi.org/10.1145/2020408.2020444">doi:10.1145/2020408.2020444</a></p>
</dd>
<dt class="bibtex label" id="id4"><span class="brackets">Corliss, 1988</span></dt>
<dd><p>Corliss, G. F. (1988). Applications of differentiation arithmetic. <em>Reliability in Computing: The Role of Interval Methods in Scientific Computing</em> (pp. 127–148). USA: Academic Press Professional, Inc.</p>
</dd>
<dt class="bibtex label" id="the"><span class="brackets">Dauvergne &amp; Hascoet, 2006</span></dt>
<dd><p>Dauvergne, B., &amp; Hascoët, L. (2006). The data-flow equations of checkpointing in reverse automatic differentiation. <em>Computational Science-iccs, International Conference, Reading, Uk, May</em>.</p>
</dd>
<dt class="bibtex label" id="duchi2011adagrad"><span class="brackets">Duchi et al., 2011</span></dt>
<dd><p>Duchi, J., Hazan, E., &amp; Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. <em>Journal of Machine Learning Research (JMLR)</em>, <em>12</em>(Jul), 2121–2159.</p>
</dd>
<dt class="bibtex label" id="erhan2009visualizing"><span class="brackets">Erhan et al., 2009</span></dt>
<dd><p>Erhan, D., Bengio, Y., Courville, A., &amp; Vincent, P. (2009). Visualizing higher-layer features of a deep network. <em>University of Montreal</em>, <em>1341</em>(3), 1.</p>
</dd>
<dt class="bibtex label" id="fetterly2009dryadlinq"><span class="brackets">Fetterly et al., 2009</span></dt>
<dd><p>Fetterly, Y. Y. M. I. D., Budiu, M., Erlingsson, Ú., &amp; Currey, P. K. G. J. (2009). Dryadlinq: a system for general-purpose distributed data-parallel computing using a high-level language. <em>Proc. LSDS-IR</em>, <em>8</em>.</p>
</dd>
<dt class="bibtex label" id="ginart2021mixed"><span class="brackets">Ginart et al., 2021</span></dt>
<dd><p>Ginart, A., Naumov, M., Mudigere, D., Yang, J., &amp; Zou, J. (2021). <em>Mixed Dimension Embeddings with Application to Memory-Efficient Recommendation Systems</em>.</p>
</dd>
<dt class="bibtex label" id="gong2020edgerec"><span class="brackets">Gong et al., 2020</span></dt>
<dd><p>Gong, Y., Jiang, Z., Feng, Y., Hu, B., Zhao, K., Liu, Q., &amp; Ou, W. (2020). Edgerec: recommender system on edge in mobile taobao. <em>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</em> (pp. 2477–2484).</p>
</dd>
<dt class="bibtex label" id="computer"><span class="brackets">Grabmeier et al., 2003</span></dt>
<dd><p>Grabmeier, J., Kaltofen, E., &amp; Weispfenning, V. (2003). <em>Computer Algebra Handbook: Foundations * Applications * Systems</em>. Computer algebra handbook : foundations, applications, systems.</p>
</dd>
<dt class="bibtex label" id="id5"><span class="brackets">Griewank &amp; Walther, 2008</span></dt>
<dd><p>Griewank, A., &amp; Walther, A. (2008). <em>Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation</em>. Second ed. USA: Society for Industrial and Applied Mathematics.</p>
</dd>
<dt class="bibtex label" id="rmpygil"><span class="brackets">Gross, 2021</span></dt>
<dd><p>Gross, S. (2021). <em>Multithreaded Python without the GIL</em>. <span><a class="reference external" href="#"></a></span>https://docs.google.com/document/d/18CXhDb1ygxg-YXNBJNzfzZsDFosB5e6BfnXLlejd9l0/edit#heading=h.kcngwrty1lv.</p>
</dd>
<dt class="bibtex label" id="ijcai2017-239"><span class="brackets">Guo et al., 2017</span></dt>
<dd><p>Guo, H., TANG, R., Ye, Y., Li, Z., &amp; He, X. (2017). Deepfm: a factorization-machine based neural network for ctr prediction. <em>Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17</em> (pp. 1725–1731). URL: <a class="reference external" href="https://doi.org/10.24963/ijcai.2017/239">https://doi.org/10.24963/ijcai.2017/239</a>, <a class="reference external" href="https://doi.org/10.24963/ijcai.2017/239">doi:10.24963/ijcai.2017/239</a></p>
</dd>
<dt class="bibtex label" id="neurips2020-a1d4c20b"><span class="brackets">He et al., 2020</span></dt>
<dd><p>He, C., Annavaram, M., &amp; Avestimehr, S. (2020). Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., &amp; Lin, H. (Eds.). Group knowledge transfer: federated learning of large cnns at the edge. <em>Advances in Neural Information Processing Systems</em> (pp. 14068–14080). Curran Associates, Inc. URL: <a class="reference external" href="https://proceedings.neurips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf</a></p>
</dd>
<dt class="bibtex label" id="he2016deep"><span class="brackets">He et al., 2016</span></dt>
<dd><p>He, K., Zhang, X., Ren, S., &amp; Sun, J. (2016). Deep Residual Learning for Image Recognition. <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>.</p>
</dd>
<dt class="bibtex label" id="id6"><span class="brackets">He et al., 2014</span></dt>
<dd><p>He, X., Pan, J., Jin, O., Xu, T., Liu, B., Xu, T., … Candela, J. Q. (2014). Practical lessons from predicting clicks on ads at facebook. <em>Proceedings of the Eighth International Workshop on Data Mining for Online Advertising</em> (pp. 1–9). New York, NY, USA: Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/2648584.2648589">https://doi.org/10.1145/2648584.2648589</a>, <a class="reference external" href="https://doi.org/10.1145/2648584.2648589">doi:10.1145/2648584.2648589</a></p>
</dd>
<dt class="bibtex label" id="id7"><span class="brackets">Hindley, 1969</span></dt>
<dd><p>Hindley, R. (1969). The principal type-scheme of an object in combinatory logic. <em>Transactions of the American Mathematical Society</em>, <em>146</em>, 29-60.</p>
</dd>
<dt class="bibtex label" id="hochreiter1997lstm"><span class="brackets">Hochreiter et al., 1997</span></dt>
<dd><p>Hochreiter, S., Hochreiter, S., Schmidhuber, J., &amp; Schmidhuber, J. (1997). Long Short-Term Memory. <em>Neural Computation</em>, <em>9</em>(8), 1735–80.</p>
</dd>
<dt class="bibtex label" id="minddata"><span class="brackets">HuaWei, 2020</span></dt>
<dd><p>HuaWei (2020). <em>Dataset Plugin</em>. <span><a class="reference external" href="#"></a></span>https://gitee.com/mindspore/dataset-plugin.</p>
</dd>
<dt class="bibtex label" id="c"><span class="brackets">Jaervi &amp; Freeman, 2010</span></dt>
<dd><p>Jaervi, J., &amp; Freeman, J. (2010). C++ lambda expressions and closures. <em>Science of Computer Programming</em>, <em>75</em>(9), 762-772.</p>
</dd>
<dt class="bibtex label" id="mlsys2021-ec895663"><span class="brackets">Jiang et al., 2021</span></dt>
<dd><p>Jiang, W., He, Z., Zhang, S., Preuß er, T. B., Zeng, K., Feng, L., … Alonso, G. (2021). Smola, A., Dimakis, A., &amp; Stoica, I. (Eds.). Microrec: efficient recommendation inference by hardware and data structure solutions. <em>Proceedings of Machine Learning and Systems</em> (pp. 845–859). URL: <a class="reference external" href="https://proceedings.mlsys.org/paper/2021/file/ec8956637a99787bd197eacd77acce5e-Paper.pdf">https://proceedings.mlsys.org/paper/2021/file/ec8956637a99787bd197eacd77acce5e-Paper.pdf</a></p>
</dd>
<dt class="bibtex label" id="kim2018interpretability"><span class="brackets">Kim et al., 2018</span></dt>
<dd><p>Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., &amp; Sayres, R. (2018). <em>Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)</em>.</p>
</dd>
<dt class="bibtex label" id="kingmaadam2014"><span class="brackets">Kingma &amp; Ba, 2014</span></dt>
<dd><p>Kingma, D., &amp; Ba, J. (2014). Adam: a method for stochastic optimization. <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>.</p>
</dd>
<dt class="bibtex label" id="krizhevsky2012imagenet"><span class="brackets">Krizhevsky et al., 2012</span></dt>
<dd><p>Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. <em>Advances in Neural Information Processing Systems</em> (pp. 1097–1105).</p>
</dd>
<dt class="bibtex label" id="llvm"><span class="brackets">Lattner &amp; Adve, 2004</span></dt>
<dd><p>Lattner, C., &amp; Adve, V. (2004). Llvm: a compilation framework for lifelong program analysis &amp; transformation. <em>Code Generation and Optimization, 2004. CGO 2004. International Symposium on</em>.</p>
</dd>
<dt class="bibtex label" id="mlir"><span class="brackets">Lattner et al., 2020a</span></dt>
<dd><p>Lattner, C., Amini, M., Bondhugula, U., Cohen, A., Davis, A., Pienaar, J., … Zinenko, O. (2020). <em>MLIR: A Compiler Infrastructure for the End of Moore’s Law</em>.</p>
</dd>
<dt class="bibtex label" id="lattner2020mlir"><span class="brackets">Lattner et al., 2020b</span></dt>
<dd><p>Lattner, C., Amini, M., Bondhugula, U., Cohen, A., Davis, A., Pienaar, J., … Zinenko, O. (2020). Mlir: a compiler infrastructure for the end of moore’s law. <em>arXiv preprint arXiv:2002.11054</em>.</p>
</dd>
<dt class="bibtex label" id="lecun2015deep"><span class="brackets">LeCun et al., 2015</span></dt>
<dd><p>LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. <em>Nature</em>, <em>521</em>(7553), 436.</p>
</dd>
<dt class="bibtex label" id="lecun1989backpropagation"><span class="brackets">LeCun et al., 1989</span></dt>
<dd><p>LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., &amp; Jackel, L. D. (1989). Backpropagation applied to handwritten zip code recognition. <em>Neural computation</em>, <em>1</em>(4), 541–551.</p>
</dd>
<dt class="bibtex label" id="tkde-li"><span class="brackets">Li et al., 2020</span></dt>
<dd><p>Li, X.-H., Cao, C. C., Shi, Y., Bai, W., Gao, H., Qiu, L., … Chen, L. (2020). A survey of data-driven and knowledge-aware explainable ai. <em>IEEE Transactions on Knowledge and Data Engineering</em>, (), 1-1. <a class="reference external" href="https://doi.org/10.1109/TKDE.2020.2983930">doi:10.1109/TKDE.2020.2983930</a></p>
</dd>
<dt class="bibtex label" id="meijer2006linq"><span class="brackets">Meijer et al., 2006</span></dt>
<dd><p>Meijer, E., Beckman, B., &amp; Bierman, G. (2006). Linq: reconciling object, relations and xml in the. net framework. <em>Proceedings of the 2006 ACM SIGMOD international conference on Management of data</em> (pp. 706–706).</p>
</dd>
<dt class="bibtex label" id="a"><span class="brackets">Milner, 1978</span></dt>
<dd><p>Milner, R. (1978). A theory of type polymorphism in programming. <em>Journal of Computer and System Sciences</em>, <em>17</em>(3), 348-375.</p>
</dd>
<dt class="bibtex label" id="mohan2020analyzing"><span class="brackets">Mohan et al., 2020</span></dt>
<dd><p>Mohan, J., Phanishayee, A., Raniwala, A., &amp; Chidambaram, V. (2020). Analyzing and mitigating data stalls in dnn training. <em>arXiv preprint arXiv:2007.06775</em>.</p>
</dd>
<dt class="bibtex label" id="moritz2018ray"><span class="brackets">Moritz et al., 2018</span></dt>
<dd><p>Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., … others. (2018). Ray: a distributed framework for emerging $\$AI$\$ applications. <em>13th $\$USENIX$\$ Symposium on Operating Systems Design and Implementation ($\$OSDI$\$ 18)</em> (pp. 561–577).</p>
</dd>
<dt class="bibtex label" id="zionex"><span class="brackets">Mudigere et al., 2021</span></dt>
<dd><p>Mudigere, D., Hao, Y., Huang, J., Jia, Z., Tulloch, A., Sridharan, S., … others. (2021). Software-hardware co-design for fast and scalable training of deep learning recommendation models. <em>arXiv preprint arXiv:2104.05158</em>.</p>
</dd>
<dt class="bibtex label" id="murray2013naiad"><span class="brackets">Murray et al., 2013</span></dt>
<dd><p>Murray, D. G., McSherry, F., Isaacs, R., Isard, M., Barham, P., &amp; Abadi, M. (2013). Naiad: a timely dataflow system. <em>Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles</em> (pp. 439–455).</p>
</dd>
<dt class="bibtex label" id="murray2021tf"><span class="brackets">Murray et al., 2021</span></dt>
<dd><p>Murray, D. G., Simsa, J., Klimovic, A., &amp; Indyk, I. (2021). Tf. data: a machine learning data processing framework. <em>arXiv preprint arXiv:2101.12127</em>.</p>
</dd>
<dt class="bibtex label" id="naumov2019deep"><span class="brackets">Naumov et al., 2019</span></dt>
<dd><p>Naumov, M., Mudigere, D., Shi, H.-J. M., Huang, J., Sundaraman, N., Park, J., … others. (2019). Deep learning recommendation model for personalization and recommendation systems. <em>arXiv preprint arXiv:1906.00091</em>.</p>
</dd>
<dt class="bibtex label" id="nvidia"><span class="brackets">NVIDIA, 2017</span></dt>
<dd><p>NVIDIA (2017). <em>NVIDIA Tesla V100 GPU Architecture: The World’s Most Advanced Datacenter GPU</em>. <span><a class="reference external" href="#"></a></span>http://www.nvidia.com/object/volta-architecture-whitepaper.html.</p>
</dd>
<dt class="bibtex label" id="nvidia-dali"><span class="brackets">NVIDIA, 2018</span></dt>
<dd><p>NVIDIA (2018). <em>DALI</em>. <span><a class="reference external" href="#"></a></span>https://github.com/NVIDIA/DALI.</p>
</dd>
<dt class="bibtex label" id="automatic"><span class="brackets">Pearlmutter, 2015</span></dt>
<dd><p>Pearlmutter, B. A. (2015). Automatic differentiation in machine learning: a survey. <em>computer science</em>.</p>
</dd>
<dt class="bibtex label" id="ragan2013halide"><span class="brackets">Ragan-Kelley et al., 2013</span></dt>
<dd><p>Ragan-Kelley, J., Barnes, C., Adams, A., Paris, S., Durand, F., &amp; Amarasinghe, S. (2013). Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines. <em>Acm Sigplan Notices</em>, <em>48</em>(6), 519–530.</p>
</dd>
<dt class="bibtex label" id="modeling"><span class="brackets">Raihan et al., 2018</span></dt>
<dd><p>Raihan, M. A., Goli, N., &amp; Aamodt, T. (2018). Modeling deep learning accelerator enabled gpus. <em>arXiv e-prints arXiv:1811.08309</em>.</p>
</dd>
<dt class="bibtex label" id="richard1995a"><span class="brackets">Richard et al., 1995</span></dt>
<dd><p>Richard, A., &amp; Kelsey. (1995). A correspondence between continuation passing style and static single assignment form. <em>Acm Sigplan Notices</em>.</p>
</dd>
<dt class="bibtex label" id="riedl2019human"><span class="brackets">Riedl, 2019</span></dt>
<dd><p>Riedl, M. O. (2019). Human-centered artificial intelligence and machine learning. <em>Human Behavior and Emerging Technologies</em>, <em>1</em>(1), 33–36.</p>
</dd>
<dt class="bibtex label" id="rosenblatt1958perceptron"><span class="brackets">Rosenblatt, 1958</span></dt>
<dd><p>Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and organization in the brain. <em>Psychological Review</em>, <em>65</em>(6), 386.</p>
</dd>
<dt class="bibtex label" id="rumelhart1986learning"><span class="brackets">Rumelhart et al., 1986</span></dt>
<dd><p>Rumelhart, D. E., Hinton, G. E., &amp; Williams, R. J. (1986). Learning representations by back-propagating errors. <em>Nature</em>, <em>323</em>(6088), 533.</p>
</dd>
<dt class="bibtex label" id="id8"><span class="brackets">Shi et al., 2020</span></dt>
<dd><p>Shi, H.-J. M., Mudigere, D., Naumov, M., &amp; Yang, J. (2020). Compositional embeddings using complementary partitions for memory-efficient recommendation systems. <em>Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp;amp; Data Mining</em> (pp. 165–175). New York, NY, USA: Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/3394486.3403059">https://doi.org/10.1145/3394486.3403059</a>, <a class="reference external" href="https://doi.org/10.1145/3394486.3403059">doi:10.1145/3394486.3403059</a></p>
</dd>
<dt class="bibtex label" id="divide"><span class="brackets">Siskind &amp; Pearlmutter, 2017</span></dt>
<dd><p>Siskind, J. M., &amp; Pearlmutter, B. A. (2017). Divide-and-conquer checkpointing for arbitrary programs with no user annotation. <em>Optimization Methods and Software</em>, <em>33</em>(4-6).</p>
</dd>
<dt class="bibtex label" id="spuler1994compiler"><span class="brackets">Spuler &amp; Sajeev, 1994</span></dt>
<dd><p>Spuler, D. A., &amp; Sajeev, A. S. M. (1994). Compiler detection of function call side effects. <em>Informatica</em>, <em>18</em>(2), 219–227.</p>
</dd>
<dt class="bibtex label" id="id9"><span class="brackets">Tian et al., 2018</span></dt>
<dd><p>Tian, H., Yu, M., &amp; Wang, W. (2018). Continuum: a platform for cost-aware, low-latency continual learning. <em>Proceedings of the ACM Symposium on Cloud Computing</em> (pp. 26–40). New York, NY, USA: Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/3267809.3267817">https://doi.org/10.1145/3267809.3267817</a>, <a class="reference external" href="https://doi.org/10.1145/3267809.3267817">doi:10.1145/3267809.3267817</a></p>
</dd>
<dt class="bibtex label" id="tieleman2012rmsprop"><span class="brackets">Tieleman &amp; Hinton, 2017</span></dt>
<dd><p>Tieleman, T., &amp; Hinton, G. (2017). <em>Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning</em>. Technical Report.</p>
</dd>
<dt class="bibtex label" id="vasilache2022composable"><span class="brackets">Vasilache et al., 2022</span></dt>
<dd><p>Vasilache, N., Zinenko, O., Bik, A. J., Ravishankar, M., Raoux, T., Belyaev, A., … others. (2022). Composable and modular code generation in mlir: a structured and retargetable approach to tensor compiler construction. <em>arXiv preprint arXiv:2202.03293</em>.</p>
</dd>
<dt class="bibtex label" id="vaswani2017attention"><span class="brackets">Vaswani et al., 2017</span></dt>
<dd><p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017). Attention is all you need. <em>Advances in Neural Information Processing Systems</em> (pp. 5998–6008).</p>
</dd>
<dt class="bibtex label" id="verdoolaege2010isl"><span class="brackets">Verdoolaege, 2010</span></dt>
<dd><p>Verdoolaege, S. (2010). Isl: an integer set library for the polyhedral model. <em>International Congress on Mathematical Software</em> (pp. 299–302).</p>
</dd>
<dt class="bibtex label" id="an"><span class="brackets">Verma, 2000</span></dt>
<dd><p>Verma, A. (2000). An introduction to automatic differentiation. <em>Siam Computational Differentiation Techniques Applications &amp; Tools</em>, <em>78</em>(7), 804-807.</p>
</dd>
<dt class="bibtex label" id="id10"><span class="brackets">Wang et al., 2017</span></dt>
<dd><p>Wang, R., Fu, B., Fu, G., &amp; Wang, M. (2017). Deep &amp;amp; cross network for ad click predictions. <em>Proceedings of the ADKDD’17</em>. New York, NY, USA: Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/3124749.3124754">https://doi.org/10.1145/3124749.3124754</a>, <a class="reference external" href="https://doi.org/10.1145/3124749.3124754">doi:10.1145/3124749.3124754</a></p>
</dd>
<dt class="bibtex label" id="id11"><span class="brackets">Xie et al., 2020</span></dt>
<dd><p>Xie, M., Ren, K., Lu, Y., Yang, G., Xu, Q., Wu, B., … Shu, J. (2020). Kraken: memory-efficient continual learning for large-scale real-time recommendations. <em>SC20: International Conference for High Performance Computing, Networking, Storage and Analysis</em> (pp. 1–17). <a class="reference external" href="https://doi.org/10.1109/SC41405.2020.00025">doi:10.1109/SC41405.2020.00025</a></p>
</dd>
<dt class="bibtex label" id="mlsys2021-979d472a"><span class="brackets">Yin et al., 2021</span></dt>
<dd><p>Yin, C., Acun, B., Wu, C.-J., &amp; Liu, X. (2021). Smola, A., Dimakis, A., &amp; Stoica, I. (Eds.). Tt-rec: tensor train compression for deep learning recommendation models. <em>Proceedings of Machine Learning and Systems</em> (pp. 448–462). URL: <a class="reference external" href="https://proceedings.mlsys.org/paper/2021/file/979d472a84804b9f647bc185a877a8b5-Paper.pdf">https://proceedings.mlsys.org/paper/2021/file/979d472a84804b9f647bc185a877a8b5-Paper.pdf</a></p>
</dd>
<dt class="bibtex label" id="zaharia2010spark"><span class="brackets">Zaharia et al., 2010</span></dt>
<dd><p>Zaharia, M., Chowdhury, M., Franklin, M. J., Shenker, S., &amp; Stoica, I. (2010). Spark: cluster computing with working sets. <em>2nd USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 10)</em>.</p>
</dd>
<dt class="bibtex label" id="zhao2021akg"><span class="brackets">Zhao et al., 2021</span></dt>
<dd><p>Zhao, J., Li, B., Nie, W., Geng, Z., Zhang, R., Gao, X., … others. (2021). Akg: automatic kernel generation for neural processing units using polyhedral transformations. <em>Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation</em> (pp. 1233–1248).</p>
</dd>
<dt class="bibtex label" id="mlsys2020-f7e6c855"><span class="brackets">Zhao et al., 2020</span></dt>
<dd><p>Zhao, W., Xie, D., Jia, R., Qian, Y., Ding, R., Sun, M., &amp; Li, P. (2020). Dhillon, I., Papailiopoulos, D., &amp; Sze, V. (Eds.). Distributed hierarchical gpu parameter server for massive scale deep learning ads systems. <em>Proceedings of Machine Learning and Systems</em> (pp. 412–428). URL: <a class="reference external" href="https://proceedings.mlsys.org/paper/2020/file/f7e6c85504ce6e82442c770f7c8606f0-Paper.pdf">https://proceedings.mlsys.org/paper/2020/file/f7e6c85504ce6e82442c770f7c8606f0-Paper.pdf</a></p>
</dd>
<dt class="bibtex label" id="zheng2020ansor"><span class="brackets">Zheng et al., 2020</span></dt>
<dd><p>Zheng, L., Jia, C., Sun, M., Wu, Z., Yu, C. H., Haj-Ali, A., … others. (2020). Ansor: generating $\$High-Performance$\$ tensor programs for deep learning. <em>14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)</em> (pp. 863–879).</p>
</dd>
</dl>
</p>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../appendix_machine_learning_introduction/classic_machine_learning.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>3. 经典机器学习方法</div>
         </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>