<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>3. 经典机器学习方法 &#8212; 机器学习系统：设计和实现 1.0.0 documentation</title>

    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/d2l.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="2. 梯度下降与反向传播" href="gradient_descent.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="index.html"><span class="section-number">12. </span>附录：机器学习介绍</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active"><span class="section-number">3. </span>经典机器学习方法</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/appendix_Introduction_machine_learning/classic_machine_learning.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-zh">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  机器学习系统：设计和实现
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">1.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">1.2. 机器学习系统的需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">1.3. 机器学习系统基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">1.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">2. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">2.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">2.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">2.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">2.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">3.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">3.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">3.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">3.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">3.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/index.html">4. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/overview_of_frontend.html">4.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/intermediate_representation.html">4.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/ad.html">4.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/type_system_and_static_analysis.html">4.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/common_frontend_optimization_pass.html">4.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/summary.html">4.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/index.html">5. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/overview.html">5.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/graph_optimizer.html">5.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/kernel_selecter.html">5.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/memory_allocator.html">5.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/compute_schedule_and_execute.html">5.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/summary.html">5.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_hardware_accelerator/index.html">6. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/accelerator_introduction.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/accelerator_architecture.html">6.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/accelerator_programming.html">6.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/summary.html">6.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing_framework/index.html">7. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/requirements.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/program_model.html">7.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/performance.html">7.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/data_order.html">7.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/extension.html">7.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/summary.html">7.6. 章节总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/reference.html">7.7. 引用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">8. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">8.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">8.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">8.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">8.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">8.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training_system/index.html">分布式训练系统</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_transition_advanced/index.html">9. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_framework_expansion/index.html">10. 框架拓展</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">12. 附录：机器学习介绍</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3. 经典机器学习方法</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  机器学习系统：设计和实现
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../chapter_introduction/index.html">1. 导论</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">1.1. 机器学习应用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">1.2. 机器学习系统的需求</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">1.3. 机器学习系统基本组成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_introduction/applicable_readers.html">1.4. 适用读者</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_programming_interface/index.html">2. 编程接口</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/development_history.html">2.1. 机器学习系统编程模型的演进</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">2.2. 机器学习工作流</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">2.3. 定义深度神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">2.4. C/C++编程接口</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_programming_interface/summary.html">2.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_computational_graph/index.html">3. 计算图</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">3.1. 计算图的设计背景和作用</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">3.2. 计算图的基本构成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">3.3. 计算图的生成</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">3.4. 计算图的调度</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_computational_graph/summary.html">3.5. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/index.html">4. 编译器前端</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/overview_of_frontend.html">4.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/intermediate_representation.html">4.2. 中间表示</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/ad.html">4.3. 自动微分</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/type_system_and_static_analysis.html">4.4. 类型系统和静态分析</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/common_frontend_optimization_pass.html">4.5. 常见前端编译优化方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_frontend_and_ir/summary.html">4.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/index.html">5. 编译器后端和运行时</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/overview.html">5.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/graph_optimizer.html">5.2. 计算图优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/kernel_selecter.html">5.3. 算子选择</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/memory_allocator.html">5.4. 内存分配</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/compute_schedule_and_execute.html">5.5. 计算调度与执行</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_compiler_backend_and_runtime/summary.html">5.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_hardware_accelerator/index.html">6. 硬件加速器</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/accelerator_introduction.html">6.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/accelerator_architecture.html">6.2. 加速器基本组成原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/accelerator_programming.html">6.3. 加速器基本编程原理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_hardware_accelerator/summary.html">6.4. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_data_processing_framework/index.html">7. 数据处理框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/requirements.html">7.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/program_model.html">7.2. 易用性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/performance.html">7.3. 高效性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/data_order.html">7.4. 保序性设计</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/extension.html">7.5. 单机数据处理性能的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/summary.html">7.6. 章节总结</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_data_processing_framework/reference.html">7.7. 引用</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_model_deployment/index.html">8. 模型部署</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">8.1. 概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">8.2. 训练模型到推理模型的转换及优化</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_compression.html">8.3. 模型压缩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_inference.html">8.4. 模型推理</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/model_security.html">8.5. 模型的安全保护</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter_model_deployment/summary.html">8.6. 总结</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_distributed_training_system/index.html">分布式训练系统</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_transition_advanced/index.html">9. 第二部分：进阶篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_framework_expansion/index.html">10. 框架拓展</a><ul class="simple">
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">12. 附录：机器学习介绍</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="neural_network.html">1. 神经网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient_descent.html">2. 梯度下降与反向传播</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3. 经典机器学习方法</a></li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <section id="id1">
<h1><span class="section-number">3. </span>经典机器学习方法<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>大量经典机器学习算法，如 支持向量机(Support Vector Machine，SVM),
K最近邻(K-Nearest Neighbor, KNN)分类算法 和K均值聚类算法(K-Means
Clustering Algorithm)等，
虽然它们有的有网络参数，有的没有网络参数，有的是监督学习算法，有的是无监督学习算法，
训练过程也不一样，但是从系统的角度，它们都是以矩阵运算为基础的。下面，我们来简要介绍一下这些算法。</p>
<section id="id2">
<h2><span class="section-number">3.1. </span>支持向量机<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><strong>支持向量机</strong>(Support Vector
Machine，SVM)，是一种经典的机器学习分类算法，其核心思想在于最大化决策边界到数据点的距离。在这里，我们以线性可分数据为例；对于非线性可分的数据，运用<strong>核方法</strong>(Kernel
Method)即可类似处理。</p>
<p>如果训练数据是线性可分的，SVM的目标则是最大化<strong>间隔</strong>(Margin)。首先，我们先来定义最大化间隔的分类器，如下：</p>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-0">
<span class="eqno">(3.1.1)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-0" title="Permalink to this equation">¶</a></span>\[\min_{\bm{w},b} ~~~\frac{1}{2} ||\bm{w}||^2\]</div>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-1">
<span class="eqno">(3.1.2)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-1" title="Permalink to this equation">¶</a></span>\[s.t. ~~~y_i (\bm{w}^T \bm{x_i} + b) \geq 1, ~~~\forall 1 \leq i \leq n\]</div>
<p>其拉格朗日乘子为</p>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-2">
<span class="eqno">(3.1.3)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-2" title="Permalink to this equation">¶</a></span>\[L(\bm{w},b,\bm{\lambda}) = \frac{1}{2} ||\bm{w}||^2 + \sum_{i=1}^n \lambda_i (1-y_i(\bm{w}^T \bm{x_i} + b))\]</div>
<p>由于<span class="math notranslate nohighlight">\(\frac{1}{2} ||\bm{w}||^2\)</span>是凸的，并且<span class="math notranslate nohighlight">\(\lambda_i (1-y_i(\bm{w}^T \bm{x_i} + b))\)</span>是线性的（也是凸的），所以优化问题的解为</p>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-3">
<span class="eqno">(3.1.4)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-3" title="Permalink to this equation">¶</a></span>\[\max_{\lambda&gt;0} \min_{\bm{w},b} L(\bm{w},b, \bm{\lambda})\]</div>
<p>求<span class="math notranslate nohighlight">\(L\)</span>关于<span class="math notranslate nohighlight">\(\bm{w},b\)</span>的导数有</p>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-4">
<span class="eqno">(3.1.5)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-4" title="Permalink to this equation">¶</a></span>\[\nabla_{\bm{w}} L= \bm{w} - \sum_{i=1}^n \lambda_i y_i \bm{x_i}\]</div>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-5">
<span class="eqno">(3.1.6)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-5" title="Permalink to this equation">¶</a></span>\[\nabla_b L = - \sum_{i=1}^n \lambda_i y_i\]</div>
<p>令<span class="math notranslate nohighlight">\(L\)</span>关于<span class="math notranslate nohighlight">\(\bm{w},b\)</span>的导数均为0得到，<span class="math notranslate nohighlight">\(\bm{w}^* = \sum_{i=1}^n \lambda_i y_i \bm{x_i}\)</span>以及<span class="math notranslate nohighlight">\(\sum_{i=1}^n \lambda_i y_i = 0\)</span>。
由于当<span class="math notranslate nohighlight">\(\lambda\)</span>固定的时候，<span class="math notranslate nohighlight">\(b\)</span>的值对目标函数无贡献，所以可以令<span class="math notranslate nohighlight">\(b^* = 0\)</span>。
这时，由对偶性理论和KTT条件，我们得到：</p>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-6">
<span class="eqno">(3.1.7)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-6" title="Permalink to this equation">¶</a></span>\[y_i (\bm{w}^{*T} \bm{x_i} + b^*) &gt; 1 \Rightarrow \lambda_i^* = 0\]</div>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-7">
<span class="eqno">(3.1.8)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-7" title="Permalink to this equation">¶</a></span>\[\lambda_i^* &gt; 0  \Rightarrow y_i (\bm{w}^{*T} \bm{x_i} + b^*) = 1\]</div>
<div class="math notranslate nohighlight" id="equation-appendix-introduction-machine-learning-classic-machine-learning-8">
<span class="eqno">(3.1.9)<a class="headerlink" href="#equation-appendix-introduction-machine-learning-classic-machine-learning-8" title="Permalink to this equation">¶</a></span>\[\bm{w}^* = \sum_{i=1}^n \lambda_i^* y_i \bm{x_i}\]</div>
<p>如果<span class="math notranslate nohighlight">\(y_i (\bm{w}^{*T} \bm{x_i} + b^*) = 1\)</span>，那么<span class="math notranslate nohighlight">\(\bm{x_i}\)</span>就是离超平面<span class="math notranslate nohighlight">\((\bm{w}^*,b^*)\)</span>最近的点之一，否则就不是。因此，<span class="math notranslate nohighlight">\(\bm{w}^*\)</span>就是离超平面<span class="math notranslate nohighlight">\((\bm{w}^*,b^*)\)</span>最近的点<span class="math notranslate nohighlight">\(\bm{x_i}\)</span>的线性组合。</p>
<p>如此，通过SVM算法，我们实现了数据的分类，并且能够最大化了决策边界到最近点的距离。
我们定义满足<span class="math notranslate nohighlight">\(y_i (\bm{w}^{*T} \bm{x_i} + b^*) = 1\)</span>的<span class="math notranslate nohighlight">\(\bm{x_i}\)</span>为<strong>支持向量</strong>(Support
Vectors)，同时把分类器<span class="math notranslate nohighlight">\(\hat{y}=sgn(\bm{w}^{*T} \bm{x_i} + b^*)\)</span>称为支持向量机。</p>
</section>
<section id="k">
<h2><span class="section-number">3.2. </span>K最近邻算法<a class="headerlink" href="#k" title="Permalink to this headline">¶</a></h2>
<p><strong>K最近邻算法</strong>(K-Nearest
Neighbor，KNN)也是一种传统的机器学习算法，可用于分类、回归等基本的机器学习任务。和上面介绍的SVM算法不同，K最近邻算法的核心思想并不是用一个决策边界把属于不同类的数据分开，而是依靠每个数据点周围几个距离最近的数据的性质，来预测数据点本身的性质。</p>
<p>KNN用于分类时，为了预测某个样本点的类别，会进行一次投票。投票的对象为离这个观测样本点最近的K个样本点，每个要投票的样本点可能会被赋予不同的权重，而投票的”内容”则是样本点的类别。处理投票结果的时候，采用的是少数服从多数的决策方法(Majority
Vote)。也就是说，若一个样本点最近的K个样本点中大多数属于某个类别，那么该样本点也属于这个类别。</p>
<p>KNN算法的具体描述如下：（1）计算待分类点到各已知类别点的距离；（2）将这些点按照距离排序，并按照距离挑选出最近的K个点；（3）按照每个点的权重进行”统票”，票面内容为点所处的类别；（4）返回得票最高的类别，并作为待分类点的预测类别。</p>
<p>KNN算法有几个需要注意的关键问题，包括超参数K的选择，距离的度量方式，还有分类决策规则。对于超参数K，不宜过大，否则会导致很大的近似误差，反之亦不宜过小，否则会导致很大的估计误差。距离的度量，则可以选择曼哈顿距离、欧式距离和闵可夫斯基距离等等。为了降低K值对于预测结果产生的误差和影响，我们通常可以对分类决策规则做一定的规定，比如在投票决策时让距离小的点有更大的权重，距离较大的点权重较小。在编程实现KNN算法的时候，权重等参数都会以矩阵的形式进行运算，以提高运算效率。</p>
</section>
<section id="id3">
<h2><span class="section-number">3.3. </span>K均值聚类算法<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p><strong>K均值聚类算法</strong>(K-Means Clustering
Algorithm)是机器学习中一种常见的无监督聚类算法。在这里，我们首先定义聚类问题：给定数据点<span class="math notranslate nohighlight">\(\bm{x_1},\cdots, \bm{x_n} \in \mathbb{R}^d\)</span>和<span class="math notranslate nohighlight">\(K\in \mathbb{N}\)</span>，需要划分为<span class="math notranslate nohighlight">\(K\)</span>个簇<span class="math notranslate nohighlight">\(\bm{C_1}, \cdots, \bm{C_K} \in \mathbb{R}^d\)</span>以及每个数据点所对应的分类中心点<span class="math notranslate nohighlight">\(\bm{ C_{(1)}}, \cdots, \bm{C_{(n)}}\)</span>，以最小化距离和<span class="math notranslate nohighlight">\(\sum_i ||\bm{x_i} - \bm{C_{(i)}}||^2\)</span>。</p>
<p>K均值聚类算法是一种解决聚类问题的算法，算法过程如下：</p>
<ul class="simple">
<li><p>随机选择<span class="math notranslate nohighlight">\(\bm{C_1}, \cdots, \bm{C_K}\)</span></p></li>
<li><p>把<span class="math notranslate nohighlight">\(\bm{x_i}\)</span>所对应的分类置为距离其最近的聚类中心点的分类</p></li>
<li><p>计算并赋值<span class="math notranslate nohighlight">\(\bm{C_K} = \frac{\sum_{\bm{C_{(i)}}=\bm{C_K}} \bm{x_i}}{\sum_{\bm{C_{(i)}}=\bm{C_K}} 1}\)</span></p></li>
<li><p>重复以上步骤直到算法收敛</p></li>
</ul>
<p>可以证明，K均值聚类算法会使得距离和<span class="math notranslate nohighlight">\(\sum_i ||\bm{x_i} - \bm{C_{(i)}}||^2\)</span>不断地单调减小，并且最终能够收敛。不过，算法可能收敛到局部最小值。</p>
<p>本章结束语：</p>
<p>在系统角度，机器学习的算法无论是什么算法，涉及到高维数据任务的现都是矩阵运算实现的。</p>
</section>
</section>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">3. 经典机器学习方法</a><ul>
<li><a class="reference internal" href="#id2">3.1. 支持向量机</a></li>
<li><a class="reference internal" href="#k">3.2. K最近邻算法</a></li>
<li><a class="reference internal" href="#id3">3.3. K均值聚类算法</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="gradient_descent.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>2. 梯度下降与反向传播</div>
         </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>