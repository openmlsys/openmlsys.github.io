<!DOCTYPE html>
<html>
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="Docutils 0.17.1: http://docutils.sourceforge.net/" name="generator"/>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
  <meta content="ie=edge" http-equiv="x-ua-compatible"/>
  <title>
   6.5. 计算调度与执行 — 机器学习系统：设计和实现 1.0.0 documentation
  </title>
  <link href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/sphinx_materialdesign_theme.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/fontawesome/all.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/fonts.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/basic.css" rel="stylesheet" type="text/css"/>
  <link href="../_static/d2l.css" rel="stylesheet" type="text/css"/>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js">
  </script>
  <script src="../_static/jquery.js">
  </script>
  <script src="../_static/underscore.js">
  </script>
  <script src="../_static/doctools.js">
  </script>
  <script src="../_static/d2l.js">
  </script>
  <link href="../_static/favicon.png" rel="shortcut icon"/>
  <link href="../genindex.html" rel="index" title="Index"/>
  <link href="../search.html" rel="search" title="Search"/>
  <link href="summary.html" rel="next" title="6.6. 总结"/>
  <link href="memory_allocator.html" rel="prev" title="6.4. 内存分配"/>
 </head>
 <body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer">
   <header class="mdl-layout__header mdl-layout__header--waterfall">
    <div class="mdl-layout__header-row">
     <nav class="mdl-navigation breadcrumb">
      <a class="mdl-navigation__link" href="index.html">
       <span class="section-number">
        6.
       </span>
       编译器后端和运行时
      </a>
      <i class="material-icons">
       navigate_next
      </i>
      <a class="mdl-navigation__link is-active">
       <span class="section-number">
        6.5.
       </span>
       计算调度与执行
      </a>
     </nav>
     <div class="mdl-layout-spacer">
     </div>
     <nav class="mdl-navigation">
      <form action="../search.html" class="form-inline pull-sm-right" method="get">
       <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label class="mdl-button mdl-js-button mdl-button--icon" for="waterfall-exp" id="quick-search-icon">
         <i class="material-icons">
          search
         </i>
        </label>
        <div class="mdl-textfield__expandable-holder">
         <input class="mdl-textfield__input" id="waterfall-exp" name="q" placeholder="Search" type="text"/>
         <input name="check_keywords" type="hidden" value="yes"/>
         <input name="area" type="hidden" value="default"/>
        </div>
       </div>
       <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
        Quick search
       </div>
      </form>
      <a class="mdl-button mdl-js-button mdl-button--icon" href="../_sources/chapter_backend_and_runtime/compute_schedule_and_execute.rst.txt" id="button-show-source" rel="nofollow">
       <i class="material-icons">
        code
       </i>
      </a>
      <div class="mdl-tooltip" data-mdl-for="button-show-source">
       Show Source
      </div>
     </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
     <div class="mdl-layout-spacer">
     </div>
     <nav class="mdl-navigation">
      <a class="mdl-navigation__link" href="https://github.com/openmlsys/openmlsys-zh">
       <i class="fab fa-github">
       </i>
       GitHub
      </a>
     </nav>
    </div>
   </header>
   <header class="mdl-layout__drawer">
    <!-- Title -->
    <span class="mdl-layout-title">
     <a class="title" href="../index.html">
      <span class="title-text">
       机器学习系统：设计和实现
      </span>
     </a>
    </span>
    <div class="globaltoc">
     <span class="mdl-layout-title toc">
      Table Of Contents
     </span>
     <nav class="mdl-navigation">
      <ul class="current">
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_introduction/index.html">
         1. 导论
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">
           1.1. 机器学习应用
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">
           1.2. 机器学习系统的需求
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">
           1.3. 机器学习系统基本组成
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_introduction/applicable_readers.html">
           1.4. 适用读者
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_programming_interface/index.html">
         2. 编程接口
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_interface/development_history.html">
           2.1. 机器学习系统编程模型的演进
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">
           2.2. 机器学习工作流
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">
           2.3. 定义深度神经网络
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">
           2.4. C/C++编程接口
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_programming_interface/summary.html">
           2.5. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_computational_graph/index.html">
         3. 计算图
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">
           3.1. 计算图的设计背景和作用
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">
           3.2. 计算图的基本构成
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">
           3.3. 计算图的生成
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">
           3.4. 计算图的调度
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_computational_graph/summary.html">
           3.5. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_preface_advanced/index.html">
         4. 第二部分：进阶篇
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_frontend_and_ir/index.html">
         5. 编译器前端
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">
           5.1. 概述
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">
           5.2. 中间表示
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_frontend_and_ir/ad.html">
           5.3. 自动微分
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">
           5.4. 类型系统和静态分析
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">
           5.5. 常见前端编译优化方法
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_frontend_and_ir/summary.html">
           5.6. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1 current">
        <a class="reference internal" href="index.html">
         6. 编译器后端和运行时
        </a>
        <ul class="current">
         <li class="toctree-l2">
          <a class="reference internal" href="overview.html">
           6.1. 概述
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="graph_optimizer.html">
           6.2. 计算图优化
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="kernel_selecter.html">
           6.3. 算子选择
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="memory_allocator.html">
           6.4. 内存分配
          </a>
         </li>
         <li class="toctree-l2 current">
          <a class="current reference internal" href="#">
           6.5. 计算调度与执行
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="summary.html">
           6.6. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_accelerator/index.html">
         7. 硬件加速器
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">
           7.1. 概述
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">
           7.2. 加速器基本组成原理
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">
           7.3. 加速器基本编程原理
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_accelerator/summary.html">
           7.4. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_data_processing/index.html">
         8. 数据处理框架
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_data_processing/requirements.html">
           8.1. 概述
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_data_processing/program_model.html">
           8.2. 易用性设计
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_data_processing/performance.html">
           8.3. 高效性设计
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_data_processing/data_order.html">
           8.4. 保序性设计
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_data_processing/extension.html">
           8.5. 单机数据处理性能的扩展
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_data_processing/summary.html">
           8.6. 章节总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_model_deployment/index.html">
         9. 模型部署
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">
           9.1. 概述
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">
           9.2. 训练模型到推理模型的转换及优化
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_model_deployment/model_compression.html">
           9.3. 模型压缩
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_model_deployment/model_inference.html">
           9.4. 模型推理
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_model_deployment/model_security.html">
           9.5. 模型的安全保护
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_model_deployment/summary.html">
           9.6. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_distributed_training/index.html">
         10. 分布式训练
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed_training/overview.html">
           10.1. 系统概述
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed_training/methods.html">
           10.2. 分布式方法
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed_training/pipeline.html">
           10.3. 流水线并行
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed_training/collective.html">
           10.4. 集合通讯
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">
           10.5. 参数服务器
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../chapter_distributed_training/summary.html">
           10.6. 总结
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_preface_extension/index.html">
         11. 第三部分：拓展篇
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_federated_learning/index.html">
         12. 联邦学习系统
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_reinforcement_learning/index.html">
         13. 强化学习系统
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_explainable_AI/index.html">
         14. 可解释性AI系统
        </a>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_online_machine_learning/index.html">
         15. 在线机器学习
        </a>
       </li>
      </ul>
      <ul>
       <li class="toctree-l1">
        <a class="reference internal" href="../appendix_machine_learning_introduction/index.html">
         附录：机器学习介绍
        </a>
        <ul>
         <li class="toctree-l2">
          <a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">
           1. 神经网络
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">
           2. 梯度下降与反向传播
          </a>
         </li>
         <li class="toctree-l2">
          <a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">
           3. 经典机器学习方法
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l1">
        <a class="reference internal" href="../chapter_references/index.html">
         参考文献
        </a>
       </li>
      </ul>
     </nav>
    </div>
   </header>
   <main class="mdl-layout__content" tabindex="0">
    <script src="../_static/sphinx_materialdesign_theme.js " type="text/javascript">
    </script>
    <header class="mdl-layout__drawer">
     <!-- Title -->
     <span class="mdl-layout-title">
      <a class="title" href="../index.html">
       <span class="title-text">
        机器学习系统：设计和实现
       </span>
      </a>
     </span>
     <div class="globaltoc">
      <span class="mdl-layout-title toc">
       Table Of Contents
      </span>
      <nav class="mdl-navigation">
       <ul class="current">
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_introduction/index.html">
          1. 导论
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/machine_learning_applications.html">
            1.1. 机器学习应用
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/requirements_for_machine_learning_systems.html">
            1.2. 机器学习系统的需求
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/components_of_machine_learning_systems.html">
            1.3. 机器学习系统基本组成
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_introduction/applicable_readers.html">
            1.4. 适用读者
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_programming_interface/index.html">
          2. 编程接口
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_interface/development_history.html">
            2.1. 机器学习系统编程模型的演进
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_interface/ml_workflow.html">
            2.2. 机器学习工作流
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_interface/neural_network_layer.html">
            2.3. 定义深度神经网络
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_interface/c_python_interaction.html">
            2.4. C/C++编程接口
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_programming_interface/summary.html">
            2.5. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_computational_graph/index.html">
          3. 计算图
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_computational_graph/background_and_functionality.html">
            3.1. 计算图的设计背景和作用
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_computational_graph/components_of_computational_graph.html">
            3.2. 计算图的基本构成
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_computational_graph/generation_of_computational_graph.html">
            3.3. 计算图的生成
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_computational_graph/schedule_of_computational_graph.html">
            3.4. 计算图的调度
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_computational_graph/summary.html">
            3.5. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_preface_advanced/index.html">
          4. 第二部分：进阶篇
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_frontend_and_ir/index.html">
          5. 编译器前端
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_frontend_and_ir/overview_of_frontend.html">
            5.1. 概述
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_frontend_and_ir/intermediate_representation.html">
            5.2. 中间表示
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_frontend_and_ir/ad.html">
            5.3. 自动微分
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_frontend_and_ir/type_system_and_static_analysis.html">
            5.4. 类型系统和静态分析
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_frontend_and_ir/common_frontend_optimization_pass.html">
            5.5. 常见前端编译优化方法
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_frontend_and_ir/summary.html">
            5.6. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1 current">
         <a class="reference internal" href="index.html">
          6. 编译器后端和运行时
         </a>
         <ul class="current">
          <li class="toctree-l2">
           <a class="reference internal" href="overview.html">
            6.1. 概述
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="graph_optimizer.html">
            6.2. 计算图优化
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="kernel_selecter.html">
            6.3. 算子选择
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="memory_allocator.html">
            6.4. 内存分配
           </a>
          </li>
          <li class="toctree-l2 current">
           <a class="current reference internal" href="#">
            6.5. 计算调度与执行
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="summary.html">
            6.6. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_accelerator/index.html">
          7. 硬件加速器
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/accelerator_introduction.html">
            7.1. 概述
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/accelerator_architecture.html">
            7.2. 加速器基本组成原理
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/accelerator_programming.html">
            7.3. 加速器基本编程原理
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_accelerator/summary.html">
            7.4. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_data_processing/index.html">
          8. 数据处理框架
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_data_processing/requirements.html">
            8.1. 概述
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_data_processing/program_model.html">
            8.2. 易用性设计
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_data_processing/performance.html">
            8.3. 高效性设计
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_data_processing/data_order.html">
            8.4. 保序性设计
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_data_processing/extension.html">
            8.5. 单机数据处理性能的扩展
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_data_processing/summary.html">
            8.6. 章节总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_model_deployment/index.html">
          9. 模型部署
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_model_deployment/model_deployment_introduction.html">
            9.1. 概述
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_model_deployment/model_converter_and_optimizer.html">
            9.2. 训练模型到推理模型的转换及优化
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_model_deployment/model_compression.html">
            9.3. 模型压缩
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_model_deployment/model_inference.html">
            9.4. 模型推理
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_model_deployment/model_security.html">
            9.5. 模型的安全保护
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_model_deployment/summary.html">
            9.6. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_distributed_training/index.html">
          10. 分布式训练
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed_training/overview.html">
            10.1. 系统概述
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed_training/methods.html">
            10.2. 分布式方法
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed_training/pipeline.html">
            10.3. 流水线并行
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed_training/collective.html">
            10.4. 集合通讯
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed_training/parameter_servers.html">
            10.5. 参数服务器
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../chapter_distributed_training/summary.html">
            10.6. 总结
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_preface_extension/index.html">
          11. 第三部分：拓展篇
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_federated_learning/index.html">
          12. 联邦学习系统
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_reinforcement_learning/index.html">
          13. 强化学习系统
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_explainable_AI/index.html">
          14. 可解释性AI系统
         </a>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_online_machine_learning/index.html">
          15. 在线机器学习
         </a>
        </li>
       </ul>
       <ul>
        <li class="toctree-l1">
         <a class="reference internal" href="../appendix_machine_learning_introduction/index.html">
          附录：机器学习介绍
         </a>
         <ul>
          <li class="toctree-l2">
           <a class="reference internal" href="../appendix_machine_learning_introduction/neural_network.html">
            1. 神经网络
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../appendix_machine_learning_introduction/gradient_descent.html">
            2. 梯度下降与反向传播
           </a>
          </li>
          <li class="toctree-l2">
           <a class="reference internal" href="../appendix_machine_learning_introduction/classic_machine_learning.html">
            3. 经典机器学习方法
           </a>
          </li>
         </ul>
        </li>
        <li class="toctree-l1">
         <a class="reference internal" href="../chapter_references/index.html">
          参考文献
         </a>
        </li>
       </ul>
      </nav>
     </div>
    </header>
    <div class="document">
     <div class="page-content" role="main">
      <section id="id1">
       <h1>
        <span class="section-number">
         6.5.
        </span>
        计算调度与执行
        <a class="headerlink" href="#id1" title="Permalink to this headline">
         ¶
        </a>
       </h1>
       <p>
        经过算子选择与内存分配之后，计算任务可以通过运行时完成计算的调度与在硬件上的执行。根据是否将算子编译为计算图，计算的调度可以分为单算子调度与计算图调度两种方式，例如在MindSpore中分别提供了PyNative模式和Graph模式。而根据硬件提供的能力差异，计算图的执行方式又可以分为逐算子下发执行的交互式执行以及将整个计算图或者部分子图一次性下发到硬件的下沉式执行两种模式。
       </p>
       <section id="id2">
        <h2>
         <span class="section-number">
          6.5.1.
         </span>
         单算子调度
         <a class="headerlink" href="#id2" title="Permalink to this headline">
          ¶
         </a>
        </h2>
        <p>
         单算子调度是相对于计算图而言，算法或者模型中包含的算子通过Python语言的运行时被逐个调度执行。例如PyTorch的默认执行方式，TensorFlow的eager模式，以及MindSpore的PyNative模式。以如下MindSpore示例代码所示：
        </p>
        <div class="highlight-python notranslate">
         <div class="highlight">
          <pre><span></span><span class="kn">import</span> <span class="nn">mindspore.nn</span> <span class="k">as</span> <span class="nn">nn</span>
    <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">context</span>
    <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">ms_function</span>

    <span class="c1"># 以单算子方式执行后续计算中的算子。</span>
    <span class="n">context</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">PYNATIVE_MODE</span><span class="p">)</span>

    <span class="k">class</span> <span class="nc">Computation</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">y</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="n">n</span>
            <span class="k">return</span> <span class="n">z</span>

    <span class="n">compute</span> <span class="o">=</span> <span class="n">Computation</span><span class="p">()</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre>
         </div>
        </div>
        <p>
         上述脚本将所有的计算逻辑定义在Computation类的construct方法中，由于在脚本开头的context中预先设置了单算子执行模式，construct中的计算将被Python的运行时逐行调用执行，同时可以在代码中的任意位置添加print命令以便打印中间的计算结果。
        </p>
        <p>
         单算子执行的调用链路如图
         <a class="reference internal" href="#single-op-exec">
          <span class="std std-numref">
           图6.5.1
          </span>
         </a>
         所示，算子在Python侧被触发执行后，会经过AI框架初始化，其中需要确定包括算子的精度，输入与输出的类型和大小以及对应的硬件设备等信息，接着框架会为该算子分配计算所需的内存，最后交给具体的硬件计算设备完成计算的执行。
        </p>
        <figure class="align-default" id="id6">
         <span id="single-op-exec">
         </span>
         <a class="reference internal image-reference" href="../_images/single_op_exec.PNG">
          <img alt="../_images/single_op_exec.PNG" src="../_images/single_op_exec.PNG" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.1
           </span>
           <span class="caption-text">
            单算子执行
           </span>
           <a class="headerlink" href="#id6" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         单算子调度方式的好处在于其灵活性，由于算子直接通过Python运行时调度，一方面可以表达任意复杂的计算逻辑，尤其是在需要复杂控制流以及需要Python原生数据结构支持来实现复杂算法的场景；另一方面单算子调度对于程序正确性的调试非常便利，开发人员可以在代码执行过程中打印任意需要调试的变量；最后一点是通过Python运行时驱动算子的方式，可以在计算中与Python庞大而丰富的生态库协同完成计算任务。
        </p>
       </section>
       <section id="id3">
        <h2>
         <span class="section-number">
          6.5.2.
         </span>
         计算图调度
         <a class="headerlink" href="#id3" title="Permalink to this headline">
          ¶
         </a>
        </h2>
        <p>
         虽然单算子调度具有如上所述的优点，其缺点也很明显。一方面是难于进行计算性能的优化，原因是由于缺乏计算图的全局信息，单算子执行时无法根据上下文完成算子融合，代数化简等优化；另一方面由于缺乏计算的拓扑关系，整个计算只能串行调度执行，即无法通过运行时完成并行计算。例如上述示例代码的计算逻辑可以表达为图
         <a class="reference internal" href="#graph-exec">
          <span class="std std-numref">
           图6.5.2
          </span>
         </a>
         所示。由该计算图可以看出，其中乘法和减法之间并没有依赖关系，因此这两个计算可以并行执行，而这样的并行执行信息只有将计算表达为计算图后才能完成分析，这也是计算图调度相对于单算子调度的优势之一。
        </p>
        <figure class="align-default" id="id7">
         <span id="graph-exec">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec.png">
          <img alt="../_images/graph_exec.png" src="../_images/graph_exec.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.2
           </span>
           <span class="caption-text">
            计算图
           </span>
           <a class="headerlink" href="#id7" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         下面我们开始介绍计算图的调度方式，在一个典型的异构计算环境中，主要存在CPU、GPU以及NPU等多种计算设备，因此一张计算图可以由运行在不同设备上的算子组成为异构计算图。图
         <a class="reference internal" href="#computation-graph">
          <span class="std std-numref">
           图6.5.3
          </span>
         </a>
         展示了一个典型的由异构硬件共同参与的计算图。
        </p>
        <figure class="align-default" id="id8">
         <span id="computation-graph">
         </span>
         <a class="reference internal image-reference" href="../_images/computation_graph.png">
          <img alt="../_images/computation_graph.png" src="../_images/computation_graph.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.3
           </span>
           <span class="caption-text">
            异构硬件计算图
           </span>
           <a class="headerlink" href="#id8" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         所述计算图由如下几类异构硬件对应的算子组成：
        </p>
        <ul class="simple">
         <li>
          <p>
           <strong>
            CPU算子
           </strong>
           ：由C++语言编写实现并在主机上通过CPU执行的算子，CPU计算的性能取决于是否能够充分利用CPU多核心的计算能力。
          </p>
         </li>
         <li>
          <p>
           <strong>
            GPU算子
           </strong>
           ：以英伟达GPU芯片为例，通过在主机侧将GPU
Kernel逐个下发到GPU设备上，由GPU芯片执行算子的计算逻辑，由于芯片上具备大量的并行执行单元，可以为高度并行的算法提供强大的加速能力。
          </p>
         </li>
         <li>
          <p>
           <strong>
            NPU算子
           </strong>
           ：以华为Ascend芯片为例,
Ascend是一个高度集成的SoC芯片，NPU的优势是支持将部分或整个计算图下沉到芯片中完成计算，计算过程中不与Host发生交互，因此具备较高的计算性能。
          </p>
         </li>
         <li>
          <p>
           <strong>
            Python算子
           </strong>
           ：在执行模式上与CPU算子类似，都是由主机上的CPU执行计算，区别在于计算逻辑是由Python语言的运行时通过Python解释器解释执行。
          </p>
         </li>
        </ul>
        <p>
         异构计算图能够被正确表达的首要条件是准确标识算子执行所在的设备，例如异构计算图
         <a class="reference internal" href="#computation-graph">
          <span class="std std-numref">
           图6.5.3
          </span>
         </a>
         中所标识的CPU、GPU和Ascend
Kernel，以及被标记为被Python语言运行时执行的Python
Kernel。主流框架均提供了指定算子所在运行设备的能力，以MindSpore为例，一段简单的异构计算代码如下所示：
        </p>
        <div class="highlight-python notranslate">
         <div class="highlight">
          <pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Tensor</span>
    <span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">ops</span>
    <span class="kn">from</span> <span class="nn">mindspore.common.api</span> <span class="kn">import</span> <span class="n">ms_function</span>

    <span class="c1"># 创建算子并指定执行算子的硬件设备</span>
    <span class="n">add</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Add</span><span class="p">()</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s1">'primitive_target'</span><span class="p">,</span> <span class="s1">'CPU'</span><span class="p">)</span>
    <span class="n">sub</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()</span><span class="o">.</span><span class="n">add_prim_attr</span><span class="p">(</span><span class="s1">'primitive_target'</span><span class="p">,</span> <span class="s1">'GPU'</span><span class="p">)</span>

    <span class="c1"># 指定按照静态计算图模式执行函数</span>
    <span class="nd">@ms_function</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sub</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

    <span class="c1"># 创建实参</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="c1"># 执行计算</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
</pre>
         </div>
        </div>
        <p>
         上述代码片段完成了x + y -
z的计算逻辑，其中Add算子被设置为在CPU上执行，Sub算子被设置为在GPU上执行，从而形成了CPU与GPU协同的异构计算，通过类似的标签机制，可以实现任意复杂的多硬件协同的异构计算表达。
另外一类较为特殊的异构是Python算子，Python语言的优势在于表达的灵活性和开发效率，以及丰富的周边生态，因此将Python算子引入到计算图中和其它异构硬件的算子协同计算，对计算的灵活性会产生非常大的帮助。与CPU、GPU分别执行在不同设备上的异构不同，Python算子和C++实现的CPU算子都是通过主机侧的CPU核执行，差异在于Python算子是通过统一的计算图进行描述，因此也需要在计算图的执行引擎中被触发执行。为了在计算图中能够表达Python算子，框架需要提供相应的支持。
        </p>
        <p>
         完成计算图中算子对应设备的标记以后，计算图已经准备好被调度与执行，根据硬件能力的差异，可以将异构计算图的执行分为三种模式，分别是逐算子交互式执行，整图下沉执行与子图下沉执行。交互式执行主要针对CPU和GPU的场景，计算图中的算子按照输入和输出的依赖关系被逐个调度与执行；而整图下沉执行模式主要是针对NPU芯片而言，这类芯片主要的优势是能够将整个神经网络的计算图一次性下发到设备上，无需借助主机的CPU能力而独立完成计算图中所有算子的调度与执行，减少了主机和芯片的交互次数，借助NPU的Tensor加速能力，提高了计算效率和性能；子图下沉执行模式是前面两种执行模式的结合，由于计算图自身表达的灵活性，对于复杂场景的计算图在NPU芯片上进行整图下沉执行的效率不一定能达到最优，因此可以将对于NPU芯片执行效率低下的部分分离出来，交给CPU或者GPU等执行效率更高的设备处理，而将部分更适合NPU计算的子图下沉到NPU进行计算，这样可以兼顾性能和灵活性两方面。
        </p>
        <p>
         上述异构计算图可以实现两个目的，一个是异构硬件加速，将特定的计算放置到合适的硬件上执行；第二个是实现算子间的并发执行，从计算图上可以看出，kernel_1和kernel_2之间没有依赖关系，kernel_3和kernel_4之间也没有依赖关系，因此这两组CPU和GPU算子在逻辑上可以被框架并发调用，而kernel_5依赖kernel_3和kernel_4的输出作为输入，因此kernel_5需要等待kernel_3和kernel_4执行完成后再被触发执行。
        </p>
        <p>
         虽然在计算图上可以充分表达算子间的并发关系，在实际代码中会产生由于并发而引起的一些不预期的副作用场景，例如如下代码所示：
        </p>
        <div class="highlight-python notranslate">
         <div class="highlight">
          <pre><span></span><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
    <span class="kn">from</span> <span class="nn">mindspore</span> <span class="kn">import</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Tensor</span>
    <span class="kn">import</span> <span class="nn">mindspore.ops.operations</span> <span class="k">as</span> <span class="nn">ops</span>
    <span class="kn">from</span> <span class="nn">mindspore.common.api</span> <span class="kn">import</span> <span class="n">ms_function</span>

    <span class="c1"># 定义全局变量</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">"x"</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.2</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">],</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># 指定按照静态计算图模式执行函数</span>
    <span class="nd">@ms_function</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">ops</span><span class="o">.</span><span class="n">Assign</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">ops</span><span class="o">.</span><span class="n">Assign</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">Sub</span><span class="p">()(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="n">compute</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
</pre>
         </div>
        </div>
        <p>
         上述代码表达了如下计算逻辑：
        </p>
        <div class="highlight-text notranslate">
         <div class="highlight">
          <pre><span></span>x = y
    x = z
    x = x - y
</pre>
         </div>
        </div>
        <p>
         这段简单的计算逻辑翻译到计算图上可以表示为：
        </p>
        <figure class="align-default" id="id9">
         <span id="side-effect-1">
         </span>
         <a class="reference internal image-reference" href="../_images/side_effect_1.png">
          <img alt="../_images/side_effect_1.png" src="../_images/side_effect_1.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.4
           </span>
           <span class="caption-text">
            并发算子执行
           </span>
           <a class="headerlink" href="#id9" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         代码中所示三行计算之间并没有依赖关系，因此这三个算子在计算图的逻辑上可以被并发执行，并发关系如图
         <a class="reference internal" href="#side-effect-1">
          <span class="std std-numref">
           图6.5.4
          </span>
         </a>
         所示，然而根据代码的语义，显而易见是需要确保程序能够被顺序执行，这里引入的问题被称为副作用，副作用是指函数修改了在函数外部定义的状态变量的行为。由于副作用的引入而导致了错误并发关系的发生，一种解决方案是在计算图编译阶段通过添加算子间的依赖，将并发执行逻辑转换为顺序执行逻辑，转换后的计算图如图
         <a class="reference internal" href="#side-effect-2">
          <span class="std std-numref">
           图6.5.5
          </span>
         </a>
         所示：
        </p>
        <figure class="align-default" id="id10">
         <span id="side-effect-2">
         </span>
         <a class="reference internal image-reference" href="../_images/side_effect_2.png">
          <img alt="../_images/side_effect_2.png" src="../_images/side_effect_2.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.5
           </span>
           <span class="caption-text">
            消除副作用
           </span>
           <a class="headerlink" href="#id10" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         图中虚线箭头表达了算子之间的依赖关系，添加依赖关系后，算子会按照Assign_1，Assign_2，Sub_1的顺序串行执行，与代码原本的语义保持一致。
        </p>
       </section>
       <section id="id4">
        <h2>
         <span class="section-number">
          6.5.3.
         </span>
         交互式执行
         <a class="headerlink" href="#id4" title="Permalink to this headline">
          ¶
         </a>
        </h2>
        <p>
         如上所述，交互式执行模式下，框架的运行时根据计算图中算子的依赖关系，按照某种执行序（例如广度优先序）逐个将算子下发到硬件上执行。为了助于理解和对比，先引入非异构计算图（计算图中的算子都是在同一类设备上）的执行方式，异构计算图的执行是基于非异构计算图基础之上的。
        </p>
        <p>
         1、非异构计算图的执行方式
        </p>
        <figure class="align-default" id="id11">
         <span id="graph-exec-1">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_1.png">
          <img alt="../_images/graph_exec_1.png" src="../_images/graph_exec_1.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.6
           </span>
           <span class="caption-text">
            非异构计算图
           </span>
           <a class="headerlink" href="#id11" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         如图
         <a class="reference internal" href="#graph-exec-1">
          <span class="std std-numref">
           图6.5.6
          </span>
         </a>
         是一张非异构计算图，计算图上全部Kernel均为GPU算子，执行方式一般分为串行执行和并行执行：
        </p>
        <figure class="align-default" id="id12">
         <span id="graph-exec-2">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_2.png">
          <img alt="../_images/graph_exec_2.png" src="../_images/graph_exec_2.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.7
           </span>
           <span class="caption-text">
            串行执行
           </span>
           <a class="headerlink" href="#id12" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <figure class="align-default" id="id13">
         <span id="graph-exec-3">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_3.png">
          <img alt="../_images/graph_exec_3.png" src="../_images/graph_exec_3.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.8
           </span>
           <span class="caption-text">
            并行执行
           </span>
           <a class="headerlink" href="#id13" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <ul class="simple">
         <li>
          <p>
           <strong>
            串行执行
           </strong>
           ：将计算图展开为执行序列，按照执行序逐个串行执行，如图
           <a class="reference internal" href="#graph-exec-2">
            <span class="std std-numref">
             图6.5.7
            </span>
           </a>
           所示。其特点为执行顺序固定，单线程执行，对系统资源要求相对较低。
          </p>
         </li>
         <li>
          <p>
           <strong>
            并行执行
           </strong>
           ：将计算图按照算子之间的依赖关系展开，有依赖关系的算子通过输入依赖保证执行顺序，没有依赖关系的算子则可以并行执行，如图
           <a class="reference internal" href="#graph-exec-3">
            <span class="std std-numref">
             图6.5.8
            </span>
           </a>
           所示，Kernel_1和Kernel_2没有依赖可以并行执行，Kernel_3和Kernel_4没有依赖可以并行执行。其特点为执行顺序不固定，每轮执行的算子顺序大概率不一样，多线程执行，对系统资源要求相关较高。
          </p>
         </li>
        </ul>
        <p>
         串行执行和并行执行各有优点和缺点，总结对比见表5.1。
        </p>
        <table class="docutils align-default" style="margin-left:auto;margin-right:auto;margin-top:10px;margin-bottom:20px;">
         <colgroup>
          <col style="width: 43%"/>
          <col style="width: 29%"/>
          <col style="width: 29%"/>
         </colgroup>
         <thead>
          <tr class="row-odd">
           <th class="head">
            <p>
             执行方式
            </p>
           </th>
           <th class="head">
            <p>
             串行执行
            </p>
           </th>
           <th class="head">
            <p>
             并行执行
            </p>
           </th>
          </tr>
         </thead>
         <tbody>
          <tr class="row-even">
           <td>
            <p>
             算子执行顺序
            </p>
           </td>
           <td>
            <p>
             固定
            </p>
           </td>
           <td>
            <p>
             不固定
            </p>
           </td>
          </tr>
          <tr class="row-odd">
           <td>
            <p>
             算子执行线程
            </p>
           </td>
           <td>
            <p>
             单线程
            </p>
           </td>
           <td>
            <p>
             多线程
            </p>
           </td>
          </tr>
          <tr class="row-even">
           <td>
            <p>
             所需执行资源
            </p>
           </td>
           <td>
            <p>
             较低
            </p>
           </td>
           <td>
            <p>
             较高
            </p>
           </td>
          </tr>
         </tbody>
        </table>
        <p>
         2、异构计算图的执行方式
        </p>
        <figure class="align-default" id="id14">
         <span id="graph-exec-4">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_4.png">
          <img alt="../_images/graph_exec_4.png" src="../_images/graph_exec_4.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.9
           </span>
           <span class="caption-text">
            异构计算图
           </span>
           <a class="headerlink" href="#id14" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         如图
         <a class="reference internal" href="#graph-exec-4">
          <span class="std std-numref">
           图6.5.9
          </span>
         </a>
         是一张异构计算图，其中Kernel_1、Kernel_2、Kernel_5、Kernel_9为CPU算子，Kernel_6为python算子（执行也是在CPU上），Kernel_3和Kernel_4为GPU算子，Kernel_7和Kernel_8为GPU算子。
一般来说计算图的优化都是基于非异构计算图来实现的，要求计算图中的算子为同一设备上的，方便算子间的融合替换等优化操作，因此需要将一张异构计算图切分为多个非异构计算图，这里切分就比较灵活了，可以定义各种切分规则，一般按照产生尽量少的子图的切分规则来切分，尽量将多的同一设备上的算子放在一张子图中，如图
         <a class="reference internal" href="#graph-exec-5">
          <span class="std std-numref">
           图6.5.10
          </span>
         </a>
         所示，最后产生5张子图：Graph_1_CPU、Graph_2_GPU、Graph_3_CPU、Graph_4_Ascend、Graph_5_CPU。
        </p>
        <figure class="align-default" id="id15">
         <span id="graph-exec-5">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_5.png">
          <img alt="../_images/graph_exec_5.png" src="../_images/graph_exec_5.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.10
           </span>
           <span class="caption-text">
            异构计算图切分
           </span>
           <a class="headerlink" href="#id15" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         将一张异构计算图切分为多个子计算图后，执行方式一般分为子图拆分执行和子图合并执行：
        </p>
        <ul class="simple">
         <li>
          <p>
           <strong>
            子图拆分执行
           </strong>
           ：将切分后的多个子图分开执行，即一个子图执行完再执行另一个子图，如图
           <a class="reference internal" href="#graph-exec-6">
            <span class="std std-numref">
             图6.5.11
            </span>
           </a>
           所示，上一个子图的输出数据会传输给下一个子图的输入数据，并且下一个子图需要对输入数据拷贝为本图的device数据，如Graph_2_GPU需要将Graph_1_CPU的输出数据从CPU拷贝到GPU，反过来Graph_3_CPU需要将Graph2GPU的输出数据从GPU拷贝到CPU，子图之间互相切换执行有一定的开销。
          </p>
         </li>
         <li>
          <p>
           <strong>
            子图合并执行
           </strong>
           ：将切分后的多个子图进行合并，合并为一个整体大的DAG执行，如图
           <a class="reference internal" href="#graph-exec-7">
            <span class="std std-numref">
             图6.5.12
            </span>
           </a>
           所示，通过算子的设备属性来插入拷贝算子以实现不同设备上的算子数据传输，并且拷贝算子也是进入整图中的，从而形成一个大的整图执行，减少子图之间的切换执行开销。
          </p>
         </li>
        </ul>
        <figure class="align-default" id="id16">
         <span id="graph-exec-6">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_6.png">
          <img alt="../_images/graph_exec_6.png" src="../_images/graph_exec_6.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.11
           </span>
           <span class="caption-text">
            子图拆分
           </span>
           <a class="headerlink" href="#id16" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <figure class="align-default" id="id17">
         <span id="graph-exec-7">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_7.png">
          <img alt="../_images/graph_exec_7.png" src="../_images/graph_exec_7.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.12
           </span>
           <span class="caption-text">
            子图合并
           </span>
           <a class="headerlink" href="#id17" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
        <p>
         由于子图合并执行能够减少子图之间的切换执行开销，因此一般来说子图合并执行性能较高，总结对比见表5.2。
        </p>
        <table class="docutils align-default" style="margin-left:auto;margin-right:auto;margin-top:10px;margin-bottom:20px;">
         <colgroup>
          <col style="width: 30%"/>
          <col style="width: 40%"/>
          <col style="width: 30%"/>
         </colgroup>
         <thead>
          <tr class="row-odd">
           <th class="head">
            <p>
             执行方式
            </p>
           </th>
           <th class="head">
            <p>
             子图拆分
            </p>
           </th>
           <th class="head">
            <p>
             子图合并
            </p>
           </th>
          </tr>
         </thead>
         <tbody>
          <tr class="row-even">
           <td>
            <p>
             异构数据传输
            </p>
           </td>
           <td>
            <p>
             子图之间拷贝
            </p>
           </td>
           <td>
            <p>
             算子之间拷贝
            </p>
           </td>
          </tr>
          <tr class="row-odd">
           <td>
            <p>
             执行额外开销
            </p>
           </td>
           <td>
            <p>
             子图切换执行开销
            </p>
           </td>
           <td>
            <p>
             无
            </p>
           </td>
          </tr>
          <tr class="row-even">
           <td>
            <p>
             执行并发粒度
            </p>
           </td>
           <td>
            <p>
             子图并发
            </p>
           </td>
           <td>
            <p>
             算子原生并发
            </p>
           </td>
          </tr>
         </tbody>
        </table>
        <p>
         3、异构计算图的执行加速
        </p>
        <p>
         前面讲述了非异构计算图的两种执行方式和异构计算图的两种执行方式，其中异构计算图又是在非异构计算图的基础之上，因此异构计算图按照两两组合共有四种执行方式，以MindSpore为例，采用的是子图合并并行执行，示例图如图
         <a class="reference internal" href="#graph-exec-5">
          <span class="std std-numref">
           图6.5.10
          </span>
         </a>
         所示，首先是作为一张整图来执行可以避免子图切换的执行开销，然后在整图内并行执行，可以最大粒度的发挥并发执行优势，达到最优的执行性能。
        </p>
        <figure class="align-default" id="id18">
         <span id="graph-exec-8">
         </span>
         <a class="reference internal image-reference" href="../_images/graph_exec_8.png">
          <img alt="../_images/graph_exec_8.png" src="../_images/graph_exec_8.png" style="width: 800px;"/>
         </a>
         <figcaption>
          <p>
           <span class="caption-number">
            图6.5.13
           </span>
           <span class="caption-text">
            异构硬件加速
           </span>
           <a class="headerlink" href="#id18" title="Permalink to this image">
            ¶
           </a>
          </p>
         </figcaption>
        </figure>
       </section>
       <section id="id5">
        <h2>
         <span class="section-number">
          6.5.4.
         </span>
         下沉式执行
         <a class="headerlink" href="#id5" title="Permalink to this headline">
          ¶
         </a>
        </h2>
        <p>
         下沉式执行是通过专用芯片的SoC架构，将整个或部分计算图一次性调度到芯片上以完成全量数据的计算。例如对于Ascend芯片，多个Ascend算子组成的计算图可以在执行前被编译成为一个Task，通过Ascend驱动程序提供的接口，将包含多个算子的Task一次性下发到硬件上调度执行。因此上例中可以将Ascend的算子Kernel_7和Kernel_8优化为一个子图Graph_4_Ascend，再将该子图编译成为一个Task，并下沉到Ascend上执行，如图
         <a class="reference internal" href="#graph-exec-8">
          <span class="std std-numref">
           图6.5.13
          </span>
         </a>
         所示。
        </p>
        <p>
         下沉式执行由于避免了在计算过程中主机侧和设备侧的交互，因此可以获得更好的整体计算性能。然而下沉式执行也存在一些局限，例如在动态shape算子，复杂控制流等场景下会面临较大的技术挑战。
        </p>
       </section>
      </section>
     </div>
     <div class="side-doc-outline">
      <div class="side-doc-outline--content">
       <div class="localtoc">
        <p class="caption">
         <span class="caption-text">
          Table Of Contents
         </span>
        </p>
        <ul>
         <li>
          <a class="reference internal" href="#">
           6.5. 计算调度与执行
          </a>
          <ul>
           <li>
            <a class="reference internal" href="#id2">
             6.5.1. 单算子调度
            </a>
           </li>
           <li>
            <a class="reference internal" href="#id3">
             6.5.2. 计算图调度
            </a>
           </li>
           <li>
            <a class="reference internal" href="#id4">
             6.5.3. 交互式执行
            </a>
           </li>
           <li>
            <a class="reference internal" href="#id5">
             6.5.4. 下沉式执行
            </a>
           </li>
          </ul>
         </li>
        </ul>
       </div>
      </div>
     </div>
     <div class="clearer">
     </div>
    </div>
    <div class="pagenation">
     <a accesskey="P" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" href="memory_allocator.html" id="button-prev" role="botton">
      <i class="pagenation-arrow-L fas fa-arrow-left fa-lg">
      </i>
      <div class="pagenation-text">
       <span class="pagenation-direction">
        Previous
       </span>
       <div>
        6.4. 内存分配
       </div>
      </div>
     </a>
     <a accesskey="N" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" href="summary.html" id="button-next" role="botton">
      <i class="pagenation-arrow-R fas fa-arrow-right fa-lg">
      </i>
      <div class="pagenation-text">
       <span class="pagenation-direction">
        Next
       </span>
       <div>
        6.6. 总结
       </div>
      </div>
     </a>
    </div>
   </main>
  </div>
 </body>
</html>